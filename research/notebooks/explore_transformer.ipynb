{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with transformers\n",
    "Transformers remain as a promising replacement of RNNs due to their parallelizability. However, RNNs are unique in their hidden state which tends to be uniquely useful for games. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import utils\n",
    "import models\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = pd.read_csv('../data/haha-longer-longer-001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trainX\n",
    "dtype_trainX = np.int32  # or the correct dtype for your data\n",
    "shape_trainX = (130177, 750)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/transformer/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int32 # or the correct dtype for your data\n",
    "shape_trainY = (130177, 7)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/transformer/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainY\n",
    "dtype_seq_lengths = np.int32 # or the correct dtype for your data\n",
    "shape_seq_lengths = (130177, 7)  # replace with the correct shape\n",
    "seq_lengths = load_memmap('./../data/transformer/seq_lengths.memmap', dtype_seq_lengths, shape_seq_lengths)\n",
    "\n",
    "with open('./../data/transformer/vocab.pkl', 'rb') as inp:\n",
    "    vocab = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130177, 7)\n"
     ]
    }
   ],
   "source": [
    "print(seq_lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, sequences, seq_lengths, labels):\n",
    "        self.sequences, self.seq_lengths, self.labels = sequences, seq_lengths, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.seq_lengths, dtype = torch.long), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127573\n"
     ]
    }
   ],
   "source": [
    "dataset = TransformerDataset(trainX, seq_lengths, trainY)\n",
    "total_size = len(dataset)\n",
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.98 * total_size)\n",
    "val_size = int(total_size * 0.02)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)\n",
    "# Reload the data with particular batch size\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class ChessTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, max_seq_length=750, dropout=0.1):\n",
    "        super(ChessTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_seq_length)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n",
    "                                          num_encoder_layers=num_layers,\n",
    "                                          num_decoder_layers=num_layers,\n",
    "                                          batch_first=True)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def forward(self, src, src_lengths, tgt):\n",
    "        # Create source padding mask\n",
    "        src_padding_mask = self.create_padding_mask(src_lengths, self.max_seq_length).to(src.device)\n",
    "        \n",
    "        # Embedding and Positional Encoding for src\n",
    "        src_emb = self.embedding(src)  # [batch_size, seq_len] -> [batch_size, seq_len, d_model]\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "\n",
    "        # Assuming tgt is provided correctly and also needs embedding & positional encoding\n",
    "        tgt_emb = self.embedding(tgt)\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "\n",
    "        # Transformer\n",
    "        output = self.transformer(src_emb, tgt_emb, src_key_padding_mask=src_padding_mask)\n",
    "        \n",
    "        # Linear layer to predict vocab\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def create_padding_mask(self, seq_lengths, max_len):\n",
    "        print(seq_lengths.shape)\n",
    "        batch_size = seq_lengths.size(0)\n",
    "        mask = (torch.arange(max_len).expand(batch_size, max_len) >= seq_lengths.unsqueeze(1))\n",
    "        return mask\n",
    "    \n",
    "    def generate_sequence(self, src, src_length, start_symbol_id, sep_token_id, max_length=100):\n",
    "        \"\"\"\n",
    "        Generate a sequence autoregressively using the trained transformer model.\n",
    "\n",
    "        Args:\n",
    "        - src (Tensor): The input source sequence tensor.\n",
    "        - src_length (Tensor): The length of the source sequence.\n",
    "        - start_symbol_id (int): The ID of the start symbol to begin generation.\n",
    "        - sep_token_id (int): The ID of the SEP token for sequence termination.\n",
    "        - max_length (int): Maximum length of the generated sequence to prevent infinite loops.\n",
    "\n",
    "        Returns:\n",
    "        - The generated sequence tensor.\n",
    "        \"\"\"\n",
    "        self.eval()  # Ensure the model is in eval mode\n",
    "\n",
    "        # Initialize the target sequence with the start symbol\n",
    "        tgt = torch.tensor([start_symbol_id], dtype=torch.long).to(src.device)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            # Assuming src_length is a tensor with the length of src. Adjust as needed.\n",
    "\n",
    "            # Perform a forward pass to get logits for the next token\n",
    "            logits = self.forward(src, src_length, tgt, src)\n",
    "            # Get the last token logits and apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "            # Sample the next token from the probability distribution\n",
    "            next_token = torch.multinomial(probs, 1)\n",
    "            \n",
    "            # Append the predicted token to the target sequence\n",
    "            tgt = torch.cat((tgt, next_token), dim=1)\n",
    "            \n",
    "            # Check if the <SEP> token is generated\n",
    "            if next_token.item() == sep_token_id:\n",
    "                break\n",
    "\n",
    "        return tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.swa_utils import AveragedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate top-3 accuracy\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    top3 = torch.topk(y_pred, 3, dim=1).indices\n",
    "    correct = top3.eq(y_true.view(-1, 1).expand_as(top3))\n",
    "    return correct.any(dim=1).float().mean().item()\n",
    "\n",
    "def train_transformer(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay):\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    val_3_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        training_loss = 0.0\n",
    "        # Training\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for sequences, lengths, labels in train_loader:\n",
    "            count += 1\n",
    "            sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
    "            # Forward Pass\n",
    "            logits = model(sequences, lengths, labels).data\n",
    "            loss = criterion(logits.view(-1, model.vocab_size), tgt_labels.contiguous().view(-1))\n",
    "            # Backpropogate & Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # For logging purposes\n",
    "            training_loss += loss.item()\n",
    "            # _, predicted = torch.max(output.data, 1)\n",
    "            # train_total += labels.size(0)\n",
    "            # train_correct += (predicted == labels).sum().item()\n",
    "            if count % 1000 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch: {count}| Training Loss: {training_loss/count}')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        validation_loss = 0.0\n",
    "        # if val_loader is not None:\n",
    "        #     with torch.no_grad():\n",
    "        #         val_correct = 0\n",
    "        #         val_total = 0\n",
    "        #         val_top3_correct = 0\n",
    "        #         validation_loss = 0\n",
    "\n",
    "        #         for sequences, lengths, labels in val_loader:\n",
    "        #             sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
    "        #             outputs = model.generate(sequences, lengths)\n",
    "        #             _, predicted = torch.max(outputs.data, 1)\n",
    "        #             val_total += labels.size(0)\n",
    "        #             val_correct += (predicted == labels).sum().item()\n",
    "        #             val_top3_correct += top_3_accuracy(labels, outputs) * labels.size(0)\n",
    "        #             loss = criterion(outputs, labels)\n",
    "        #             validation_loss += loss.item()\n",
    "\n",
    "        #         val_loss_values.append(validation_loss / len(val_loader))\n",
    "        #         val_accuracy = 100 * val_correct / val_total\n",
    "        #         val_top3_accuracy = 100 * val_top3_correct / val_total\n",
    "        #         val_error.append(100 - val_accuracy)\n",
    "        #         val_3_accuracy.append(val_top3_accuracy)\n",
    "\n",
    "        # Log Model Performance  \n",
    "        train_loss_values.append(training_loss)\n",
    "        train_error.append(100-100*train_correct/train_total)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_loss/len(train_loader)}, Validation Error: {val_error[-1]}, Validation Top-3 Accuracy: {val_3_accuracy[-1]}, Training Error: {train_error[-1]}')\n",
    "        for op_params in optimizer.param_groups:\n",
    "            op_params['lr'] = op_params['lr'] * learn_decay\n",
    "    return train_error,train_loss_values, val_error, val_loss_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11598892\n"
     ]
    }
   ],
   "source": [
    "# Reload the data with particular batch size\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_model = 256\n",
    "NUM_EPOCHS = 5\n",
    "d_out = len(vocab.id_to_word.keys())\n",
    "nhead = 8\n",
    "num_layers = 4\n",
    "model = ChessTransformer(d_out, d_model, nhead, num_layers = num_layers)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab.get_id('<PAD>'))  # Assuming you have a PAD token\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.65 # This causes the LR to be 2e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 130177, 7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (750) must match the size of tensor b (7) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_error,train_loss_values, val_error, val_loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the training error\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[0;32mIn[41], line 24\u001b[0m, in \u001b[0;36mtrain_transformer\u001b[0;34m(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay)\u001b[0m\n\u001b[1;32m     22\u001b[0m sequences, lengths, labels \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39mto(device), lengths\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Forward Pass\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m.\u001b[39mvocab_size), tgt_labels\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Backpropogate & Optimize\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 34\u001b[0m, in \u001b[0;36mChessTransformer.forward\u001b[0;34m(self, src, src_lengths, tgt)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, src_lengths, tgt):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Create source padding mask\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     src_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_padding_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(src\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Embedding and Positional Encoding for src\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     src_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(src)  \u001b[38;5;66;03m# [batch_size, seq_len] -> [batch_size, seq_len, d_model]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 54\u001b[0m, in \u001b[0;36mChessTransformer.create_padding_mask\u001b[0;34m(self, seq_lengths, max_len)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(seq_lengths\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     53\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m seq_lengths\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m mask \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq_lengths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (750) must match the size of tensor b (7) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train_transformer(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('transformer-4-04.png')  # This will save the plot as an image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
