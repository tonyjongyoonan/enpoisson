{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with transformers\n",
    "Transformers remain as a promising replacement of RNNs due to their parallelizability. However, RNNs are unique in their hidden state which tends to be uniquely useful for games. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import numpy as np\n",
    "import utils\n",
    "import models\n",
    "\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = pd.read_csv('../data/haha-longer-longer-001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trainX\n",
    "dtype_trainX = np.int32  # or the correct dtype for your data\n",
    "shape_trainX = (2161482, 750)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/transformer/jan/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int32 # or the correct dtype for your data\n",
    "shape_trainY = (2161482, 7)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/transformer/jan/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "with open('./../data/transformer/jan/vocab.pkl', 'rb') as inp:\n",
    "    vocab = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "print(trainX[:1,:4])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences, self.labels = sequences, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2118252\n"
     ]
    }
   ],
   "source": [
    "dataset = TransformerDataset(trainX, trainY)\n",
    "total_size = len(dataset)\n",
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.98 * total_size)\n",
    "val_size = int(total_size * 0.02)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)\n",
    "# Reload the data with particular batch size\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class ChessTransformer(nn.Module):\n",
    "    def __init__(self, vocab, d_model, nhead, num_layers, max_seq_length=750, dropout=0.1):\n",
    "        super(ChessTransformer, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(vocab.id_to_word.keys())\n",
    "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_seq_length)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n",
    "                                          num_encoder_layers=num_layers,\n",
    "                                          num_decoder_layers=num_layers,\n",
    "                                          batch_first=True)\n",
    "        self.fc = nn.Linear(d_model, self.vocab_size)\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # Create source padding mask\n",
    "        print(src.shape)\n",
    "        src_padding_mask = self.create_padding_mask(src).to(src.device)\n",
    "        tgt_padding_mask = self.create_padding_mask(tgt).to(tgt.device)\n",
    "        # Embedding and Positional Encoding for src\n",
    "\n",
    "        src_emb = self.embedding(src)  # [batch_size, seq_len] -> [batch_size, seq_len, d_model]\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        print(src_emb.shape)\n",
    "        # Assuming tgt is provided correctly and also needs embedding & positional encoding\n",
    "        tgt_emb = self.embedding(tgt)\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "\n",
    "        # Transformer\n",
    "        output = self.transformer(src_emb, tgt_emb, src_key_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask)\n",
    "        print(output.shape)\n",
    "        # Linear layer to predict vocab\n",
    "        output = self.fc(output)\n",
    "        print(output.shape)\n",
    "        return output\n",
    "    \n",
    "    def create_padding_mask(self, src):\n",
    "        PAD_IDX = 0\n",
    "        src_padding_mask = (src == PAD_IDX)\n",
    "        return src_padding_mask\n",
    "    \n",
    "    def generate_sequence(self, src, src_length, start_symbol_id, sep_token_id, max_length=100):\n",
    "        \"\"\"\n",
    "        Generate a sequence autoregressively using the trained transformer model.\n",
    "\n",
    "        Args:\n",
    "        - src (Tensor): The input source sequence tensor.\n",
    "        - src_length (Tensor): The length of the source sequence.\n",
    "        - start_symbol_id (int): The ID of the start symbol to begin generation.\n",
    "        - sep_token_id (int): The ID of the SEP token for sequence termination.\n",
    "        - max_length (int): Maximum length of the generated sequence to prevent infinite loops.\n",
    "\n",
    "        Returns:\n",
    "        - The generated sequence tensor.\n",
    "        \"\"\"\n",
    "        self.eval()  # Ensure the model is in eval mode\n",
    "\n",
    "        # Initialize the target sequence with the start symbol\n",
    "        tgt = torch.tensor([start_symbol_id], dtype=torch.long).to(src.device)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            # Assuming src_length is a tensor with the length of src. Adjust as needed.\n",
    "\n",
    "            # Perform a forward pass to get logits for the next token\n",
    "            logits = self.forward(src, src_length, tgt, src)\n",
    "            # Get the last token logits and apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "            # get most likely token from probs\n",
    "            next_token = torch.max(probs, 1)\n",
    "            \n",
    "            # Append the predicted token to the target sequence\n",
    "            tgt = torch.cat((tgt, next_token), dim=1)\n",
    "            \n",
    "            # Check if the <SEP> token is generated\n",
    "            if next_token.item() == sep_token_id:\n",
    "                break\n",
    "\n",
    "        return tgt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate top-3 accuracy\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    top3 = torch.topk(y_pred, 3, dim=1).indices\n",
    "    correct = top3.eq(y_true.view(-1, 1).expand_as(top3))\n",
    "    return correct.any(dim=1).float().mean().item()\n",
    "\n",
    "def train_transformer(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay):\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    val_3_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        training_loss = 0.0\n",
    "        # Training\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for sequences, labels in train_loader:\n",
    "            count += 1\n",
    "            sequences, lengths, labels = sequences.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            # Forward Pass\n",
    "            logits = model(sequences, labels)\n",
    "            print(logits)\n",
    "            loss = criterion(logits.view(-1, model.vocab_size), labels.contiguous().view(-1))\n",
    "            # Backpropogate & Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # Clip it\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            # For logging purposes\n",
    "            training_loss += loss.item()\n",
    "            # _, predicted = torch.max(output.data, 1)\n",
    "            # train_total += labels.size(0)\n",
    "            # train_correct += (predicted == labels).sum().item()\n",
    "            # Get the predicted class indices for each position in each sequence\n",
    "            _, predicted = torch.max(logits.data, dim=2)  # Shape: (batch_size, seq_length)\n",
    "            correct_predictions = predicted == labels  # Shape: (batch_size, seq_length)\n",
    "            correct_sequences = correct_predictions.all(dim=1)  # Shape: (batch_size)\n",
    "            train_correct += correct_sequences.sum().item()\n",
    "            train_total += labels.size(0) \n",
    "            break\n",
    "            if count % 1000 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch: {count}| Training Loss: {training_loss/count}')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        validation_loss = 0.0\n",
    "        # if val_loader is not None:\n",
    "        #     with torch.no_grad():\n",
    "        #         val_correct = 0\n",
    "        #         val_total = 0\n",
    "        #         val_top3_correct = 0\n",
    "        #         validation_loss = 0\n",
    "\n",
    "        #         for sequences, lengths, labels in val_loader:\n",
    "        #             sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
    "        #             outputs = model.generate(sequences, lengths)\n",
    "        #             _, predicted = torch.max(outputs.data, 1)\n",
    "        #             val_total += labels.size(0)\n",
    "        #             val_correct += (predicted == labels).sum().item()\n",
    "        #             val_top3_correct += top_3_accuracy(labels, outputs) * labels.size(0)\n",
    "        #             loss = criterion(outputs, labels)\n",
    "        #             validation_loss += loss.item()\n",
    "\n",
    "        #         val_loss_values.append(validation_loss / len(val_loader))\n",
    "        #         val_accuracy = 100 * val_correct / val_total\n",
    "        #         val_top3_accuracy = 100 * val_top3_correct / val_total\n",
    "        #         val_error.append(100 - val_accuracy)\n",
    "        #         val_3_accuracy.append(val_top3_accuracy)\n",
    "        # Log Model Performance  \n",
    "        train_loss_values.append(training_loss)\n",
    "        train_error.append(100-100*train_correct/train_total)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_loss/len(train_loader)}, Validation Error: {val_error[-1]}, Validation Top-3 Accuracy: {val_3_accuracy[-1]}, Training Error: {train_error[-1]}')\n",
    "        for op_params in optimizer.param_groups:\n",
    "            op_params['lr'] = op_params['lr'] * learn_decay\n",
    "    return train_error,train_loss_values, val_error, val_loss_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5811244\n"
     ]
    }
   ],
   "source": [
    "# Reload the data with particular batch size\n",
    "torch.multiprocessing.set_start_method('fork', force=True)\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_model = 256\n",
    "NUM_EPOCHS = 5\n",
    "vocab_size = len(vocab.id_to_word.keys())\n",
    "nhead = 8\n",
    "num_layers = 2\n",
    "model = ChessTransformer(vocab, d_model, nhead, num_layers = num_layers)\n",
    "model = model.to(device)\n",
    "# This ignores loss on pad tokens from the label's perspective\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab.get_id('<PAD>'))  # Assuming you have a PAD token\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.65 # This causes the LR to be 2e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 750])\n",
      "torch.Size([1, 750, 256])\n",
      "torch.Size([1, 7, 256])\n",
      "torch.Size([1, 7, 44])\n",
      "tensor([[[ 0.4648,  0.2252, -0.7298, -0.1633,  0.1543,  0.7997,  0.7714,\n",
      "          -0.3767, -0.0298, -0.1123,  0.3134, -0.0044,  0.8669,  0.6347,\n",
      "          -0.2052,  0.3185, -1.3403,  0.0363, -0.2123,  0.6981,  0.7101,\n",
      "           0.1066,  1.0624, -1.5129, -0.2120,  0.1658,  0.4270, -0.1416,\n",
      "           0.2197, -0.2524,  0.2754,  0.1417,  0.6042, -0.4900,  0.1448,\n",
      "          -0.7046, -0.7374,  0.0967, -0.7628,  0.1386,  0.0323, -0.9926,\n",
      "          -0.0522,  0.8933],\n",
      "         [-0.3992, -0.0509, -0.0180,  0.1279,  0.3200,  0.0432,  0.5092,\n",
      "           0.0205,  0.1142, -0.1747,  0.2441, -0.0703, -0.2902,  0.7650,\n",
      "          -0.1831, -0.4725, -1.2954, -0.6571, -1.0736,  0.2546,  0.3756,\n",
      "           0.2168,  0.9371, -0.7129,  0.6834, -0.1957,  0.1172, -0.2603,\n",
      "           0.0576,  0.3933,  0.1552, -0.0979,  1.2780, -0.7649,  0.0508,\n",
      "          -0.7701, -0.4351, -0.1240, -0.7158,  0.5540, -0.1512, -0.8305,\n",
      "          -0.2640,  0.9626],\n",
      "         [ 0.1863,  0.2432, -0.2752,  0.0895,  0.2752,  0.1176,  0.2087,\n",
      "          -0.4160, -0.3387,  0.2458,  0.3870, -0.2686,  0.4319,  0.2414,\n",
      "          -0.4135, -0.1955, -0.4558, -0.6785, -0.4870,  0.1691,  0.0932,\n",
      "          -0.6495,  0.8495, -0.7141,  0.1877, -0.6343,  0.0803,  0.0591,\n",
      "          -0.0965, -0.3672, -0.1527,  0.0520,  0.1951, -1.0202, -0.4516,\n",
      "          -0.7492,  0.4307, -0.2962, -0.2037,  0.2471, -0.8213, -1.2533,\n",
      "          -0.3900,  1.2624],\n",
      "         [-0.1006, -0.1421,  0.0341,  0.2444,  0.2680,  0.5861,  0.4273,\n",
      "          -0.3683,  0.5992, -0.3240,  0.2621,  0.6452, -0.6059,  0.4106,\n",
      "           0.6854, -0.9803, -1.1371, -0.1021, -1.5207,  0.2027,  0.5857,\n",
      "          -0.0045,  1.0953, -1.0223,  0.6318,  0.0085,  0.4251, -0.0706,\n",
      "           0.2946,  0.4665,  0.2393,  0.0150,  1.2905, -0.7208,  0.0074,\n",
      "          -0.9747, -0.1526, -0.1162, -0.8221,  0.8387, -0.0695, -1.1034,\n",
      "           0.1505,  1.1473],\n",
      "         [ 0.4344, -0.4949,  0.4220,  0.4255,  0.0231,  0.2355,  0.9145,\n",
      "          -0.3652, -0.3336, -0.4710,  0.6187, -0.5954,  0.2269,  0.2974,\n",
      "          -0.1968, -0.1195, -0.8464, -0.4366, -0.8014,  0.5381,  0.0054,\n",
      "          -0.4372,  1.1811, -0.6216, -0.2029, -0.0985,  1.0580,  0.0456,\n",
      "           0.1876, -0.0995, -0.4719,  0.1840,  0.9907, -0.2907, -0.5261,\n",
      "          -0.6461, -0.5484, -0.1157, -0.6453,  1.0108, -0.8187, -1.4249,\n",
      "           0.0605,  1.1907],\n",
      "         [ 0.6232,  0.3923,  0.3494,  0.3231,  0.3016,  0.7852,  0.0957,\n",
      "          -0.3648, -0.4591, -0.6431,  0.4352, -0.1922,  0.0725,  0.7127,\n",
      "           0.3473, -0.7606, -1.0392, -0.1928, -1.4070,  0.6290,  0.3017,\n",
      "           0.1921,  1.2168, -0.8687,  0.7804, -0.6908,  0.7134,  0.0700,\n",
      "          -0.5400,  0.3638,  0.2790,  0.0805,  0.9576, -0.8315,  0.4735,\n",
      "          -0.6917,  0.0702, -0.4929, -0.4981,  1.0587, -0.2978, -0.6331,\n",
      "           0.3704,  0.7309],\n",
      "         [ 0.3268,  0.0769,  0.0347,  0.1416,  0.4020,  0.6311,  0.4056,\n",
      "          -0.5004,  0.3908, -0.3629,  0.0947, -0.4002, -0.2786,  0.1614,\n",
      "           0.2114, -0.3728, -1.0059, -0.3491, -0.8522,  0.2651,  0.3182,\n",
      "          -0.1955,  0.9051, -1.1156,  0.4541, -0.5696,  0.3886, -0.5038,\n",
      "           0.0291,  0.5676, -0.2603, -0.2516,  1.4564, -0.7387,  0.0255,\n",
      "          -1.1723,  0.0280, -0.2988, -0.9257,  0.6992,  0.1231, -1.1554,\n",
      "           0.0086,  1.1477]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train_transformer(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('transformer-4-04.png')  # This will save the plot as an image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
