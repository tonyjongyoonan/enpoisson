{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlee0/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import utils\n",
    "import models\n",
    "import data_processing_utils\n",
    "\n",
    "importlib.reload(data_processing_utils)\n",
    "from data_processing_utils import *\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use the csv.format\n",
    "grouped_df = pd.read_csv('../data/haha-longer-longer-001.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/combined/vocab.pkl', 'rb') as inp:\n",
    "    vocab = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.id_to_move.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_sequences, fens, trainX, trainY, vocab = df_to_data(grouped_df[:1000], vocab, sampling_rate=1,color= 'w', with_checkmate = False)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    save_as_memmap(trainX, '../data/1500/black/trainX_boards.memmap'),\n",
    "    save_as_memmap(trainX_sequences, '../data/1500/black/trainX_sequences.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, '../data/1500/black/trainX_seqlengths.memmap'),\n",
    "    save_as_memmap(trainY, '../data/1500/black/trainY.memmap'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(fens, columns=['fens'])\n",
    "csv_filename = './../data/1500/black/fens.csv'\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fens = pd.read_csv('../data/1500/black/fens.csv')['fens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trainX\n",
    "dtype_trainX = np.bool_  # or the correct dtype for your data\n",
    "shape_trainX = (18568313, 12,8,8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/1500/black/trainX_boards.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64 # or the correct dtype for your data\n",
    "shape_trainY = (18568313,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/1500/black/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainX_seqlengths = np.int64 # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (18568313,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/1500/black/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainX_sequences = np.int64 # or the correct dtype for your data\n",
    "shape_trainX_sequences = (18568313, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/1500/black/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay):\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    val_3_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        training_loss = 0.0\n",
    "        # Training\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for boards, sequences, lengths, labels in train_loader:\n",
    "            count += 1\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "            # Forward Pass\n",
    "            output = model(boards, sequences, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            # Backpropogate & Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # For logging purposes\n",
    "            training_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            if count % 1000 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch: {count}| Training Loss: {training_loss/count}')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        validation_loss = 0.0\n",
    "        if val_loader is not None:\n",
    "            with torch.no_grad():\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                val_top3_correct = 0\n",
    "                validation_loss = 0\n",
    "\n",
    "                for boards, sequences, lengths, labels in val_loader:\n",
    "                    boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "                    outputs = model(boards, sequences, lengths)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_top3_correct += top_3_accuracy(labels, outputs) * labels.size(0)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    validation_loss += loss.item()\n",
    "\n",
    "                val_loss_values.append(validation_loss / len(val_loader))\n",
    "                val_accuracy = 100 * val_correct / val_total\n",
    "                val_top3_accuracy = 100 * val_top3_correct / val_total\n",
    "                val_error.append(100 - val_accuracy)\n",
    "                val_3_accuracy.append(val_top3_accuracy)\n",
    "\n",
    "        # Log Model Performance  \n",
    "        train_loss_values.append(training_loss)\n",
    "        train_error.append(100-100*train_correct/train_total)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_loss/len(train_loader)}, Validation Error: {val_error[-1]}, Validation Top-3 Accuracy: {val_3_accuracy[-1]}, Training Error: {train_error[-1]}')\n",
    "        if epoch <= 10:\n",
    "            for op_params in optimizer.param_groups:\n",
    "                op_params['lr'] = op_params['lr'] * learn_decay\n",
    "    return train_error,train_loss_values, val_error, val_loss_values\n",
    "\n",
    "def train_with_fen(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay, experiment_name):\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    val_3_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        training_loss = 0.0\n",
    "        # Training\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for boards, sequences, lengths, fens, labels in train_loader:\n",
    "            count += 1\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "            # Forward Pass\n",
    "            output = model(boards, sequences, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            # Backpropogate & Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # For logging purposes\n",
    "            training_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            if count % 1000 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch: {count}| Training Loss: {training_loss/count}')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        validation_loss = 0.0\n",
    "        if val_loader is not None:\n",
    "            with torch.no_grad():\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                val_top3_correct = 0\n",
    "                validation_loss = 0\n",
    "\n",
    "                for boards, sequences, lengths, fens, labels in val_loader:\n",
    "                    boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "                    outputs = model(boards, sequences, lengths)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_top3_correct += top_3_accuracy(labels, outputs) * labels.size(0)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    validation_loss += loss.item()\n",
    "\n",
    "                val_loss_values.append(validation_loss / len(val_loader))\n",
    "                val_accuracy = 100 * val_correct / val_total\n",
    "                val_top3_accuracy = 100 * val_top3_correct / val_total\n",
    "                val_error.append(100 - val_accuracy)\n",
    "                val_3_accuracy.append(val_top3_accuracy)\n",
    "\n",
    "        # Log Model Performance  \n",
    "        train_loss_values.append(training_loss)\n",
    "        train_error.append(100-100*train_correct/train_total)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_loss/len(train_loader)}, Validation Error: {val_error[-1]}, Validation Top-3 Accuracy: {val_3_accuracy[-1]}, Training Error: {train_error[-1]}')\n",
    "        for op_params in optimizer.param_groups:\n",
    "            op_params['lr'] = op_params['lr'] * learn_decay\n",
    "        torch.save(model.state_dict(), f'model_images/multimodalmodel-exp-{experiment_name}-checkpoint-{epoch}.pth')\n",
    "    return train_error,train_loss_values, val_error, val_loss_values\n",
    "\n",
    "\n",
    "def train_for_multi_transformer(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay):\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    val_3_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        training_loss = 0.0\n",
    "        # Training\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for boards, sequences, lengths, fens, labels in train_loader:\n",
    "            count += 1\n",
    "            boards, sequences, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            # Forward Pass\n",
    "            output = model(boards, sequences)\n",
    "            loss = criterion(output, labels)\n",
    "            # Backpropogate & Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            # For logging purposes\n",
    "            training_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            if count % 1000 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch: {count}| Training Loss: {training_loss/count} | Training Error: {train_correct/train_total}')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        validation_loss = 0.0\n",
    "        if val_loader is not None:\n",
    "            with torch.no_grad():\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                val_top3_correct = 0\n",
    "                validation_loss = 0\n",
    "\n",
    "                for boards, sequences, lengths, fens, labels in val_loader:\n",
    "                    boards, sequences, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                    outputs = model(boards, sequences)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_top3_correct += top_3_accuracy(labels, outputs) * labels.size(0)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    validation_loss += loss.item()\n",
    "\n",
    "                val_loss_values.append(validation_loss / len(val_loader))\n",
    "                val_accuracy = 100 * val_correct / val_total\n",
    "                val_top3_accuracy = 100 * val_top3_correct / val_total\n",
    "                val_error.append(100 - val_accuracy)\n",
    "                val_3_accuracy.append(val_top3_accuracy)\n",
    "\n",
    "        # Log Model Performance  \n",
    "        train_loss_values.append(training_loss)\n",
    "        train_error.append(100-100*train_correct/train_total)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_loss/len(train_loader)}, Validation Error: {val_error[-1]}, Validation Top-3 Accuracy: {val_3_accuracy[-1]}, Training Error: {train_error[-1]}')\n",
    "        for op_params in optimizer.param_groups:\n",
    "            op_params['lr'] = op_params['lr'] * learn_decay\n",
    "    return train_error,train_loss_values, val_error, val_loss_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26912\n"
     ]
    }
   ],
   "source": [
    "dataset = MultimodalDatasetWithFEN(trainX_sequences, trainX, trainX_seqlengths, fens, trainY)\n",
    "batch_size = 64\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_hidden = 256\n",
    "d_embed = 64\n",
    "NUM_EPOCHS = 7\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalSeven(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('model_images/multimodalmodel-exp-12-white-1500-checkpoint-8.pth',map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlee0/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jlee0/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jlee0/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jlee0/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jlee0/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jlee0/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "val_correct_3 = 0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "if val_loader is not None:\n",
    "    with torch.no_grad():\n",
    "        for boards, sequences, lengths, fens, labels in val_loader:\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "            outputs = model(boards, sequences, lengths)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            minus = 0\n",
    "            batch_correct = 0\n",
    "            for idx, (sequence, fen, label) in enumerate(zip(sequences, fens, labels)):\n",
    "                output = probabilities[idx]\n",
    "                sorted_probs, sorted_indices = torch.sort(output, descending=True)\n",
    "                chess_board = chess.Board(fen)\n",
    "                legal_moves_found = 0\n",
    "                correct_move_found_within_top_3 = False\n",
    "\n",
    "                for move_idx in sorted_indices:\n",
    "                    move = vocab.get_move(move_idx.item())  # Convert index to move\n",
    "                    if is_legal_move(chess_board, move):\n",
    "                        if legal_moves_found == 0:\n",
    "                            pred_move = vocab.get_id(move)\n",
    "                        if vocab.get_id(move) == label.item():  # Check if this legal move is the correct one\n",
    "                            correct_move_found_within_top_3 = True\n",
    "                            break\n",
    "                        legal_moves_found += 1\n",
    "                        if legal_moves_found == 3:  # Stop after finding top 3 legal moves\n",
    "                            break\n",
    "                if pred_move == label.item():\n",
    "                    batch_correct +=1\n",
    "                if correct_move_found_within_top_3:\n",
    "                    val_correct_3 += 1\n",
    "            val_correct += batch_correct\n",
    "            val_total += (labels.size(0) - minus)\n",
    "            if batch_correct/labels.size(0) > 0.75:\n",
    "                print(val_total)\n",
    "                break\n",
    "\n",
    "        val_accuracy = 100 * val_correct_3 / val_total\n",
    "        print(f\"Top-3 Validation Accuracy (with only legal moves allowed): {val_accuracy}%\")\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Top-1 Validation Accuracy (with only legal moves allowed): {val_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Most Up to Date Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7513159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the data with particular batch size\n",
    "torch.multiprocessing.set_start_method('fork', force=True)\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 256\n",
    "d_embed = 64\n",
    "NUM_EPOCHS = 20\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalSeven(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))\n",
    "\n",
    "model.load_state_dict(torch.load('model_images/multimodalmodel-exp-12-white-1500-checkpoint-8.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Validation Accuracy (with only legal moves allowed): 76.61637931034483%\n",
      "Top-1 Validation Accuracy (with only legal moves allowed): 48.00646551724138%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_correct_3 = 0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "if val_loader is not None:\n",
    "    with torch.no_grad():\n",
    "        for boards, sequences, lengths, fens, labels in val_loader:\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "            outputs = model(boards, sequences, lengths)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            minus = 0\n",
    "            for idx, (sequence, fen, label) in enumerate(zip(sequences, fens, labels)):\n",
    "                output = probabilities[idx]\n",
    "                sorted_probs, sorted_indices = torch.sort(output, descending=True)\n",
    "                chess_board = chess.Board(fen)\n",
    "                legal_moves_found = 0\n",
    "                correct_move_found_within_top_3 = False\n",
    "\n",
    "                for move_idx in sorted_indices:\n",
    "                    move = vocab.get_move(move_idx.item())  # Convert index to move\n",
    "                    if is_legal_move(chess_board, move):\n",
    "                        if legal_moves_found == 0:\n",
    "                            pred_move = vocab.get_id(move)\n",
    "                        if vocab.get_id(move) == label.item():  # Check if this legal move is the correct one\n",
    "                            correct_move_found_within_top_3 = True\n",
    "                            break\n",
    "                        legal_moves_found += 1\n",
    "                        if legal_moves_found == 3:  # Stop after finding top 3 legal moves\n",
    "                            break\n",
    "                if pred_move == label.item():\n",
    "                    val_correct +=1\n",
    "                if correct_move_found_within_top_3:\n",
    "                    val_correct_3 += 1\n",
    "            val_total += (labels.size(0) - minus)\n",
    "\n",
    "        val_accuracy = 100 * val_correct_3 / val_total\n",
    "        print(f\"Top-3 Validation Accuracy (with only legal moves allowed): {val_accuracy}%\")\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Top-1 Validation Accuracy (with only legal moves allowed): {val_accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
