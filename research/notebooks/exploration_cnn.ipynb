{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Games of Elo ~1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "import dask.dataframe as dd \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import chess\n",
    "import random\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV File (from Maia: http://csslab.cs.toronto.edu/datasets/#monthly_chess_csv)\n",
    "# The CSV has 151,072,060 rows\n",
    "data_types ={'clock': 'float32',\n",
    "       'cp': 'object',\n",
    "       'opp_clock': 'float32',\n",
    "       'opp_clock_percent': 'float32'}\n",
    "df = dd.read_csv('../data/lichess_db_standard_rated_2019-01.csv', blocksize='64e6', dtype= data_types, low_memory=False)\n",
    "\n",
    "# Filter out quick games (Bullet and HyperBullet) and take out moves that happened in the last XX seconds (this won't affect how many games we import but the # of moves we look at)\n",
    "condition_time_control = ~df['time_control'].isin(['Bullet', 'HyperBullet'])\n",
    "condition_clock = df['clock'] > 45\n",
    "# condition_plays = df['num_ply'] < 80\n",
    "filtered_df = df[condition_time_control & condition_clock]\n",
    "\n",
    "# Select Relevant Columns\n",
    "selected_columns = ['game_id','white_elo','black_elo','move','white_active','board']\n",
    "filtered_df = filtered_df[selected_columns]\n",
    "\n",
    "# Filter only games of Elo 1100-1199\n",
    "filtered_df = filtered_df[(filtered_df['white_elo'].between(1100, 1199)) & (filtered_df['black_elo'].between(1100, 1199))]\n",
    "\n",
    "# Group Same Games Together \n",
    "def aggregate_moves(group):\n",
    "    moves = ' '.join(group['move'])  # Concatenate moves into a single string\n",
    "    white_elo = group['white_elo'].iloc[0]  # Get the first white_elo\n",
    "    black_elo = group['black_elo'].iloc[0]  # Get the first black_elo\n",
    "    white_active = group['white_active'].iloc[0]  # Get the first num_ply\n",
    "    board = '*'.join(group['board'])  # Get the first num_ply\n",
    "    return pd.Series({'moves': moves, 'white_elo': white_elo, 'black_elo': black_elo, 'white_active': white_active, 'board': board})\n",
    "\n",
    "grouped_df = filtered_df.groupby('game_id',sort=True).apply(aggregate_moves, meta={'moves': 'str', 'white_elo': 'int', 'black_elo': 'int', 'white_active': 'str', 'board': 'str'}).compute()\n",
    "\n",
    "# This gives us 99,300 Games when we don't filter games with more than 80 half-moves\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         game_id  white_elo  black_elo  move  white_active  \\\n",
      "1223    MpE9bxRV       1180       1125  e2e4          True   \n",
      "1224    MpE9bxRV       1180       1125  e7e5         False   \n",
      "1225    MpE9bxRV       1180       1125  g1f3          True   \n",
      "1226    MpE9bxRV       1180       1125  f7f6         False   \n",
      "1227    MpE9bxRV       1180       1125  f1b5          True   \n",
      "...          ...        ...        ...   ...           ...   \n",
      "226499  L7OPs0AX       1160       1166  d7c8         False   \n",
      "226500  L7OPs0AX       1160       1166  e4e5          True   \n",
      "226501  L7OPs0AX       1160       1166  d6c5         False   \n",
      "226502  L7OPs0AX       1160       1166  h5f5          True   \n",
      "226504  L7OPs0AX       1160       1166  c3e4          True   \n",
      "\n",
      "                                                    board  \n",
      "1223    rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "1224    rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...  \n",
      "1225    rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBN...  \n",
      "1226    rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQK...  \n",
      "1227    rnbqkbnr/pppp2pp/5p2/4p3/4P3/5N2/PPPP1PPP/RNBQ...  \n",
      "...                                                   ...  \n",
      "226499  3r3r/p2kp2p/2pq3B/1p3p1Q/3bPP2/1BN5/PP4PP/3R1K...  \n",
      "226500  2kr3r/p3p2p/2pq3B/1p3p1Q/3bPP2/1BN5/PP4PP/3R1K...  \n",
      "226501  2kr3r/p3p2p/2pq3B/1p2Pp1Q/3b1P2/1BN5/PP4PP/3R1...  \n",
      "226502  2kr3r/p3p2p/2p4B/1pq1Pp1Q/3b1P2/1BN5/PP4PP/3R1...  \n",
      "226504  1k1r3r/p3p2p/2p4B/1pq1PQ2/3b1P2/1BN5/PP4PP/3R1...  \n",
      "\n",
      "[4875655 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv('haha_longer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      moves  white_elo  \\\n",
      "game_id                                                                  \n",
      "001QYJhZ  d2d4 f7f6 c2c4 e7e5 d4e5 f6e5 e2e3 b8c6 b1c3 f...       1127   \n",
      "0073Uoft  e2e4 e7e5 g1f3 b8c6 f1c4 g8f6 f3g5 d7d5 g5f7 e...       1142   \n",
      "008AlITg  e2e4 e7e5 g1f3 b8c6 b1c3 g8f6 f3e5 f8b4 e5c6 d...       1187   \n",
      "00911g2y  e2e4 d7d5 e4d5 d8d5 g1f3 d5a5 b1c3 g8f6 d2d4 c...       1135   \n",
      "00A6eGbe  b2b4 e7e5 c1b2 g8f6 b2e5 b8c6 e5c3 d7d5 d2d4 f...       1112   \n",
      "...                                                     ...        ...   \n",
      "zzo2DSPt  d2d4 g8f6 c1f4 g7g6 g1f3 f8g7 b1c3 e8g8 e2e3 d...       1141   \n",
      "zzo5kmuO  e2e4 e7e5 g1f3 d7d6 b1c3 c8g4 f1e2 g4f3 e2f3 d...       1112   \n",
      "zztPJDK8  e2e4 c7c5 g1f3 b8c6 f1c4 e7e6 d2d3 d7d5 e4d5 e...       1178   \n",
      "zzx4qVJx  e2e3 d7d5 f2f4 g8f6 b2b3 e7e6 c1b2 f6e4 g2g4 d...       1197   \n",
      "zzxkXY9h  d2d4 d7d5 g1f3 g8f6 c1f4 b8c6 e2e3 c8f5 f1b5 f...       1140   \n",
      "\n",
      "          black_elo  white_active  \\\n",
      "game_id                             \n",
      "001QYJhZ       1165          True   \n",
      "0073Uoft       1179          True   \n",
      "008AlITg       1168          True   \n",
      "00911g2y       1126          True   \n",
      "00A6eGbe       1107          True   \n",
      "...             ...           ...   \n",
      "zzo2DSPt       1149          True   \n",
      "zzo5kmuO       1123          True   \n",
      "zztPJDK8       1151          True   \n",
      "zzx4qVJx       1197          True   \n",
      "zzxkXY9h       1124          True   \n",
      "\n",
      "                                                      board  \n",
      "game_id                                                      \n",
      "001QYJhZ  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "0073Uoft  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "008AlITg  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "00911g2y  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "00A6eGbe  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "...                                                     ...  \n",
      "zzo2DSPt  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "zzo5kmuO  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "zztPJDK8  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "zzx4qVJx  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "zzxkXY9h  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "\n",
      "[99295 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2e4\n",
      "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
      "e7e6\n",
      "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1\n",
      "g1f3\n",
      "rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2\n",
      "f7f6\n",
      "rnbqkbnr/pppp1ppp/4p3/8/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2\n",
      "d2d4\n",
      "rnbqkbnr/pppp2pp/4pp2/8/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 0 3\n",
      "f8d6\n",
      "rnbqkbnr/pppp2pp/4pp2/8/3PP3/5N2/PPP2PPP/RNBQKB1R b KQkq - 0 3\n",
      "c2c4\n",
      "rnbqk1nr/pppp2pp/3bpp2/8/3PP3/5N2/PPP2PPP/RNBQKB1R w KQkq - 1 4\n",
      "c7c6\n",
      "rnbqk1nr/pppp2pp/3bpp2/8/2PPP3/5N2/PP3PPP/RNBQKB1R b KQkq - 0 4\n",
      "h2h3\n",
      "rnbqk1nr/pp1p2pp/2pbpp2/8/2PPP3/5N2/PP3PPP/RNBQKB1R w KQkq - 0 5\n",
      "b7b6\n",
      "rnbqk1nr/pp1p2pp/2pbpp2/8/2PPP3/5N1P/PP3PP1/RNBQKB1R b KQkq - 0 5\n",
      "b1c3\n",
      "rnbqk1nr/p2p2pp/1ppbpp2/8/2PPP3/5N1P/PP3PP1/RNBQKB1R w KQkq - 0 6\n",
      "c8a6\n",
      "rnbqk1nr/p2p2pp/1ppbpp2/8/2PPP3/2N2N1P/PP3PP1/R1BQKB1R b KQkq - 1 6\n",
      "b2b3\n",
      "rn1qk1nr/p2p2pp/bppbpp2/8/2PPP3/2N2N1P/PP3PP1/R1BQKB1R w KQkq - 2 7\n",
      "c6c5\n",
      "rn1qk1nr/p2p2pp/bppbpp2/8/2PPP3/1PN2N1P/P4PP1/R1BQKB1R b KQkq - 0 7\n",
      "d4d5\n",
      "rn1qk1nr/p2p2pp/bp1bpp2/2p5/2PPP3/1PN2N1P/P4PP1/R1BQKB1R w KQkq - 0 8\n",
      "d5e6\n",
      "rn1qk2r/p2pn1pp/bp1bpp2/2pP4/2P1P3/1PN2N1P/P4PP1/R1BQKB1R w KQkq - 1 9\n",
      "b3b4\n",
      "rn1qk2r/p3n1pp/bp1bpp2/2p5/2P1P3/1PN2N1P/P4PP1/R1BQKB1R w KQkq - 0 10\n",
      "c3a4\n",
      "rn1qk2r/p3n1pp/bp1bpp2/8/1pP1P3/2N2N1P/P4PP1/R1BQKB1R w KQkq - 0 11\n",
      "new game\n",
      "e2e4\n",
      "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
      "d7d5\n",
      "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1\n",
      "d2d4\n",
      "rnbqkbnr/ppp1pppp/8/3p4/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2\n",
      "d5e4\n",
      "rnbqkbnr/ppp1pppp/8/3p4/3PP3/8/PPP2PPP/RNBQKBNR b KQkq - 0 2\n",
      "c2c3\n",
      "rnbqkbnr/ppp1pppp/8/8/3Pp3/8/PPP2PPP/RNBQKBNR w KQkq - 0 3\n",
      "h7h5\n",
      "rnbqkbnr/ppp1pppp/8/8/3Pp3/2P5/PP3PPP/RNBQKBNR b KQkq - 0 3\n",
      "b1d2\n",
      "rnbqkbnr/ppp1ppp1/8/7p/3Pp3/2P5/PP3PPP/RNBQKBNR w KQkq - 0 4\n",
      "g8f6\n",
      "rnbqkbnr/ppp1ppp1/8/7p/3Pp3/2P5/PP1N1PPP/R1BQKBNR b KQkq - 1 4\n",
      "d1c2\n",
      "rnbqkb1r/ppp1ppp1/5n2/7p/3Pp3/2P5/PP1N1PPP/R1BQKBNR w KQkq - 2 5\n",
      "c8f5\n",
      "rnbqkb1r/ppp1ppp1/5n2/7p/3Pp3/2P5/PPQN1PPP/R1B1KBNR b KQkq - 3 5\n",
      "f1e2\n",
      "rn1qkb1r/ppp1ppp1/5n2/5b1p/3Pp3/2P5/PPQN1PPP/R1B1KBNR w KQkq - 4 6\n",
      "e7e6\n",
      "rn1qkb1r/ppp1ppp1/5n2/5b1p/3Pp3/2P5/PPQNBPPP/R1B1K1NR b KQkq - 5 6\n",
      "f2f3\n",
      "rn1qkb1r/ppp2pp1/4pn2/5b1p/3Pp3/2P5/PPQNBPPP/R1B1K1NR w KQkq - 0 7\n",
      "e4e3\n",
      "rn1qkb1r/ppp2pp1/4pn2/5b1p/3Pp3/2P2P2/PPQNB1PP/R1B1K1NR b KQkq - 0 7\n",
      "d2e4\n",
      "rn1qkb1r/ppp2pp1/4pn2/5b1p/3P4/2P1pP2/PPQNB1PP/R1B1K1NR w KQkq - 0 8\n",
      "f5e4\n",
      "rn1qkb1r/ppp2pp1/4pn2/5b1p/3PN3/2P1pP2/PPQ1B1PP/R1B1K1NR b KQkq - 1 8\n",
      "f3e4\n",
      "rn1qkb1r/ppp2pp1/4pn2/7p/3Pb3/2P1pP2/PPQ1B1PP/R1B1K1NR w KQkq - 0 9\n",
      "a7a5\n",
      "rn1qkb1r/ppp2pp1/4pn2/7p/3PP3/2P1p3/PPQ1B1PP/R1B1K1NR b KQkq - 0 9\n",
      "g1f3\n",
      "rn1qkb1r/1pp2pp1/4pn2/p6p/3PP3/2P1p3/PPQ1B1PP/R1B1K1NR w KQkq - 0 10\n",
      "f6g4\n",
      "rn1qkb1r/1pp2pp1/4pn2/p6p/3PP3/2P1pN2/PPQ1B1PP/R1B1K2R b KQkq - 1 10\n",
      "e4e5\n",
      "rn1qkb1r/1pp2pp1/4p3/p6p/3PP1n1/2P1pN2/PPQ1B1PP/R1B1K2R w KQkq - 2 11\n",
      "g4f2\n",
      "rn1qkb1r/1pp2pp1/4p3/p3P2p/3P2n1/2P1pN2/PPQ1B1PP/R1B1K2R b KQkq - 0 11\n",
      "h1f1\n",
      "rn1qkb1r/1pp2pp1/4p3/p3P2p/3P4/2P1pN2/PPQ1BnPP/R1B1K2R w KQkq - 1 12\n",
      "f7f5\n",
      "rn1qkb1r/1pp2pp1/4p3/p3P2p/3P4/2P1pN2/PPQ1BnPP/R1B1KR2 b Qkq - 2 12\n",
      "c1e3\n",
      "rn1qkb1r/1pp3p1/4p3/p3Pp1p/3P4/2P1pN2/PPQ1BnPP/R1B1KR2 w Qkq f6 0 13\n",
      "f2g4\n",
      "rn1qkb1r/1pp3p1/4p3/p3Pp1p/3P4/2P1BN2/PPQ1BnPP/R3KR2 b Qkq - 0 13\n",
      "e3g5\n",
      "rn1qkb1r/1pp3p1/4p3/p3Pp1p/3P2n1/2P1BN2/PPQ1B1PP/R3KR2 w Qkq - 1 14\n",
      "f8e7\n",
      "rn1qkb1r/1pp3p1/4p3/p3PpBp/3P2n1/2P2N2/PPQ1B1PP/R3KR2 b Qkq - 2 14\n",
      "c2b3\n",
      "rn1qk2r/1pp1b1p1/4p3/p3PpBp/3P2n1/2P2N2/PPQ1B1PP/R3KR2 w Qkq - 3 15\n",
      "e7g5\n",
      "rn1qk2r/1pp1b1p1/4p3/p3PpBp/3P2n1/1QP2N2/PP2B1PP/R3KR2 b Qkq - 4 15\n",
      "b3b7\n",
      "rn1qk2r/1pp3p1/4p3/p3Ppbp/3P2n1/1QP2N2/PP2B1PP/R3KR2 w Qkq - 0 16\n",
      "b8d7\n",
      "rn1qk2r/1Qp3p1/4p3/p3Ppbp/3P2n1/2P2N2/PP2B1PP/R3KR2 b Qkq - 0 16\n",
      "e2b5\n",
      "r2qk2r/1Qpn2p1/4p3/p3Ppbp/3P2n1/2P2N2/PP2B1PP/R3KR2 w Qkq - 1 17\n",
      "a8b8\n",
      "r2qk2r/1Qpn2p1/4p3/pB2Ppbp/3P2n1/2P2N2/PP4PP/R3KR2 b Qkq - 2 17\n",
      "b7c6\n",
      "1r1qk2r/1Qpn2p1/4p3/pB2Ppbp/3P2n1/2P2N2/PP4PP/R3KR2 w Qk - 3 18\n",
      "e8g8\n",
      "1r1qk2r/2pn2p1/2Q1p3/pB2Ppbp/3P2n1/2P2N2/PP4PP/R3KR2 b Qk - 4 18\n",
      "f3g5\n",
      "1r1q1rk1/2pn2p1/2Q1p3/pB2Ppbp/3P2n1/2P2N2/PP4PP/R3KR2 w Q - 5 19\n",
      "g4e3\n",
      "1r1q1rk1/2pn2p1/2Q1p3/pB2PpNp/3P2n1/2P5/PP4PP/R3KR2 b Q - 0 19\n",
      "g5e6\n",
      "1r1q1rk1/2pn2p1/2Q1p3/pB2PpNp/3P4/2P1n3/PP4PP/R3KR2 w Q - 1 20\n",
      "d8e8\n",
      "1r1q1rk1/2pn2p1/2Q1N3/pB2Pp1p/3P4/2P1n3/PP4PP/R3KR2 b Q - 0 20\n",
      "f1f3\n",
      "1r2qrk1/2pn2p1/2Q1N3/pB2Pp1p/3P4/2P1n3/PP4PP/R3KR2 w Q - 1 21\n",
      "e3c2\n",
      "1r2qrk1/2pn2p1/2Q1N3/pB2Pp1p/3P4/2P1nR2/PP4PP/R3K3 b Q - 2 21\n",
      "e1d2\n",
      "1r2qrk1/2pn2p1/2Q1N3/pB2Pp1p/3P4/2P2R2/PPn3PP/R3K3 w Q - 3 22\n",
      "c2a1\n",
      "1r2qrk1/2pn2p1/2Q1N3/pB2Pp1p/3P4/2P2R2/PPnK2PP/R7 b - - 4 22\n",
      "e6f8\n",
      "1r2qrk1/2pn2p1/2Q1N3/pB2Pp1p/3P4/2P2R2/PP1K2PP/n7 w - - 0 23\n",
      "d7f8\n",
      "1r2qNk1/2pn2p1/2Q5/pB2Pp1p/3P4/2P2R2/PP1K2PP/n7 b - - 0 23\n",
      "f3f5\n",
      "1r2qnk1/2p3p1/2Q5/pB2Pp1p/3P4/2P2R2/PP1K2PP/n7 w - - 0 24\n",
      "e8c6\n",
      "1r2qnk1/2p3p1/2Q5/pB2PR1p/3P4/2P5/PP1K2PP/n7 b - - 0 24\n",
      "b5c6\n",
      "1r3nk1/2p3p1/2q5/pB2PR1p/3P4/2P5/PP1K2PP/n7 w - - 0 25\n",
      "b8b2\n",
      "1r3nk1/2p3p1/2B5/p3PR1p/3P4/2P5/PP1K2PP/n7 b - - 0 25\n",
      "d2d3\n",
      "5nk1/2p3p1/2B5/p3PR1p/3P4/2P5/Pr1K2PP/n7 w - - 0 26\n",
      "b2g2\n",
      "5nk1/2p3p1/2B5/p3PR1p/3P4/2PK4/Pr4PP/n7 b - - 1 26\n",
      "c6g2\n",
      "5nk1/2p3p1/2B5/p3PR1p/3P4/2PK4/P5rP/n7 w - - 0 27\n",
      "g7g6\n",
      "5nk1/2p3p1/8/p3PR1p/3P4/2PK4/P5BP/n7 b - - 0 27\n",
      "f5f6\n",
      "5nk1/2p5/6p1/p3PR1p/3P4/2PK4/P5BP/n7 w - - 0 28\n",
      "g8g7\n",
      "5nk1/2p5/5Rp1/p3P2p/3P4/2PK4/P5BP/n7 b - - 1 28\n",
      "g2e4\n",
      "5n2/2p3k1/5Rp1/p3P2p/3P4/2PK4/P5BP/n7 w - - 2 29\n",
      "f8h7\n",
      "5n2/2p3k1/5Rp1/p3P2p/3PB3/2PK4/P6P/n7 b - - 3 29\n",
      "f6c6\n",
      "8/2p3kn/5Rp1/p3P2p/3PB3/2PK4/P6P/n7 w - - 4 30\n",
      "h7g5\n",
      "8/2p3kn/2R3p1/p3P2p/3PB3/2PK4/P6P/n7 b - - 5 30\n",
      "e4g6\n",
      "8/2p3k1/2R3p1/p3P1np/3PB3/2PK4/P6P/n7 w - - 6 31\n",
      "g5f3\n",
      "8/2p3k1/2R3B1/p3P1np/3P4/2PK4/P6P/n7 b - - 0 31\n",
      "e5e6\n",
      "8/2p3k1/2R3B1/p3P2p/3P4/2PK1n2/P6P/n7 w - - 1 32\n",
      "g7f8\n",
      "8/2p3k1/2R1P1B1/p6p/3P4/2PK1n2/P6P/n7 b - - 0 32\n",
      "c6c7\n",
      "5k2/2p5/2R1P1B1/p6p/3P4/2PK1n2/P6P/n7 w - - 1 33\n",
      "f3e1\n",
      "5k2/2R5/4P1B1/p6p/3P4/2PK1n2/P6P/n7 b - - 0 33\n",
      "d3c4\n",
      "5k2/2R5/4P1B1/p6p/3P4/2PK4/P6P/n3n3 w - - 1 34\n",
      "e1d3\n",
      "5k2/2R5/4P1B1/p6p/2KP4/2P5/P6P/n3n3 b - - 2 34\n",
      "e6e7\n",
      "5k2/2R5/4P1B1/p6p/2KP4/2Pn4/P6P/n7 w - - 3 35\n",
      "f8g7\n",
      "5k2/2R1P3/6B1/p6p/2KP4/2Pn4/P6P/n7 b - - 0 35\n",
      "e7e8q\n",
      "8/2R1P1k1/6B1/p6p/2KP4/2Pn4/P6P/n7 w - - 1 36\n",
      "g7h6\n",
      "4Q3/2R3k1/6B1/p6p/2KP4/2Pn4/P6P/n7 b - - 0 36\n",
      "e8e3\n",
      "4Q3/2R5/6Bk/p6p/2KP4/2Pn4/P6P/n7 w - - 1 37\n",
      "h6g6\n",
      "8/2R5/6Bk/p6p/2KP4/2PnQ3/P6P/n7 b - - 2 37\n",
      "e3d3\n",
      "8/2R5/6k1/p6p/2KP4/2PnQ3/P6P/n7 w - - 0 38\n",
      "g6g5\n",
      "8/2R5/6k1/p6p/2KP4/2PQ4/P6P/n7 b - - 0 38\n",
      "c7c5\n",
      "8/2R5/8/p5kp/2KP4/2PQ4/P6P/n7 w - - 1 39\n",
      "g5f4\n",
      "8/8/8/p1R3kp/2KP4/2PQ4/P6P/n7 b - - 2 39\n",
      "c5h5\n",
      "8/8/8/p1R4p/2KP1k2/2PQ4/P6P/n7 w - - 3 40\n",
      "f4g4\n",
      "8/8/8/p6R/2KP1k2/2PQ4/P6P/n7 b - - 0 40\n",
      "d3g6\n",
      "8/8/8/p6R/2KP2k1/2PQ4/P6P/n7 w - - 1 41\n",
      "g4f3\n",
      "8/8/6Q1/p6R/2KP2k1/2P5/P6P/n7 b - - 2 41\n",
      "h5f5\n",
      "8/8/6Q1/p6R/2KP4/2P2k2/P6P/n7 w - - 3 42\n",
      "f3e3\n",
      "8/8/6Q1/p4R2/2KP4/2P2k2/P6P/n7 b - - 4 42\n",
      "g6e6\n",
      "8/8/6Q1/p4R2/2KP4/2P1k3/P6P/n7 w - - 5 43\n",
      "e3d2\n",
      "8/8/4Q3/p4R2/2KP4/2P1k3/P6P/n7 b - - 6 43\n",
      "f5f2\n",
      "8/8/4Q3/p4R2/2KP4/2P5/P2k3P/n7 w - - 7 44\n",
      "d2c1\n",
      "8/8/4Q3/p7/2KP4/2P5/P2k1R1P/n7 b - - 8 44\n",
      "e6e1\n",
      "8/8/4Q3/p7/2KP4/2P5/P4R1P/n1k5 w - - 9 45\n",
      "new game\n"
     ]
    }
   ],
   "source": [
    "# Line by line reading the data -> there are some broken lines\n",
    "for move,board in (zip(grouped_df['moves'][20:22],grouped_df['board'][20:22])):\n",
    "    for a,b in zip(move.split(' '),board.split('*')):\n",
    "        print(a)\n",
    "        print(b)\n",
    "    print(\"new game\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our raw data, we need to be able to make sense of chess moves. Meaning, we're transforming our entire world from chess moves into numerical tokens that will serve as indices into unique embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, generate a mapping from each move to a unique embedding. In order to index into our matrix of \n",
    "# embeddings (matrix format so it's something we can tune), we'll also want a mapping from each move to a unique ID\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.move_to_id = {\"<UNK>\": 0}\n",
    "        self.id_to_move = {0: \"<UNK>\"}\n",
    "        self.index = 1  # Start indexing from 1\n",
    "\n",
    "    def add_move(self, move):\n",
    "        if move not in self.move_to_id:\n",
    "            self.move_to_id[move] = self.index\n",
    "            self.id_to_move[self.index] = move\n",
    "            self.index += 1\n",
    "\n",
    "    def get_id(self, move):\n",
    "        return self.move_to_id.get(move, self.move_to_id[\"<UNK>\"])\n",
    "\n",
    "    def get_move(self, id):\n",
    "        return self.id_to_move.get(id, self.id_to_move[0])\n",
    "\n",
    "# We can just use nn.Embedding later when we pass the model a sequence of indices, but this is if we ever want to pre-train and have access to the matrix we've trained\n",
    "def get_embedding_matrix(vocab, d_embed):\n",
    "    n_embed = len(vocab.move_to_id)\n",
    "    return np.random.normal(0, 1, (n_embed, d_embed))\n",
    "# embedding_matrix = get_embedding_matrix(vocab, 64)\n",
    "    \n",
    "# Now let's turn our data into sequences of indices instead of chess moves\n",
    "\n",
    "# Function to convert games to a list of lists in which each list represents the move sequence of a game\n",
    "def df_to_list_of_games(df, vocab_map):\n",
    "    sequences = []\n",
    "    for game in df['moves']:\n",
    "        moves = game.split()\n",
    "        seq = [vocab_map.get_id(move) for move in moves]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "def df_to_subsequences_and_labels(df, vocab_map, fixed_window=False, fixed_window_size=32, sampling_rate=1):\n",
    "    subsequences = []\n",
    "    next_moves = []\n",
    "\n",
    "    for game in df['moves']:\n",
    "        moves = game.split()\n",
    "        encoded_moves = [vocab_map.get_id(move) for move in moves]\n",
    "\n",
    "        for i in range(len(encoded_moves)-1):\n",
    "            # Generate a random number and compare with sampling rate\n",
    "            if random.uniform(0, 1) <= sampling_rate:\n",
    "                subseq = encoded_moves[0:i+1]\n",
    "                \n",
    "                if fixed_window and len(subseq) > fixed_window_size:\n",
    "                    subseq = subseq[-fixed_window_size:]\n",
    "\n",
    "                label = encoded_moves[i+1]\n",
    "                subsequences.append(subseq)\n",
    "                next_moves.append(label)\n",
    "\n",
    "    return subsequences, next_moves\n",
    "\n",
    "# Broken\n",
    "def df_to_data(df, fixed_window=False, fixed_window_size=32, sampling_rate=1):\n",
    "    \"\"\"\n",
    "    Input: Dataframe of training data in which each row represents a full game played between players\n",
    "    Output: List in which each item represents some game's history up until a particular move, List in the same order in which the associated label is the following move\n",
    "    \"\"\"\n",
    "    subsequences = []\n",
    "    next_moves = []\n",
    "    vocab = Vocabulary()\n",
    "    board = chess.Board()\n",
    "    for game in df['moves']:\n",
    "        # Turn the game into a list of SAN notation moves\n",
    "        moves = game.split()\n",
    "        encoded_moves = []\n",
    "        for move in moves:\n",
    "            # Create a move object from the coordinate notation\n",
    "            move_obj = chess.Move.from_uci(move)\n",
    "            if move_obj not in board.legal_moves:\n",
    "                break \n",
    "            else:\n",
    "                algebraic_move = board.san(move_obj)\n",
    "                board.push(move_obj)\n",
    "                vocab.add_move(algebraic_move)\n",
    "                encoded_move = vocab.get_id(algebraic_move)\n",
    "                encoded_moves.append(encoded_move)\n",
    "        board.reset()\n",
    "        # Turn the list of moves into subsequences\n",
    "        for i in range(len(encoded_moves)-1):\n",
    "            if random.uniform(0, 1) <= sampling_rate:\n",
    "                subseq = encoded_moves[0:i+1]\n",
    "                if fixed_window and len(subseq) > fixed_window_size:\n",
    "                    subseq = subseq[-fixed_window_size:]\n",
    "                label = encoded_moves[i+1]\n",
    "                subsequences.append(subseq)\n",
    "                next_moves.append(label)\n",
    "\n",
    "    return subsequences, next_moves, vocab\n",
    "\n",
    "# Function to pad move sequences & get their sequence lengths\n",
    "def pad_sequences(sequences, max_len=None, pad_id=0):\n",
    "    if max_len is None:\n",
    "        max_len = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = np.full((len(sequences), max_len), pad_id, dtype=int)\n",
    "    sequence_lengths = np.zeros(len(sequences), dtype=int)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = seq[:length]\n",
    "        sequence_lengths[i] = length\n",
    "    return padded_sequences, sequence_lengths\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, lengths, labels):\n",
    "        self.sequences = sequences\n",
    "        self.lengths = lengths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.lengths[idx], self.labels[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, vocab = df_to_data(grouped_df, fixed_window=True, sampling_rate=0.25)\n",
    "trainX, trainX_seqlengths  = pad_sequences(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7593\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab.id_to_move.keys()))\n",
    "print(len(trainX[140]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Note: The input to the Embedding module is a list of indices, and the output is the corresponding word embeddings.\"\"\"\n",
    "# Bi-LSTM Model for PyTorch\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab, d_embed, d_hidden, d_out, dropout = 0.5, num_layers = 2, bidirectional = False, embedding_matrix = None):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(len(vocab.move_to_id), d_embed)\n",
    "        # self.embeddings = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        self.lstm = nn.LSTM(d_embed, d_hidden, dropout = dropout, bidirectional=bidirectional, num_layers = num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * d_hidden,d_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, seq_lengths):\n",
    "        x = self.embeddings(x)\n",
    "        # Sort x and seq_lengths in descending order\n",
    "        # This is required for packing the sequence\n",
    "        seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "        x = x[perm_idx]\n",
    "        # Pack the sequence\n",
    "        packed_input = pack_padded_sequence(x, seq_lengths, batch_first=True)\n",
    "        # Pass the packed sequence through the LSTM\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "\n",
    "        # Unpack the sequence\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True,total_length = x.size()[1])\n",
    "        _, unperm_idx = perm_idx.sort(0)\n",
    "        #unperm_idx = unperm_idx.to(self.device)\n",
    "        output = output.index_select(0, unperm_idx)\n",
    "        #This takes all the outputs across the cells\n",
    "        mean_pooled = torch.mean(output, dim=1)\n",
    "        output = torch.cat((mean_pooled,hidden[-1]),dim=1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.swa_utils import AveragedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate top-3 accuracy\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    top3 = torch.topk(y_pred, 3, dim=1).indices\n",
    "    correct = top3.eq(y_true.view(-1, 1).expand_as(top3))\n",
    "    return correct.any(dim=1).float().mean().item()\n",
    "\n",
    "def train_rnn(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay):\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    val_3_accuracy = []\n",
    "    swa_model = AveragedModel(model)\n",
    "    swa_start = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        training_loss = 0.0\n",
    "        # Training\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for sequences, lengths, labels in train_loader:\n",
    "            count += 1\n",
    "            sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
    "            # Forward Pass\n",
    "            output = model(sequences, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            # Backpropogate & Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # For logging purposes\n",
    "            training_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            if count % 1000 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch: {count}| Training Loss: {training_loss/count}')\n",
    "        if epoch >= swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "        torch.optim.swa_utils.update_bn(train_loader, swa_model)\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        validation_loss = 0.0\n",
    "        if val_loader is not None:\n",
    "            with torch.no_grad():\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                val_top3_correct = 0\n",
    "                validation_loss = 0\n",
    "\n",
    "                for sequences, lengths, labels in val_loader:\n",
    "                    sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
    "                    outputs = model(sequences, lengths)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_top3_correct += top_3_accuracy(labels, outputs) * labels.size(0)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    validation_loss += loss.item()\n",
    "\n",
    "                val_loss_values.append(validation_loss / len(val_loader))\n",
    "                val_accuracy = 100 * val_correct / val_total\n",
    "                val_top3_accuracy = 100 * val_top3_correct / val_total\n",
    "                val_error.append(100 - val_accuracy)\n",
    "                val_3_accuracy.append(val_top3_accuracy)\n",
    "\n",
    "        # Log Model Performance  \n",
    "        train_loss_values.append(training_loss)\n",
    "        train_error.append(100-100*train_correct/train_total)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_loss/len(train_loader)}, Validation Error: {val_error[-1]}, Validation Top-3 Accuracy: {val_3_accuracy[-1]}, Training Error: {train_error[-1]}')\n",
    "        for op_params in optimizer.param_groups:\n",
    "            op_params['lr'] = op_params['lr'] * learn_decay\n",
    "    return train_error,train_loss_values, val_error, val_loss_values, swa_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193465\n"
     ]
    }
   ],
   "source": [
    "dataset = SequenceDataset(trainX, trainX_seqlengths, trainY)\n",
    "# Calculate split sizes\n",
    "total_size = len(dataset)\n",
    "print(total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 128\n",
    "d_embed = 128\n",
    "NUM_EPOCHS = 10\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = RNNModel(vocab,d_embed,d_hidden,d_out,num_layers=2) \n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 2e-3\n",
    "weight_decay=0\n",
    "learn_decay = 0.5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value,swa_model = train_rnn(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('validation_error_model_rnn.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074118\n"
     ]
    }
   ],
   "source": [
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.9 * total_size)\n",
    "val_size = int(total_size * 0.04)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997232\n"
     ]
    }
   ],
   "source": [
    "# Reload the data with particular batch size\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 128\n",
    "d_embed = 128\n",
    "NUM_EPOCHS = 4\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "nhead = 2\n",
    "model = RNNModel(vocab,d_embed,d_hidden,d_out,num_layers=2) \n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.7 # This causes the LR to be 2e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1000| Training Loss: 6.403552149772644\n",
      "Epoch 1, Batch: 2000| Training Loss: 6.312016486644745\n",
      "Epoch 1, Batch: 3000| Training Loss: 6.271635150591532\n",
      "Epoch 1, Batch: 4000| Training Loss: 6.239639240503311\n",
      "Epoch 1, Batch: 5000| Training Loss: 6.21986857175827\n",
      "Epoch 1, Batch: 6000| Training Loss: 6.200330499490102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_error,train_loss_values, val_error, val_loss_value,swa_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the training error\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[0;32mIn[32], line 26\u001b[0m, in \u001b[0;36mtrain_rnn\u001b[0;34m(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay)\u001b[0m\n\u001b[1;32m     24\u001b[0m sequences, lengths, labels \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39mto(device), lengths\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Forward Pass\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Backpropogate & Optimize\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x, seq_lengths)\u001b[0m\n\u001b[1;32m     20\u001b[0m packed_input \u001b[38;5;241m=\u001b[39m pack_padded_sequence(x, seq_lengths, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Pass the packed sequence through the LSTM\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m packed_output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Unpack the sequence\u001b[39;00m\n\u001b[1;32m     25\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m pad_packed_sequence(packed_output, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,total_length \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:882\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    879\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    880\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    885\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value,swa_model = train_rnn(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('validation_error_model_rnn.png')  # This will save the plot as an image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
