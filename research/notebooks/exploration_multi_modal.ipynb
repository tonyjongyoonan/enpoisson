{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import importlib\n",
    "import utils\n",
    "import models\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "trainX_boards = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (3038976,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)\n",
    "\n",
    "with open('./../data/jan-march/vocab.pkl', 'rb') as inp:\n",
    "    vocab = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our raw data, we need to be able to make sense of chess moves. Meaning, we're transforming our entire world from chess moves into numerical tokens that will serve as indices into unique embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can just use nn.Embedding later when we pass the model a sequence of indices, but this is if we ever want to pre-train and have access to the matrix we've trained\n",
    "def get_embedding_matrix(vocab, d_embed):\n",
    "    n_embed = len(vocab.move_to_id)\n",
    "    return np.random.normal(0, 1, (n_embed, d_embed))\n",
    "# embedding_matrix = get_embedding_matrix(vocab, 64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8121\n",
      "torch.Size([12, 8, 8])\n",
      "[[[0 0 0 0 0 0 0 0]\n",
      "  [1 1 0 0 1 0 1 1]\n",
      "  [0 0 1 0 0 1 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[1 0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [1 1 1 1 0 1 1 1]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 1]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab.id_to_move.keys()))\n",
    "print(torch.tensor(trainX_boards[0]).shape)\n",
    "print(trainX_boards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(trainY[:5000]),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay):\n",
    "    train_loss_values = []\n",
    "    train_error = []\n",
    "    val_loss_values = []\n",
    "    val_error = []\n",
    "    val_3_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        training_loss = 0.0\n",
    "        # Training\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for boards, sequences, lengths, labels in train_loader:\n",
    "            count += 1\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "            # Forward Pass\n",
    "            output = model(boards, sequences, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            # Backpropogate & Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # For logging purposes\n",
    "            training_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            if count % 1000 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch: {count}| Training Loss: {training_loss/count}')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        validation_loss = 0.0\n",
    "        if val_loader is not None:\n",
    "            with torch.no_grad():\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                val_top3_correct = 0\n",
    "                validation_loss = 0\n",
    "\n",
    "                for boards, sequences, lengths, labels in val_loader:\n",
    "                    boards, sequences, lengths, labels = boards.to(device, non_blocking=True), sequences.to(device, non_blocking=True), lengths, labels.to(device, non_blocking=True)\n",
    "                    outputs = model(boards, sequences, lengths)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_top3_correct += top_3_accuracy(labels, outputs) * labels.size(0)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    validation_loss += loss.item()\n",
    "\n",
    "                val_loss_values.append(validation_loss / len(val_loader))\n",
    "                val_accuracy = 100 * val_correct / val_total\n",
    "                val_top3_accuracy = 100 * val_top3_correct / val_total\n",
    "                val_error.append(100 - val_accuracy)\n",
    "                val_3_accuracy.append(val_top3_accuracy)\n",
    "\n",
    "        # Log Model Performance  \n",
    "        train_loss_values.append(training_loss)\n",
    "        train_error.append(100-100*train_correct/train_total)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_loss/len(train_loader)}, Validation Error: {val_error[-1]}, Validation Top-3 Accuracy: {val_3_accuracy[-1]}, Training Error: {train_error[-1]}')\n",
    "        if epoch <= 10:\n",
    "            for op_params in optimizer.param_groups:\n",
    "                op_params['lr'] = op_params['lr'] * learn_decay\n",
    "    return train_error,train_loss_values, val_error, val_loss_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887027\n"
     ]
    }
   ],
   "source": [
    "dataset = MultimodalDataset(trainX_sequences, trainX_boards, trainX_seqlengths, trainY)\n",
    "# Calculate split sizes\n",
    "total_size = len(dataset)\n",
    "\n",
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.95 * total_size)\n",
    "val_size = int(total_size * 0.04)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 (CNN has 2 Convolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589\n"
     ]
    }
   ],
   "source": [
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.95 * total_size)\n",
    "val_size = int(total_size * 0.04)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathaniel/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490555\n"
     ]
    }
   ],
   "source": [
    "# Reload the data with particular batch size\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 72\n",
    "d_embed = 32\n",
    "NUM_EPOCHS = 25\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModal(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.7 # This causes the LR to be 2e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 6.682768297195435, Validation Error: 91.66666666666667, Validation Top-3 Accuracy: 8.33333358168602, Training Error: 98.64176570458405\n",
      "Epoch 2, Training Loss: 5.682501029968262, Validation Error: 91.66666666666667, Validation Top-3 Accuracy: 8.33333358168602, Training Error: 94.90662139219015\n",
      "Epoch 3, Training Loss: 4.880701231956482, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 92.69949066213923\n",
      "Epoch 4, Training Loss: 4.429151296615601, Validation Error: 91.66666666666667, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 89.64346349745331\n",
      "Epoch 5, Training Loss: 4.106862878799438, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 84.04074702886248\n",
      "Epoch 6, Training Loss: 3.8884287595748903, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 83.02207130730051\n",
      "Epoch 7, Training Loss: 3.7301934957504272, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 80.98471986417657\n",
      "Epoch 8, Training Loss: 3.617365038394928, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 77.58913412563668\n",
      "Epoch 9, Training Loss: 3.5376277327537538, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 75.72156196943973\n",
      "Epoch 10, Training Loss: 3.4814242839813234, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 74.87266553480475\n",
      "Epoch 11, Training Loss: 3.4420204639434813, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 74.36332767402376\n",
      "Epoch 12, Training Loss: 3.4145872712135317, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 73.85398981324278\n",
      "Epoch 13, Training Loss: 3.3931331992149354, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 73.3446519524618\n",
      "Epoch 14, Training Loss: 3.3715712785720826, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 72.66553480475382\n",
      "Epoch 15, Training Loss: 3.3506837368011473, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 72.32597623089983\n",
      "Epoch 16, Training Loss: 3.329383409023285, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 71.81663837011885\n",
      "Epoch 17, Training Loss: 3.3081316232681273, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 71.64685908319186\n",
      "Epoch 18, Training Loss: 3.2866799592971803, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 71.30730050933786\n",
      "Epoch 19, Training Loss: 3.2652185440063475, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 70.79796264855688\n",
      "Epoch 20, Training Loss: 3.2440505743026735, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 70.62818336162988\n",
      "Epoch 21, Training Loss: 3.2227064847946165, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 70.28862478777589\n",
      "Epoch 22, Training Loss: 3.201303219795227, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 70.11884550084889\n",
      "Epoch 23, Training Loss: 3.179571670293808, Validation Error: 87.5, Validation Top-3 Accuracy: 16.66666716337204, Training Error: 69.43972835314092\n",
      "Epoch 24, Training Loss: 3.158334803581238, Validation Error: 87.5, Validation Top-3 Accuracy: 12.5, Training Error: 69.26994906621393\n",
      "Epoch 25, Training Loss: 3.13666113615036, Validation Error: 87.5, Validation Top-3 Accuracy: 12.5, Training Error: 68.93039049235993\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('validation_error_model_rnn.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we filter out illegal moves in our prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "Validation Accuracy: 35.87428571428571%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_size = int(total_size * 0.04)\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "if val_loader is not None:\n",
    "    with torch.no_grad():\n",
    "        for boards, sequences, lengths, labels in val_loader:\n",
    "            boards, sequences, lengths, labels = boards.to(device), sequences.to(device), lengths.to(device), labels.to(device)\n",
    "            outputs = model(boards, sequences, lengths)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            minus = 0\n",
    "            for idx, (sequence, label) in enumerate(zip(sequences, labels)):\n",
    "                # This tells us we're looking at games that include the opening but has developed more than the first 4 half-moves\n",
    "                if sequence[-1].item() == 0 and sequence[2].item() != 0 and sequence[3].item() != 0 and sequence[4].item() != 0:\n",
    "                    output = probabilities[idx]\n",
    "                    sorted_probs, sorted_indices = torch.sort(output, descending=True)\n",
    "                    predicted_move = sorted_indices[0]\n",
    "                    # print(predicted_move)\n",
    "                    chess_board = load_board_state_from_san(sequence, vocab)\n",
    "                    for move_idx in sorted_indices:\n",
    "                        move = vocab.get_move(move_idx.item()) # Convert index to move (e.g., 'e2e4')\n",
    "                        if is_legal_move(chess_board, move):\n",
    "                            # print(\"we found one\")\n",
    "                            predicted_move = vocab.get_id(move)\n",
    "                            break\n",
    "                    \n",
    "                    # Check if predicted move is correct\n",
    "                    correct_move = label.item() # Convert label to move\n",
    "                    # print(correct_move)\n",
    "                    if predicted_move == correct_move:\n",
    "                        val_correct += 1\n",
    "                else:\n",
    "                    minus += 1\n",
    "            val_total += (labels.size(0) - minus)\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Accuracy: {val_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'multimodalmodel.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 (CNN has 3 convolutions,SE, ReLu after combining inputs and larger RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634630\n"
     ]
    }
   ],
   "source": [
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.95 * total_size)\n",
    "val_size = int(total_size * 0.04)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131882\n"
     ]
    }
   ],
   "source": [
    "# Reload the data with particular batch size\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 100\n",
    "d_embed = 48\n",
    "NUM_EPOCHS = 15\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalTwo(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.72 # This causes the LR to be 5e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1000| Training Loss: 5.358224760532379\n",
      "Epoch 1, Batch: 2000| Training Loss: 5.12661018884182\n",
      "Epoch 1, Batch: 3000| Training Loss: 4.984487212657928\n",
      "Epoch 1, Batch: 4000| Training Loss: 4.880090206086636\n",
      "Epoch 1, Batch: 5000| Training Loss: 4.78517461733818\n",
      "Epoch 1, Batch: 6000| Training Loss: 4.7084750316937765\n",
      "Epoch 1, Batch: 7000| Training Loss: 4.644520375422069\n",
      "Epoch 1, Batch: 8000| Training Loss: 4.584236370325089\n",
      "Epoch 1, Batch: 9000| Training Loss: 4.53359999956025\n",
      "Epoch 1, Batch: 10000| Training Loss: 4.487822722411155\n",
      "Epoch 1, Batch: 11000| Training Loss: 4.445587667400186\n",
      "Epoch 1, Batch: 12000| Training Loss: 4.40721798068285\n",
      "Epoch 1, Batch: 13000| Training Loss: 4.372255387526292\n",
      "Epoch 1, Batch: 14000| Training Loss: 4.34038493510655\n",
      "Epoch 1, Batch: 15000| Training Loss: 4.310646494738261\n",
      "Epoch 1, Batch: 16000| Training Loss: 4.282993175700307\n",
      "Epoch 1, Batch: 17000| Training Loss: 4.257371399865431\n",
      "Epoch 1, Batch: 18000| Training Loss: 4.234443660351965\n",
      "Epoch 1, Batch: 19000| Training Loss: 4.212246252285807\n",
      "Epoch 1, Batch: 20000| Training Loss: 4.192180788624286\n",
      "Epoch 1, Batch: 21000| Training Loss: 4.1727453940822965\n",
      "Epoch 1, Batch: 22000| Training Loss: 4.153056076591665\n",
      "Epoch 1, Batch: 23000| Training Loss: 4.134850503247717\n",
      "Epoch 1, Batch: 24000| Training Loss: 4.117725422114134\n",
      "Epoch 1, Batch: 25000| Training Loss: 4.100960772876739\n",
      "Epoch 1, Training Loss: 4.092024691895884, Validation Error: 78.61563943858425, Validation Top-3 Accuracy: 38.39246796277512, Training Error: 81.66166043691845\n",
      "Epoch 2, Batch: 1000| Training Loss: 3.651757910966873\n",
      "Epoch 2, Batch: 2000| Training Loss: 3.6435871212482454\n",
      "Epoch 2, Batch: 3000| Training Loss: 3.636805051167806\n",
      "Epoch 2, Batch: 4000| Training Loss: 3.6328137121200563\n",
      "Epoch 2, Batch: 5000| Training Loss: 3.6196360639572145\n",
      "Epoch 2, Batch: 6000| Training Loss: 3.611985718011856\n",
      "Epoch 2, Batch: 7000| Training Loss: 3.606109873499189\n",
      "Epoch 2, Batch: 8000| Training Loss: 3.5995867279171945\n",
      "Epoch 2, Batch: 9000| Training Loss: 3.5946447857485877\n",
      "Epoch 2, Batch: 10000| Training Loss: 3.589093448472023\n",
      "Epoch 2, Batch: 11000| Training Loss: 3.5832591432874854\n",
      "Epoch 2, Batch: 12000| Training Loss: 3.5772508108615875\n",
      "Epoch 2, Batch: 13000| Training Loss: 3.572073632130256\n",
      "Epoch 2, Batch: 14000| Training Loss: 3.5667808487585613\n",
      "Epoch 2, Batch: 15000| Training Loss: 3.5611668466091158\n",
      "Epoch 2, Batch: 16000| Training Loss: 3.5557396154105665\n",
      "Epoch 2, Batch: 17000| Training Loss: 3.5509392418580896\n",
      "Epoch 2, Batch: 18000| Training Loss: 3.5468732714255653\n",
      "Epoch 2, Batch: 19000| Training Loss: 3.5419234688031045\n",
      "Epoch 2, Batch: 20000| Training Loss: 3.5383571269750593\n",
      "Epoch 2, Batch: 21000| Training Loss: 3.5342637304010847\n",
      "Epoch 2, Batch: 22000| Training Loss: 3.5291866980357605\n",
      "Epoch 2, Batch: 23000| Training Loss: 3.5244237489182018\n",
      "Epoch 2, Batch: 24000| Training Loss: 3.520382763793071\n",
      "Epoch 2, Batch: 25000| Training Loss: 3.51564538479805\n",
      "Epoch 2, Training Loss: 3.513015216336479, Validation Error: 76.1470955743469, Validation Top-3 Accuracy: 42.37352163435272, Training Error: 76.12114056391967\n",
      "Epoch 3, Batch: 1000| Training Loss: 3.3968165423870085\n",
      "Epoch 3, Batch: 2000| Training Loss: 3.3915503358840944\n",
      "Epoch 3, Batch: 3000| Training Loss: 3.388434473911921\n",
      "Epoch 3, Batch: 4000| Training Loss: 3.386762285888195\n",
      "Epoch 3, Batch: 5000| Training Loss: 3.376897746324539\n",
      "Epoch 3, Batch: 6000| Training Loss: 3.371298305829366\n",
      "Epoch 3, Batch: 7000| Training Loss: 3.367647926398686\n",
      "Epoch 3, Batch: 8000| Training Loss: 3.3633185525238516\n",
      "Epoch 3, Batch: 9000| Training Loss: 3.360056888686286\n",
      "Epoch 3, Batch: 10000| Training Loss: 3.356820752286911\n",
      "Epoch 3, Batch: 11000| Training Loss: 3.353009033203125\n",
      "Epoch 3, Batch: 12000| Training Loss: 3.349058154940605\n",
      "Epoch 3, Batch: 13000| Training Loss: 3.3461518198160025\n",
      "Epoch 3, Batch: 14000| Training Loss: 3.3431409624814985\n",
      "Epoch 3, Batch: 15000| Training Loss: 3.3394856364568075\n",
      "Epoch 3, Batch: 16000| Training Loss: 3.3361066677719355\n",
      "Epoch 3, Batch: 17000| Training Loss: 3.333304230633904\n",
      "Epoch 3, Batch: 18000| Training Loss: 3.330866246461868\n",
      "Epoch 3, Batch: 19000| Training Loss: 3.3272903495587802\n",
      "Epoch 3, Batch: 20000| Training Loss: 3.325440343296528\n",
      "Epoch 3, Batch: 21000| Training Loss: 3.3230360287825267\n",
      "Epoch 3, Batch: 22000| Training Loss: 3.3195801607262005\n",
      "Epoch 3, Batch: 23000| Training Loss: 3.316181686411733\n",
      "Epoch 3, Batch: 24000| Training Loss: 3.3136821582814058\n",
      "Epoch 3, Batch: 25000| Training Loss: 3.3103332914543153\n",
      "Epoch 3, Training Loss: 3.3084982360466917, Validation Error: 74.94406183709644, Validation Top-3 Accuracy: 44.36840728794351, Training Error: 73.71386797012168\n",
      "Epoch 4, Batch: 1000| Training Loss: 3.2426090804338457\n",
      "Epoch 4, Batch: 2000| Training Loss: 3.2394311973452568\n",
      "Epoch 4, Batch: 3000| Training Loss: 3.237845349272092\n",
      "Epoch 4, Batch: 4000| Training Loss: 3.2373722124397757\n",
      "Epoch 4, Batch: 5000| Training Loss: 3.2290585483789442\n",
      "Epoch 4, Batch: 6000| Training Loss: 3.224792125840982\n",
      "Epoch 4, Batch: 7000| Training Loss: 3.22172945197991\n",
      "Epoch 4, Batch: 8000| Training Loss: 3.2184972061961887\n",
      "Epoch 4, Batch: 9000| Training Loss: 3.2163732378085452\n",
      "Epoch 4, Batch: 10000| Training Loss: 3.2137737374186517\n",
      "Epoch 4, Batch: 11000| Training Loss: 3.2110257436253806\n",
      "Epoch 4, Batch: 12000| Training Loss: 3.2080346365670365\n",
      "Epoch 4, Batch: 13000| Training Loss: 3.2058979679896282\n",
      "Epoch 4, Batch: 14000| Training Loss: 3.2036454378621917\n",
      "Epoch 4, Batch: 15000| Training Loss: 3.2007091786146162\n",
      "Epoch 4, Batch: 16000| Training Loss: 3.198168506927788\n",
      "Epoch 4, Batch: 17000| Training Loss: 3.1960652034352806\n",
      "Epoch 4, Batch: 18000| Training Loss: 3.194248376482063\n",
      "Epoch 4, Batch: 19000| Training Loss: 3.191405326749149\n",
      "Epoch 4, Batch: 20000| Training Loss: 3.1901013551652433\n",
      "Epoch 4, Batch: 21000| Training Loss: 3.1883402648937134\n",
      "Epoch 4, Batch: 22000| Training Loss: 3.185604849192229\n",
      "Epoch 4, Batch: 23000| Training Loss: 3.1829309985896814\n",
      "Epoch 4, Batch: 24000| Training Loss: 3.181089966798822\n",
      "Epoch 4, Batch: 25000| Training Loss: 3.178336095890999\n",
      "Epoch 4, Training Loss: 3.1768458565552247, Validation Error: 74.01853950541947, Validation Top-3 Accuracy: 45.680411473447904, Training Error: 72.16097832537027\n",
      "Epoch 5, Batch: 1000| Training Loss: 3.140281164884567\n",
      "Epoch 5, Batch: 2000| Training Loss: 3.137476062178612\n",
      "Epoch 5, Batch: 3000| Training Loss: 3.136243986765544\n",
      "Epoch 5, Batch: 4000| Training Loss: 3.1367310014367105\n",
      "Epoch 5, Batch: 5000| Training Loss: 3.1296361626148226\n",
      "Epoch 5, Batch: 6000| Training Loss: 3.1260660774707794\n",
      "Epoch 5, Batch: 7000| Training Loss: 3.123539417709623\n",
      "Epoch 5, Batch: 8000| Training Loss: 3.120637203261256\n",
      "Epoch 5, Batch: 9000| Training Loss: 3.118758892522918\n",
      "Epoch 5, Batch: 10000| Training Loss: 3.11668400799036\n",
      "Epoch 5, Batch: 11000| Training Loss: 3.114330873803659\n",
      "Epoch 5, Batch: 12000| Training Loss: 3.1116949720084666\n",
      "Epoch 5, Batch: 13000| Training Loss: 3.1100655871446317\n",
      "Epoch 5, Batch: 14000| Training Loss: 3.108396685046809\n",
      "Epoch 5, Batch: 15000| Training Loss: 3.1060492034832636\n",
      "Epoch 5, Batch: 16000| Training Loss: 3.103933355100453\n",
      "Epoch 5, Batch: 17000| Training Loss: 3.1021872108052757\n",
      "Epoch 5, Batch: 18000| Training Loss: 3.1006701845261784\n",
      "Epoch 5, Batch: 19000| Training Loss: 3.098166624828389\n",
      "Epoch 5, Batch: 20000| Training Loss: 3.0972964865148067\n",
      "Epoch 5, Batch: 21000| Training Loss: 3.095809174202737\n",
      "Epoch 5, Batch: 22000| Training Loss: 3.093537267961285\n",
      "Epoch 5, Batch: 23000| Training Loss: 3.091270495036374\n",
      "Epoch 5, Batch: 24000| Training Loss: 3.0895970076074204\n",
      "Epoch 5, Batch: 25000| Training Loss: 3.087207551774979\n",
      "Epoch 5, Training Loss: 3.085907254332188, Validation Error: 73.4707813907535, Validation Top-3 Accuracy: 46.569610321507554, Training Error: 71.06703045949236\n",
      "Epoch 6, Batch: 1000| Training Loss: 3.0678865529298784\n",
      "Epoch 6, Batch: 2000| Training Loss: 3.065613861501217\n",
      "Epoch 6, Batch: 3000| Training Loss: 3.065330901503563\n",
      "Epoch 6, Batch: 4000| Training Loss: 3.0664185711443426\n",
      "Epoch 6, Batch: 5000| Training Loss: 3.059781267666817\n",
      "Epoch 6, Batch: 6000| Training Loss: 3.0567422559460002\n",
      "Epoch 6, Batch: 7000| Training Loss: 3.0544450075115477\n",
      "Epoch 6, Batch: 8000| Training Loss: 3.051874518662691\n",
      "Epoch 6, Batch: 9000| Training Loss: 3.0502714044517942\n",
      "Epoch 6, Batch: 10000| Training Loss: 3.048397197175026\n",
      "Epoch 6, Batch: 11000| Training Loss: 3.0463356130990116\n",
      "Epoch 6, Batch: 12000| Training Loss: 3.04400585069259\n",
      "Epoch 6, Batch: 13000| Training Loss: 3.042730453913028\n",
      "Epoch 6, Batch: 14000| Training Loss: 3.041364134669304\n",
      "Epoch 6, Batch: 15000| Training Loss: 3.0393445292949677\n",
      "Epoch 6, Batch: 16000| Training Loss: 3.0374716517180205\n",
      "Epoch 6, Batch: 17000| Training Loss: 3.0359388306000654\n",
      "Epoch 6, Batch: 18000| Training Loss: 3.0345618599587016\n",
      "Epoch 6, Batch: 19000| Training Loss: 3.032283503331636\n",
      "Epoch 6, Batch: 20000| Training Loss: 3.0315905069708826\n",
      "Epoch 6, Batch: 21000| Training Loss: 3.0304173103741237\n",
      "Epoch 6, Batch: 22000| Training Loss: 3.028403895486485\n",
      "Epoch 6, Batch: 23000| Training Loss: 3.0263572992967522\n",
      "Epoch 6, Batch: 24000| Training Loss: 3.024980157852173\n",
      "Epoch 6, Batch: 25000| Training Loss: 3.0228709458446503\n",
      "Epoch 6, Training Loss: 3.0217201649400587, Validation Error: 73.00148199808211, Validation Top-3 Accuracy: 47.232150640573025, Training Error: 70.22390388038883\n",
      "Epoch 7, Batch: 1000| Training Loss: 3.0201055139303206\n",
      "Epoch 7, Batch: 2000| Training Loss: 3.017170093357563\n",
      "Epoch 7, Batch: 3000| Training Loss: 3.0174953127702078\n",
      "Epoch 7, Batch: 4000| Training Loss: 3.0186905769705774\n",
      "Epoch 7, Batch: 5000| Training Loss: 3.0124560492038728\n",
      "Epoch 7, Batch: 6000| Training Loss: 3.0095274131298067\n",
      "Epoch 7, Batch: 7000| Training Loss: 3.007142053638186\n",
      "Epoch 7, Batch: 8000| Training Loss: 3.0049535977989437\n",
      "Epoch 7, Batch: 9000| Training Loss: 3.003604592680931\n",
      "Epoch 7, Batch: 10000| Training Loss: 3.0019830515146255\n",
      "Epoch 7, Batch: 11000| Training Loss: 3.0001343515136023\n",
      "Epoch 7, Batch: 12000| Training Loss: 2.9979772396186988\n",
      "Epoch 7, Batch: 13000| Training Loss: 2.996847433869655\n",
      "Epoch 7, Batch: 14000| Training Loss: 2.995643303470952\n",
      "Epoch 7, Batch: 15000| Training Loss: 2.9937524714549384\n",
      "Epoch 7, Batch: 16000| Training Loss: 2.991907784126699\n",
      "Epoch 7, Batch: 17000| Training Loss: 2.9905570759562887\n",
      "Epoch 7, Batch: 18000| Training Loss: 2.989292973856131\n",
      "Epoch 7, Batch: 19000| Training Loss: 2.9873047904403585\n",
      "Epoch 7, Batch: 20000| Training Loss: 2.986717792803049\n",
      "Epoch 7, Batch: 21000| Training Loss: 2.985636543364752\n",
      "Epoch 7, Batch: 22000| Training Loss: 2.98374988898364\n",
      "Epoch 7, Batch: 23000| Training Loss: 2.9818797529158383\n",
      "Epoch 7, Batch: 24000| Training Loss: 2.980530419498682\n",
      "Epoch 7, Batch: 25000| Training Loss: 2.9784792034959793\n",
      "Epoch 7, Training Loss: 2.9774368919852794, Validation Error: 72.72542353180484, Validation Top-3 Accuracy: 47.6709383092367, Training Error: 69.64713727265497\n",
      "Epoch 8, Batch: 1000| Training Loss: 2.985103551506996\n",
      "Epoch 8, Batch: 2000| Training Loss: 2.98260239225626\n",
      "Epoch 8, Batch: 3000| Training Loss: 2.9829917999505997\n",
      "Epoch 8, Batch: 4000| Training Loss: 2.9844755600988866\n",
      "Epoch 8, Batch: 5000| Training Loss: 2.9788212438821793\n",
      "Epoch 8, Batch: 6000| Training Loss: 2.9758359957734744\n",
      "Epoch 8, Batch: 7000| Training Loss: 2.9734476071596148\n",
      "Epoch 8, Batch: 8000| Training Loss: 2.971505431905389\n",
      "Epoch 8, Batch: 9000| Training Loss: 2.970245382944743\n",
      "Epoch 8, Batch: 10000| Training Loss: 2.9688278483510016\n",
      "Epoch 8, Batch: 11000| Training Loss: 2.9670583903030914\n",
      "Epoch 8, Batch: 12000| Training Loss: 2.9651006292104722\n",
      "Epoch 8, Batch: 13000| Training Loss: 2.963996638939931\n",
      "Epoch 8, Batch: 14000| Training Loss: 2.962999806829861\n",
      "Epoch 8, Batch: 15000| Training Loss: 2.961275273609161\n",
      "Epoch 8, Batch: 16000| Training Loss: 2.959512501217425\n",
      "Epoch 8, Batch: 17000| Training Loss: 2.958209812648156\n",
      "Epoch 8, Batch: 18000| Training Loss: 2.9569436461925505\n",
      "Epoch 8, Batch: 19000| Training Loss: 2.955014316207484\n",
      "Epoch 8, Batch: 20000| Training Loss: 2.9544911190867422\n",
      "Epoch 8, Batch: 21000| Training Loss: 2.953485906294414\n",
      "Epoch 8, Batch: 22000| Training Loss: 2.9517084162452005\n",
      "Epoch 8, Batch: 23000| Training Loss: 2.9498474678734072\n",
      "Epoch 8, Batch: 24000| Training Loss: 2.9485820445170003\n",
      "Epoch 8, Batch: 25000| Training Loss: 2.946619019021988\n",
      "Epoch 8, Training Loss: 2.945615731062451, Validation Error: 72.5089355766716, Validation Top-3 Accuracy: 47.69127945938345, Training Error: 69.20300006729352\n",
      "Epoch 9, Batch: 1000| Training Loss: 2.9591165297031403\n",
      "Epoch 9, Batch: 2000| Training Loss: 2.9565978664159775\n",
      "Epoch 9, Batch: 3000| Training Loss: 2.9579790262381236\n",
      "Epoch 9, Batch: 4000| Training Loss: 2.9592695457339286\n",
      "Epoch 9, Batch: 5000| Training Loss: 2.9535207255125044\n",
      "Epoch 9, Batch: 6000| Training Loss: 2.9507935391465825\n",
      "Epoch 9, Batch: 7000| Training Loss: 2.9486976746320726\n",
      "Epoch 9, Batch: 8000| Training Loss: 2.9469273146241903\n",
      "Epoch 9, Batch: 9000| Training Loss: 2.9459409682618247\n",
      "Epoch 9, Batch: 10000| Training Loss: 2.9443347998857496\n",
      "Epoch 9, Batch: 11000| Training Loss: 2.9425533046505667\n",
      "Epoch 9, Batch: 12000| Training Loss: 2.9405323606431484\n",
      "Epoch 9, Batch: 13000| Training Loss: 2.9396069645789953\n",
      "Epoch 9, Batch: 14000| Training Loss: 2.9387191323637962\n",
      "Epoch 9, Batch: 15000| Training Loss: 2.937059528652827\n",
      "Epoch 9, Batch: 16000| Training Loss: 2.9353375568389892\n",
      "Epoch 9, Batch: 17000| Training Loss: 2.9341450306387507\n",
      "Epoch 9, Batch: 18000| Training Loss: 2.9329819265007973\n",
      "Epoch 9, Batch: 19000| Training Loss: 2.9311470370355406\n",
      "Epoch 9, Batch: 20000| Training Loss: 2.9306889545619486\n",
      "Epoch 9, Batch: 21000| Training Loss: 2.9297191989478613\n",
      "Epoch 9, Batch: 22000| Training Loss: 2.9280191683389925\n",
      "Epoch 9, Batch: 23000| Training Loss: 2.9262417292439418\n",
      "Epoch 9, Batch: 24000| Training Loss: 2.925040630112092\n",
      "Epoch 9, Batch: 25000| Training Loss: 2.923190500454903\n",
      "Epoch 9, Training Loss: 2.9221982374027746, Validation Error: 72.37381222212537, Validation Top-3 Accuracy: 47.923749746774845, Training Error: 68.90715330074696\n",
      "Epoch 10, Batch: 1000| Training Loss: 2.942651938080788\n",
      "Epoch 10, Batch: 2000| Training Loss: 2.9388877754807474\n",
      "Epoch 10, Batch: 3000| Training Loss: 2.9402778798739115\n",
      "Epoch 10, Batch: 4000| Training Loss: 2.941494235098362\n",
      "Epoch 10, Batch: 5000| Training Loss: 2.9359844781398774\n",
      "Epoch 10, Batch: 6000| Training Loss: 2.9336939415534338\n",
      "Epoch 10, Batch: 7000| Training Loss: 2.931403711421149\n",
      "Epoch 10, Batch: 8000| Training Loss: 2.9296506073325874\n",
      "Epoch 10, Batch: 9000| Training Loss: 2.92880011733373\n",
      "Epoch 10, Batch: 10000| Training Loss: 2.927413677430153\n",
      "Epoch 10, Batch: 11000| Training Loss: 2.925694975571199\n",
      "Epoch 10, Batch: 12000| Training Loss: 2.9236992925703524\n",
      "Epoch 10, Batch: 13000| Training Loss: 2.922867253386057\n",
      "Epoch 10, Batch: 14000| Training Loss: 2.9219514468227112\n",
      "Epoch 10, Batch: 15000| Training Loss: 2.920351440747579\n",
      "Epoch 10, Batch: 16000| Training Loss: 2.918701268956065\n",
      "Epoch 10, Batch: 17000| Training Loss: 2.917517299567952\n",
      "Epoch 10, Batch: 18000| Training Loss: 2.916393088698387\n",
      "Epoch 10, Batch: 19000| Training Loss: 2.914512223877405\n",
      "Epoch 10, Batch: 20000| Training Loss: 2.914086051827669\n",
      "Epoch 10, Batch: 21000| Training Loss: 2.9131151449737094\n",
      "Epoch 10, Batch: 22000| Training Loss: 2.911441717326641\n",
      "Epoch 10, Batch: 23000| Training Loss: 2.909687483549118\n",
      "Epoch 10, Batch: 24000| Training Loss: 2.9084795691172283\n",
      "Epoch 10, Batch: 25000| Training Loss: 2.9066401192712785\n",
      "Epoch 10, Training Loss: 2.905672571250429, Validation Error: 72.27791822857641, Validation Top-3 Accuracy: 48.05015546554392, Training Error: 68.66850602276968\n",
      "Epoch 11, Batch: 1000| Training Loss: 2.9272338223457335\n",
      "Epoch 11, Batch: 2000| Training Loss: 2.9249668496251107\n",
      "Epoch 11, Batch: 3000| Training Loss: 2.926251265605291\n",
      "Epoch 11, Batch: 4000| Training Loss: 2.927783680379391\n",
      "Epoch 11, Batch: 5000| Training Loss: 2.9225695748805998\n",
      "Epoch 11, Batch: 6000| Training Loss: 2.9202721897761026\n",
      "Epoch 11, Batch: 7000| Training Loss: 2.918092726945877\n",
      "Epoch 11, Batch: 8000| Training Loss: 2.916610171958804\n",
      "Epoch 11, Batch: 9000| Training Loss: 2.9158207762108908\n",
      "Epoch 11, Batch: 10000| Training Loss: 2.9144918267607687\n",
      "Epoch 11, Batch: 11000| Training Loss: 2.9128593230139126\n",
      "Epoch 11, Batch: 12000| Training Loss: 2.911004111687342\n",
      "Epoch 11, Batch: 13000| Training Loss: 2.9100704071613457\n",
      "Epoch 11, Batch: 14000| Training Loss: 2.9092596410768374\n",
      "Epoch 11, Batch: 15000| Training Loss: 2.9076943257252377\n",
      "Epoch 11, Batch: 16000| Training Loss: 2.9060568145886063\n",
      "Epoch 11, Batch: 17000| Training Loss: 2.904954256709884\n",
      "Epoch 11, Batch: 18000| Training Loss: 2.903845960398515\n",
      "Epoch 11, Batch: 19000| Training Loss: 2.902109869411117\n",
      "Epoch 11, Batch: 20000| Training Loss: 2.901758336442709\n",
      "Epoch 11, Batch: 21000| Training Loss: 2.900886386825925\n",
      "Epoch 11, Batch: 22000| Training Loss: 2.899218969150023\n",
      "Epoch 11, Batch: 23000| Training Loss: 2.897462416845819\n",
      "Epoch 11, Batch: 24000| Training Loss: 2.8962819805194933\n",
      "Epoch 11, Batch: 25000| Training Loss: 2.8944008681297304\n",
      "Epoch 11, Training Loss: 2.893461563883835, Validation Error: 72.26920059279924, Validation Top-3 Accuracy: 48.324760992525, Training Error: 68.48773116852132\n",
      "Epoch 12, Batch: 1000| Training Loss: 2.9175214400291445\n",
      "Epoch 12, Batch: 2000| Training Loss: 2.915702455699444\n",
      "Epoch 12, Batch: 3000| Training Loss: 2.9174674254258472\n",
      "Epoch 12, Batch: 4000| Training Loss: 2.9191014917492866\n",
      "Epoch 12, Batch: 5000| Training Loss: 2.9140793596982957\n",
      "Epoch 12, Batch: 6000| Training Loss: 2.9115413689812026\n",
      "Epoch 12, Batch: 7000| Training Loss: 2.909352442758424\n",
      "Epoch 12, Batch: 8000| Training Loss: 2.907803991943598\n",
      "Epoch 12, Batch: 9000| Training Loss: 2.9071117030249702\n",
      "Epoch 12, Batch: 10000| Training Loss: 2.9057951046824457\n",
      "Epoch 12, Batch: 11000| Training Loss: 2.9041041990735312\n",
      "Epoch 12, Batch: 12000| Training Loss: 2.9022029966513316\n",
      "Epoch 12, Batch: 13000| Training Loss: 2.9011787192546405\n",
      "Epoch 12, Batch: 14000| Training Loss: 2.9003167059847286\n",
      "Epoch 12, Batch: 15000| Training Loss: 2.8988964504559833\n",
      "Epoch 12, Batch: 16000| Training Loss: 2.8972342068850994\n",
      "Epoch 12, Batch: 17000| Training Loss: 2.896018249778187\n",
      "Epoch 12, Batch: 18000| Training Loss: 2.89484561182393\n",
      "Epoch 12, Batch: 19000| Training Loss: 2.89304489679713\n",
      "Epoch 12, Batch: 20000| Training Loss: 2.8927132951796053\n",
      "Epoch 12, Batch: 21000| Training Loss: 2.891872513708614\n",
      "Epoch 12, Batch: 22000| Training Loss: 2.890222723857923\n",
      "Epoch 12, Batch: 23000| Training Loss: 2.888470413612283\n",
      "Epoch 12, Batch: 24000| Training Loss: 2.88723755514125\n",
      "Epoch 12, Batch: 25000| Training Loss: 2.885444519753456\n",
      "Epoch 12, Training Loss: 2.8845409466986762, Validation Error: 72.21253596024758, Validation Top-3 Accuracy: 48.37416092859567, Training Error: 68.37314866361194\n",
      "Epoch 13, Batch: 1000| Training Loss: 2.912703545808792\n",
      "Epoch 13, Batch: 2000| Training Loss: 2.909955084979534\n",
      "Epoch 13, Batch: 3000| Training Loss: 2.911555638829867\n",
      "Epoch 13, Batch: 4000| Training Loss: 2.913081691920757\n",
      "Epoch 13, Batch: 5000| Training Loss: 2.9080309290647506\n",
      "Epoch 13, Batch: 6000| Training Loss: 2.9057465114196144\n",
      "Epoch 13, Batch: 7000| Training Loss: 2.9037076154436385\n",
      "Epoch 13, Batch: 8000| Training Loss: 2.902227616533637\n",
      "Epoch 13, Batch: 9000| Training Loss: 2.9014974092377557\n",
      "Epoch 13, Batch: 10000| Training Loss: 2.9001386999726297\n",
      "Epoch 13, Batch: 11000| Training Loss: 2.8984868774955923\n",
      "Epoch 13, Batch: 12000| Training Loss: 2.896740030914545\n",
      "Epoch 13, Batch: 13000| Training Loss: 2.8958291242947944\n",
      "Epoch 13, Batch: 14000| Training Loss: 2.8951704015476363\n",
      "Epoch 13, Batch: 15000| Training Loss: 2.8937872382799785\n",
      "Epoch 13, Batch: 16000| Training Loss: 2.892190606854856\n",
      "Epoch 13, Batch: 17000| Training Loss: 2.8910519582874636\n",
      "Epoch 13, Batch: 18000| Training Loss: 2.889973071263896\n",
      "Epoch 13, Batch: 19000| Training Loss: 2.8882898202444376\n",
      "Epoch 13, Batch: 20000| Training Loss: 2.887992945200205\n",
      "Epoch 13, Batch: 21000| Training Loss: 2.887200176000595\n",
      "Epoch 13, Batch: 22000| Training Loss: 2.885629110878164\n",
      "Epoch 13, Batch: 23000| Training Loss: 2.8839206466052842\n",
      "Epoch 13, Batch: 24000| Training Loss: 2.8827505879650515\n",
      "Epoch 13, Batch: 25000| Training Loss: 2.8810259076309204\n",
      "Epoch 13, Training Loss: 2.8801704435786855, Validation Error: 72.17621247784268, Validation Top-3 Accuracy: 48.44390201481309, Training Error: 68.3078127772034\n",
      "Epoch 14, Batch: 1000| Training Loss: 2.9070361644029616\n",
      "Epoch 14, Batch: 2000| Training Loss: 2.9045500036478042\n",
      "Epoch 14, Batch: 3000| Training Loss: 2.9061776479482653\n",
      "Epoch 14, Batch: 4000| Training Loss: 2.907652519762516\n",
      "Epoch 14, Batch: 5000| Training Loss: 2.9027121810436247\n",
      "Epoch 14, Batch: 6000| Training Loss: 2.9004349587162337\n",
      "Epoch 14, Batch: 7000| Training Loss: 2.898411779386657\n",
      "Epoch 14, Batch: 8000| Training Loss: 2.897178705081344\n",
      "Epoch 14, Batch: 9000| Training Loss: 2.8964210275411606\n",
      "Epoch 14, Batch: 10000| Training Loss: 2.895313549041748\n",
      "Epoch 14, Batch: 11000| Training Loss: 2.8937483720129187\n",
      "Epoch 14, Batch: 12000| Training Loss: 2.891885655124982\n",
      "Epoch 14, Batch: 13000| Training Loss: 2.8911438416517696\n",
      "Epoch 14, Batch: 14000| Training Loss: 2.8904253344791275\n",
      "Epoch 14, Batch: 15000| Training Loss: 2.8889762285629907\n",
      "Epoch 14, Batch: 16000| Training Loss: 2.887486680150032\n",
      "Epoch 14, Batch: 17000| Training Loss: 2.8864215368944057\n",
      "Epoch 14, Batch: 18000| Training Loss: 2.885308835380607\n",
      "Epoch 14, Batch: 19000| Training Loss: 2.8836468281808654\n",
      "Epoch 14, Batch: 20000| Training Loss: 2.883354423236847\n",
      "Epoch 14, Batch: 21000| Training Loss: 2.8826268673226947\n",
      "Epoch 14, Batch: 22000| Training Loss: 2.881123961865902\n",
      "Epoch 14, Batch: 23000| Training Loss: 2.8795367946106456\n",
      "Epoch 14, Batch: 24000| Training Loss: 2.8784785576264063\n",
      "Epoch 14, Batch: 25000| Training Loss: 2.876788261680603\n",
      "Epoch 14, Training Loss: 2.875925107636436, Validation Error: 72.16313602417691, Validation Top-3 Accuracy: 48.426466743258736, Training Error: 68.23611459474009\n",
      "Epoch 15, Batch: 1000| Training Loss: 2.902768669247627\n",
      "Epoch 15, Batch: 2000| Training Loss: 2.900293594837189\n",
      "Epoch 15, Batch: 3000| Training Loss: 2.9017615470488867\n",
      "Epoch 15, Batch: 4000| Training Loss: 2.9035180234909057\n",
      "Epoch 15, Batch: 5000| Training Loss: 2.8984339817762375\n",
      "Epoch 15, Batch: 6000| Training Loss: 2.8959592772722242\n",
      "Epoch 15, Batch: 7000| Training Loss: 2.8938503274236407\n",
      "Epoch 15, Batch: 8000| Training Loss: 2.8925002371668818\n",
      "Epoch 15, Batch: 9000| Training Loss: 2.89177711851067\n",
      "Epoch 15, Batch: 10000| Training Loss: 2.8905411552786826\n",
      "Epoch 15, Batch: 11000| Training Loss: 2.888896894617514\n",
      "Epoch 15, Batch: 12000| Training Loss: 2.8871798782845337\n",
      "Epoch 15, Batch: 13000| Training Loss: 2.886488559456972\n",
      "Epoch 15, Batch: 14000| Training Loss: 2.885865281198706\n",
      "Epoch 15, Batch: 15000| Training Loss: 2.884509125614166\n",
      "Epoch 15, Batch: 16000| Training Loss: 2.8830463977232577\n",
      "Epoch 15, Batch: 17000| Training Loss: 2.8820447498419703\n",
      "Epoch 15, Batch: 18000| Training Loss: 2.8809907164904804\n",
      "Epoch 15, Batch: 19000| Training Loss: 2.879369472208776\n",
      "Epoch 15, Batch: 20000| Training Loss: 2.8791235761106013\n",
      "Epoch 15, Batch: 21000| Training Loss: 2.878373941557748\n",
      "Epoch 15, Batch: 22000| Training Loss: 2.8768955464363097\n",
      "Epoch 15, Batch: 23000| Training Loss: 2.8752972190069115\n",
      "Epoch 15, Batch: 24000| Training Loss: 2.8743170627256234\n",
      "Epoch 15, Batch: 25000| Training Loss: 2.8726384447431563\n",
      "Epoch 15, Training Loss: 2.8717943185432975, Validation Error: 72.09194199866329, Validation Top-3 Accuracy: 48.47005492214462, Training Error: 68.17389868043533\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('validation_error_model_rnn.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 37.41142857142857%\n"
     ]
    }
   ],
   "source": [
    "def is_legal_move(chess_board, move_san):\n",
    "    try:\n",
    "        chess_move = chess_board.parse_san(move_san)\n",
    "        return chess_move in chess_board.legal_moves\n",
    "    except ValueError:\n",
    "        # This handles cases where the SAN move cannot be parsed or is not legal\n",
    "        return False\n",
    "\n",
    "def load_board_state_from_san(moves):\n",
    "    board = chess.Board()\n",
    "    for index in moves:\n",
    "        try:\n",
    "            if index == 0:\n",
    "                return board\n",
    "            else:\n",
    "                move_san = vocab.get_move(index.item())\n",
    "                move = board.parse_san(move_san)\n",
    "                board.push(move)\n",
    "        except ValueError:\n",
    "            # Handle invalid moves, e.g., break the loop or log an error\n",
    "            break\n",
    "    return board\n",
    "\n",
    "val_size = int(total_size * 0.04)\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "if val_loader is not None:\n",
    "    with torch.no_grad():\n",
    "        for boards, sequences, lengths, labels in val_loader:\n",
    "            boards, sequences, lengths, labels = boards.to(device), sequences.to(device), lengths.to(device), labels.to(device)\n",
    "            outputs = model(boards, sequences, lengths)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            minus = 0\n",
    "            for idx, (sequence, label) in enumerate(zip(sequences, labels)):\n",
    "                # This tells us we're looking at games that include the opening but has developed more than the first 4 half-moves\n",
    "                if sequence[-1].item() == 0 and sequence[2].item() != 0 and sequence[3].item() != 0 and sequence[4].item() != 0:\n",
    "                    output = probabilities[idx]\n",
    "                    sorted_probs, sorted_indices = torch.sort(output, descending=True)\n",
    "                    predicted_move = sorted_indices[0]\n",
    "                    # print(predicted_move)\n",
    "                    chess_board = load_board_state_from_san(sequence)\n",
    "                    for move_idx in sorted_indices:\n",
    "                        move = vocab.get_move(move_idx.item()) # Convert index to move (e.g., 'e2e4')\n",
    "                        if is_legal_move(chess_board, move):\n",
    "                            # print(\"we found one\")\n",
    "                            predicted_move = vocab.get_id(move)\n",
    "                            break\n",
    "                    \n",
    "                    # Check if predicted move is correct\n",
    "                    correct_move = label.item() # Convert label to move\n",
    "                    # print(correct_move)\n",
    "                    if predicted_move == correct_move:\n",
    "                        val_correct += 1\n",
    "                else:\n",
    "                    minus += 1\n",
    "            val_total += (labels.size(0) - minus)\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Accuracy: {val_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'multimodalmodel-2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 (focal loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131882\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=1, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # alpha can be set to a constant, or it can be a tensor of shape (num_classes,)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability 0\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "# Reload the data with particular batch size\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 100\n",
    "d_embed = 48\n",
    "NUM_EPOCHS = 15\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalTwo(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=1, reduction='mean')\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.72 # This causes the LR to be 5e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1000| Training Loss: 5.216632953643799\n",
      "Epoch 1, Batch: 2000| Training Loss: 4.9681913522481915\n",
      "Epoch 1, Batch: 3000| Training Loss: 4.809984962622325\n",
      "Epoch 1, Batch: 4000| Training Loss: 4.693838460147381\n",
      "Epoch 1, Batch: 5000| Training Loss: 4.583828910255432\n",
      "Epoch 1, Batch: 6000| Training Loss: 4.49359255596002\n",
      "Epoch 1, Batch: 7000| Training Loss: 4.419784398453576\n",
      "Epoch 1, Batch: 8000| Training Loss: 4.352040460258722\n",
      "Epoch 1, Batch: 9000| Training Loss: 4.294694580793381\n",
      "Epoch 1, Batch: 10000| Training Loss: 4.244223247122765\n",
      "Epoch 1, Batch: 11000| Training Loss: 4.197138833761215\n",
      "Epoch 1, Batch: 12000| Training Loss: 4.153256935497125\n",
      "Epoch 1, Batch: 13000| Training Loss: 4.113717842560548\n",
      "Epoch 1, Batch: 14000| Training Loss: 4.077679372889655\n",
      "Epoch 1, Batch: 15000| Training Loss: 4.044189786974589\n",
      "Epoch 1, Batch: 16000| Training Loss: 4.012455889597535\n",
      "Epoch 1, Batch: 17000| Training Loss: 3.9834087364673616\n",
      "Epoch 1, Batch: 18000| Training Loss: 3.956665287401941\n",
      "Epoch 1, Batch: 19000| Training Loss: 3.931393717213681\n",
      "Epoch 1, Batch: 20000| Training Loss: 3.9084694637537\n",
      "Epoch 1, Batch: 21000| Training Loss: 3.8859627670674097\n",
      "Epoch 1, Batch: 22000| Training Loss: 3.8635805377851833\n",
      "Epoch 1, Batch: 23000| Training Loss: 3.8423105001967888\n",
      "Epoch 1, Batch: 24000| Training Loss: 3.822287365158399\n",
      "Epoch 1, Batch: 25000| Training Loss: 3.8030709920835495\n",
      "Epoch 1, Training Loss: 3.7927171604092496, Validation Error: 77.91968151570627, Validation Top-3 Accuracy: 40.393165373723896, Training Error: 81.12129350372868\n",
      "Epoch 2, Batch: 1000| Training Loss: 3.2819662536382674\n",
      "Epoch 2, Batch: 2000| Training Loss: 3.275852493822575\n",
      "Epoch 2, Batch: 3000| Training Loss: 3.269808694163958\n",
      "Epoch 2, Batch: 4000| Training Loss: 3.2638935178220274\n",
      "Epoch 2, Batch: 5000| Training Loss: 3.249166759586334\n",
      "Epoch 2, Batch: 6000| Training Loss: 3.240282856941223\n",
      "Epoch 2, Batch: 7000| Training Loss: 3.233263347574643\n",
      "Epoch 2, Batch: 8000| Training Loss: 3.2249943661540748\n",
      "Epoch 2, Batch: 9000| Training Loss: 3.2195510797897975\n",
      "Epoch 2, Batch: 10000| Training Loss: 3.2134720901846885\n",
      "Epoch 2, Batch: 11000| Training Loss: 3.207195402741432\n",
      "Epoch 2, Batch: 12000| Training Loss: 3.2001376625299454\n",
      "Epoch 2, Batch: 13000| Training Loss: 3.194754500535818\n",
      "Epoch 2, Batch: 14000| Training Loss: 3.1895418390376227\n",
      "Epoch 2, Batch: 15000| Training Loss: 3.1838418961524964\n",
      "Epoch 2, Batch: 16000| Training Loss: 3.177613760218024\n",
      "Epoch 2, Batch: 17000| Training Loss: 3.1721128615772023\n",
      "Epoch 2, Batch: 18000| Training Loss: 3.1673498900665176\n",
      "Epoch 2, Batch: 19000| Training Loss: 3.1619891420351833\n",
      "Epoch 2, Batch: 20000| Training Loss: 3.1582417416751385\n",
      "Epoch 2, Batch: 21000| Training Loss: 3.153596747018042\n",
      "Epoch 2, Batch: 22000| Training Loss: 3.1481343298879536\n",
      "Epoch 2, Batch: 23000| Training Loss: 3.1426628705418627\n",
      "Epoch 2, Batch: 24000| Training Loss: 3.138012427295248\n",
      "Epoch 2, Batch: 25000| Training Loss: 3.1328575599241257\n",
      "Epoch 2, Training Loss: 3.1301114987528003, Validation Error: 75.44096707639555, Validation Top-3 Accuracy: 44.029872431929796, Training Error: 75.23476260682845\n",
      "Epoch 3, Batch: 1000| Training Loss: 3.000643640637398\n",
      "Epoch 3, Batch: 2000| Training Loss: 2.9942184072732925\n",
      "Epoch 3, Batch: 3000| Training Loss: 2.990476909081141\n",
      "Epoch 3, Batch: 4000| Training Loss: 2.98824698343873\n",
      "Epoch 3, Batch: 5000| Training Loss: 2.977424277639389\n",
      "Epoch 3, Batch: 6000| Training Loss: 2.9723902878959976\n",
      "Epoch 3, Batch: 7000| Training Loss: 2.968596156716347\n",
      "Epoch 3, Batch: 8000| Training Loss: 2.963587023794651\n",
      "Epoch 3, Batch: 9000| Training Loss: 2.9616011015706594\n",
      "Epoch 3, Batch: 10000| Training Loss: 2.9581176186800002\n",
      "Epoch 3, Batch: 11000| Training Loss: 2.954791423212398\n",
      "Epoch 3, Batch: 12000| Training Loss: 2.950438773840666\n",
      "Epoch 3, Batch: 13000| Training Loss: 2.9477586478636817\n",
      "Epoch 3, Batch: 14000| Training Loss: 2.9452212199143\n",
      "Epoch 3, Batch: 15000| Training Loss: 2.942076596911748\n",
      "Epoch 3, Batch: 16000| Training Loss: 2.9382585611194374\n",
      "Epoch 3, Batch: 17000| Training Loss: 2.935024822340292\n",
      "Epoch 3, Batch: 18000| Training Loss: 2.9325994193024107\n",
      "Epoch 3, Batch: 19000| Training Loss: 2.9291543554883255\n",
      "Epoch 3, Batch: 20000| Training Loss: 2.9274938245236872\n",
      "Epoch 3, Batch: 21000| Training Loss: 2.924983433411235\n",
      "Epoch 3, Batch: 22000| Training Loss: 2.9215648407177492\n",
      "Epoch 3, Batch: 23000| Training Loss: 2.918184255288995\n",
      "Epoch 3, Batch: 24000| Training Loss: 2.915475325147311\n",
      "Epoch 3, Batch: 25000| Training Loss: 2.912181992902756\n",
      "Epoch 3, Training Loss: 2.9106184281120004, Validation Error: 74.33673321128643, Validation Top-3 Accuracy: 45.90125824646973, Training Error: 72.88829888109235\n",
      "Epoch 4, Batch: 1000| Training Loss: 2.8472345204353333\n",
      "Epoch 4, Batch: 2000| Training Loss: 2.841963389873505\n",
      "Epoch 4, Batch: 3000| Training Loss: 2.840683022260666\n",
      "Epoch 4, Batch: 4000| Training Loss: 2.840290137499571\n",
      "Epoch 4, Batch: 5000| Training Loss: 2.8310180349826815\n",
      "Epoch 4, Batch: 6000| Training Loss: 2.826858473777771\n",
      "Epoch 4, Batch: 7000| Training Loss: 2.823676180209432\n",
      "Epoch 4, Batch: 8000| Training Loss: 2.8195690371245146\n",
      "Epoch 4, Batch: 9000| Training Loss: 2.818657794793447\n",
      "Epoch 4, Batch: 10000| Training Loss: 2.8161660451292994\n",
      "Epoch 4, Batch: 11000| Training Loss: 2.813642211480574\n",
      "Epoch 4, Batch: 12000| Training Loss: 2.810279815226793\n",
      "Epoch 4, Batch: 13000| Training Loss: 2.8083488430243273\n",
      "Epoch 4, Batch: 14000| Training Loss: 2.8067419288243567\n",
      "Epoch 4, Batch: 15000| Training Loss: 2.8043741691350936\n",
      "Epoch 4, Batch: 16000| Training Loss: 2.801354578591883\n",
      "Epoch 4, Batch: 17000| Training Loss: 2.798886652287315\n",
      "Epoch 4, Batch: 18000| Training Loss: 2.7970022896462017\n",
      "Epoch 4, Batch: 19000| Training Loss: 2.7941356245906728\n",
      "Epoch 4, Batch: 20000| Training Loss: 2.7931177794218063\n",
      "Epoch 4, Batch: 21000| Training Loss: 2.7914336742162704\n",
      "Epoch 4, Batch: 22000| Training Loss: 2.788882786349817\n",
      "Epoch 4, Batch: 23000| Training Loss: 2.7861152065111243\n",
      "Epoch 4, Batch: 24000| Training Loss: 2.7840932846864064\n",
      "Epoch 4, Batch: 25000| Training Loss: 2.78158749809742\n",
      "Epoch 4, Training Loss: 2.7803334090976835, Validation Error: 73.52308720541656, Validation Top-3 Accuracy: 46.97352744688932, Training Error: 71.3624489945737\n",
      "Epoch 5, Batch: 1000| Training Loss: 2.7503232909440993\n",
      "Epoch 5, Batch: 2000| Training Loss: 2.7431851140260695\n",
      "Epoch 5, Batch: 3000| Training Loss: 2.742925958673159\n",
      "Epoch 5, Batch: 4000| Training Loss: 2.7433976736366747\n",
      "Epoch 5, Batch: 5000| Training Loss: 2.735429484319687\n",
      "Epoch 5, Batch: 6000| Training Loss: 2.7319870011011758\n",
      "Epoch 5, Batch: 7000| Training Loss: 2.729166055253574\n",
      "Epoch 5, Batch: 8000| Training Loss: 2.7258504909723995\n",
      "Epoch 5, Batch: 9000| Training Loss: 2.7255642856491935\n",
      "Epoch 5, Batch: 10000| Training Loss: 2.72330943107605\n",
      "Epoch 5, Batch: 11000| Training Loss: 2.7212300214659084\n",
      "Epoch 5, Batch: 12000| Training Loss: 2.718216303706169\n",
      "Epoch 5, Batch: 13000| Training Loss: 2.7166780581841103\n",
      "Epoch 5, Batch: 14000| Training Loss: 2.7155301693422453\n",
      "Epoch 5, Batch: 15000| Training Loss: 2.7136465473413467\n",
      "Epoch 5, Batch: 16000| Training Loss: 2.710937145344913\n",
      "Epoch 5, Batch: 17000| Training Loss: 2.708697263801799\n",
      "Epoch 5, Batch: 18000| Training Loss: 2.707256145026949\n",
      "Epoch 5, Batch: 19000| Training Loss: 2.7046667062546077\n",
      "Epoch 5, Batch: 20000| Training Loss: 2.7040714063823224\n",
      "Epoch 5, Batch: 21000| Training Loss: 2.7027382278896512\n",
      "Epoch 5, Batch: 22000| Training Loss: 2.7006037548292765\n",
      "Epoch 5, Batch: 23000| Training Loss: 2.6983664329414783\n",
      "Epoch 5, Batch: 24000| Training Loss: 2.6966489586333435\n",
      "Epoch 5, Batch: 25000| Training Loss: 2.694535411877632\n",
      "Epoch 5, Training Loss: 2.693509607515379, Validation Error: 72.97678203004679, Validation Top-3 Accuracy: 47.714526486736965, Training Error: 70.37861779118211\n",
      "Epoch 6, Batch: 1000| Training Loss: 2.685300169467926\n",
      "Epoch 6, Batch: 2000| Training Loss: 2.677582105219364\n",
      "Epoch 6, Batch: 3000| Training Loss: 2.6778926556507745\n",
      "Epoch 6, Batch: 4000| Training Loss: 2.6790279506742953\n",
      "Epoch 6, Batch: 5000| Training Loss: 2.6716868950128556\n",
      "Epoch 6, Batch: 6000| Training Loss: 2.6688768330613772\n",
      "Epoch 6, Batch: 7000| Training Loss: 2.666120795420238\n",
      "Epoch 6, Batch: 8000| Training Loss: 2.663067936077714\n",
      "Epoch 6, Batch: 9000| Training Loss: 2.66277545773983\n",
      "Epoch 6, Batch: 10000| Training Loss: 2.6609107632756235\n",
      "Epoch 6, Batch: 11000| Training Loss: 2.6589836594191465\n",
      "Epoch 6, Batch: 12000| Training Loss: 2.6563256346186\n",
      "Epoch 6, Batch: 13000| Training Loss: 2.655052075817035\n",
      "Epoch 6, Batch: 14000| Training Loss: 2.654100790696485\n",
      "Epoch 6, Batch: 15000| Training Loss: 2.6523516079505285\n",
      "Epoch 6, Batch: 16000| Training Loss: 2.649903248369694\n",
      "Epoch 6, Batch: 17000| Training Loss: 2.6478227971161115\n",
      "Epoch 6, Batch: 18000| Training Loss: 2.6466453631652724\n",
      "Epoch 6, Batch: 19000| Training Loss: 2.644197550434815\n",
      "Epoch 6, Batch: 20000| Training Loss: 2.6437614857912064\n",
      "Epoch 6, Batch: 21000| Training Loss: 2.6426062157154084\n",
      "Epoch 6, Batch: 22000| Training Loss: 2.640676648286256\n",
      "Epoch 6, Batch: 23000| Training Loss: 2.638580253445584\n",
      "Epoch 6, Batch: 24000| Training Loss: 2.637031800394257\n",
      "Epoch 6, Batch: 25000| Training Loss: 2.6350659330511093\n",
      "Epoch 6, Training Loss: 2.634147851060714, Validation Error: 72.64696480981024, Validation Top-3 Accuracy: 48.118443611079506, Training Error: 69.65557955011226\n",
      "Epoch 7, Batch: 1000| Training Loss: 2.639013529062271\n",
      "Epoch 7, Batch: 2000| Training Loss: 2.632335887491703\n",
      "Epoch 7, Batch: 3000| Training Loss: 2.6334518223603567\n",
      "Epoch 7, Batch: 4000| Training Loss: 2.6345638402104377\n",
      "Epoch 7, Batch: 5000| Training Loss: 2.6274857970952987\n",
      "Epoch 7, Batch: 6000| Training Loss: 2.624602499385675\n",
      "Epoch 7, Batch: 7000| Training Loss: 2.621914629970278\n",
      "Epoch 7, Batch: 8000| Training Loss: 2.6191388222426175\n",
      "Epoch 7, Batch: 9000| Training Loss: 2.618940722372797\n",
      "Epoch 7, Batch: 10000| Training Loss: 2.616948248231411\n",
      "Epoch 7, Batch: 11000| Training Loss: 2.6151848739277233\n",
      "Epoch 7, Batch: 12000| Training Loss: 2.6126033655603726\n",
      "Epoch 7, Batch: 13000| Training Loss: 2.6115063859316017\n",
      "Epoch 7, Batch: 14000| Training Loss: 2.6106998269472803\n",
      "Epoch 7, Batch: 15000| Training Loss: 2.6090445515473686\n",
      "Epoch 7, Batch: 16000| Training Loss: 2.6066624905765057\n",
      "Epoch 7, Batch: 17000| Training Loss: 2.604841964819852\n",
      "Epoch 7, Batch: 18000| Training Loss: 2.603607551323043\n",
      "Epoch 7, Batch: 19000| Training Loss: 2.601259569419058\n",
      "Epoch 7, Batch: 20000| Training Loss: 2.6008927312552927\n",
      "Epoch 7, Batch: 21000| Training Loss: 2.5998962810096287\n",
      "Epoch 7, Batch: 22000| Training Loss: 2.598103395012292\n",
      "Epoch 7, Batch: 23000| Training Loss: 2.5960418548376665\n",
      "Epoch 7, Batch: 24000| Training Loss: 2.5946545254141093\n",
      "Epoch 7, Batch: 25000| Training Loss: 2.59269545627594\n",
      "Epoch 7, Training Loss: 2.591847537001842, Validation Error: 72.3578298898672, Validation Top-3 Accuracy: 48.34655508179474, Training Error: 69.11967845934554\n",
      "Epoch 8, Batch: 1000| Training Loss: 2.6064755642414092\n",
      "Epoch 8, Batch: 2000| Training Loss: 2.599916649401188\n",
      "Epoch 8, Batch: 3000| Training Loss: 2.6016660457452137\n",
      "Epoch 8, Batch: 4000| Training Loss: 2.602395138710737\n",
      "Epoch 8, Batch: 5000| Training Loss: 2.5955066236257553\n",
      "Epoch 8, Batch: 6000| Training Loss: 2.592838813463847\n",
      "Epoch 8, Batch: 7000| Training Loss: 2.5901660614865167\n",
      "Epoch 8, Batch: 8000| Training Loss: 2.58733392752707\n",
      "Epoch 8, Batch: 9000| Training Loss: 2.587564178850916\n",
      "Epoch 8, Batch: 10000| Training Loss: 2.5856376228809355\n",
      "Epoch 8, Batch: 11000| Training Loss: 2.5840525516379964\n",
      "Epoch 8, Batch: 12000| Training Loss: 2.5814534273942313\n",
      "Epoch 8, Batch: 13000| Training Loss: 2.5803328416164106\n",
      "Epoch 8, Batch: 14000| Training Loss: 2.5795928243398665\n",
      "Epoch 8, Batch: 15000| Training Loss: 2.577925791533788\n",
      "Epoch 8, Batch: 16000| Training Loss: 2.575623089849949\n",
      "Epoch 8, Batch: 17000| Training Loss: 2.573853932983735\n",
      "Epoch 8, Batch: 18000| Training Loss: 2.572701970981227\n",
      "Epoch 8, Batch: 19000| Training Loss: 2.5703974293156673\n",
      "Epoch 8, Batch: 20000| Training Loss: 2.5700979127943517\n",
      "Epoch 8, Batch: 21000| Training Loss: 2.5692663190251306\n",
      "Epoch 8, Batch: 22000| Training Loss: 2.5675760295174337\n",
      "Epoch 8, Batch: 23000| Training Loss: 2.565718868058661\n",
      "Epoch 8, Batch: 24000| Training Loss: 2.5643945365498464\n",
      "Epoch 8, Batch: 25000| Training Loss: 2.5625151151800156\n",
      "Epoch 8, Training Loss: 2.561702743463178, Validation Error: 72.16023014558452, Validation Top-3 Accuracy: 48.64150175771014, Training Error: 68.7438135847256\n",
      "Epoch 9, Batch: 1000| Training Loss: 2.5845847001075746\n",
      "Epoch 9, Batch: 2000| Training Loss: 2.577542078256607\n",
      "Epoch 9, Batch: 3000| Training Loss: 2.5787126348813376\n",
      "Epoch 9, Batch: 4000| Training Loss: 2.579888223975897\n",
      "Epoch 9, Batch: 5000| Training Loss: 2.573327467107773\n",
      "Epoch 9, Batch: 6000| Training Loss: 2.570638845205307\n",
      "Epoch 9, Batch: 7000| Training Loss: 2.5675133563791004\n",
      "Epoch 9, Batch: 8000| Training Loss: 2.5651421091258526\n",
      "Epoch 9, Batch: 9000| Training Loss: 2.5650546063582103\n",
      "Epoch 9, Batch: 10000| Training Loss: 2.563202931725979\n",
      "Epoch 9, Batch: 11000| Training Loss: 2.5614651249863885\n",
      "Epoch 9, Batch: 12000| Training Loss: 2.558929222593705\n",
      "Epoch 9, Batch: 13000| Training Loss: 2.5578428015525523\n",
      "Epoch 9, Batch: 14000| Training Loss: 2.5570287166322982\n",
      "Epoch 9, Batch: 15000| Training Loss: 2.55551614716053\n",
      "Epoch 9, Batch: 16000| Training Loss: 2.553303094774485\n",
      "Epoch 9, Batch: 17000| Training Loss: 2.551567654266077\n",
      "Epoch 9, Batch: 18000| Training Loss: 2.5503882195750873\n",
      "Epoch 9, Batch: 19000| Training Loss: 2.5481156351942764\n",
      "Epoch 9, Batch: 20000| Training Loss: 2.5478197799682616\n",
      "Epoch 9, Batch: 21000| Training Loss: 2.5470049419119243\n",
      "Epoch 9, Batch: 22000| Training Loss: 2.545286584165963\n",
      "Epoch 9, Batch: 23000| Training Loss: 2.5433601272158\n",
      "Epoch 9, Batch: 24000| Training Loss: 2.5420123490641515\n",
      "Epoch 9, Batch: 25000| Training Loss: 2.540224390501976\n",
      "Epoch 9, Training Loss: 2.5394104992192426, Validation Error: 72.09920669514428, Validation Top-3 Accuracy: 48.78824862662596, Training Error: 68.41976471739783\n",
      "Epoch 10, Batch: 1000| Training Loss: 2.56681403195858\n",
      "Epoch 10, Batch: 2000| Training Loss: 2.560149531841278\n",
      "Epoch 10, Batch: 3000| Training Loss: 2.561791538874308\n",
      "Epoch 10, Batch: 4000| Training Loss: 2.5628273230195044\n",
      "Epoch 10, Batch: 5000| Training Loss: 2.5566755803823473\n",
      "Epoch 10, Batch: 6000| Training Loss: 2.5542537104884784\n",
      "Epoch 10, Batch: 7000| Training Loss: 2.551227181008884\n",
      "Epoch 10, Batch: 8000| Training Loss: 2.5485607362091542\n",
      "Epoch 10, Batch: 9000| Training Loss: 2.548568366540803\n",
      "Epoch 10, Batch: 10000| Training Loss: 2.5467330105900765\n",
      "Epoch 10, Batch: 11000| Training Loss: 2.5449853281649677\n",
      "Epoch 10, Batch: 12000| Training Loss: 2.542459654589494\n",
      "Epoch 10, Batch: 13000| Training Loss: 2.5414291294996554\n",
      "Epoch 10, Batch: 14000| Training Loss: 2.5406890376039915\n",
      "Epoch 10, Batch: 15000| Training Loss: 2.5390507150014243\n",
      "Epoch 10, Batch: 16000| Training Loss: 2.5368099968954922\n",
      "Epoch 10, Batch: 17000| Training Loss: 2.535053325737224\n",
      "Epoch 10, Batch: 18000| Training Loss: 2.5339546286066374\n",
      "Epoch 10, Batch: 19000| Training Loss: 2.531782887007061\n",
      "Epoch 10, Batch: 20000| Training Loss: 2.5315011556088924\n",
      "Epoch 10, Batch: 21000| Training Loss: 2.530646411214556\n",
      "Epoch 10, Batch: 22000| Training Loss: 2.5289936655109577\n",
      "Epoch 10, Batch: 23000| Training Loss: 2.5271431494536607\n",
      "Epoch 10, Batch: 24000| Training Loss: 2.5257807784080506\n",
      "Epoch 10, Batch: 25000| Training Loss: 2.524061273508072\n",
      "Epoch 10, Training Loss: 2.5232615483487635, Validation Error: 72.00621858018772, Validation Top-3 Accuracy: 48.94371313131895, Training Error: 68.21042070682662\n",
      "Epoch 11, Batch: 1000| Training Loss: 2.553467501282692\n",
      "Epoch 11, Batch: 2000| Training Loss: 2.5473553225398065\n",
      "Epoch 11, Batch: 3000| Training Loss: 2.5490424966812135\n",
      "Epoch 11, Batch: 4000| Training Loss: 2.5502828776538373\n",
      "Epoch 11, Batch: 5000| Training Loss: 2.544268540596962\n",
      "Epoch 11, Batch: 6000| Training Loss: 2.541955498437087\n",
      "Epoch 11, Batch: 7000| Training Loss: 2.5392436019352504\n",
      "Epoch 11, Batch: 8000| Training Loss: 2.5366732833087444\n",
      "Epoch 11, Batch: 9000| Training Loss: 2.5366269638140997\n",
      "Epoch 11, Batch: 10000| Training Loss: 2.5349003220200537\n",
      "Epoch 11, Batch: 11000| Training Loss: 2.5331794048331\n",
      "Epoch 11, Batch: 12000| Training Loss: 2.530729010651509\n",
      "Epoch 11, Batch: 13000| Training Loss: 2.5298722680256915\n",
      "Epoch 11, Batch: 14000| Training Loss: 2.5290286399722097\n",
      "Epoch 11, Batch: 15000| Training Loss: 2.5274874745051066\n",
      "Epoch 11, Batch: 16000| Training Loss: 2.5252337026298046\n",
      "Epoch 11, Batch: 17000| Training Loss: 2.523595171430532\n",
      "Epoch 11, Batch: 18000| Training Loss: 2.5224497066338856\n",
      "Epoch 11, Batch: 19000| Training Loss: 2.5202910674998633\n",
      "Epoch 11, Batch: 20000| Training Loss: 2.5199994537711143\n",
      "Epoch 11, Batch: 21000| Training Loss: 2.519219618320465\n",
      "Epoch 11, Batch: 22000| Training Loss: 2.517544999637387\n",
      "Epoch 11, Batch: 23000| Training Loss: 2.5156791921491206\n",
      "Epoch 11, Batch: 24000| Training Loss: 2.5142452359199523\n",
      "Epoch 11, Batch: 25000| Training Loss: 2.512482847576141\n",
      "Epoch 11, Training Loss: 2.511693900683111, Validation Error: 71.94374219045127, Validation Top-3 Accuracy: 48.94952488850374, Training Error: 68.0267094082453\n",
      "Epoch 12, Batch: 1000| Training Loss: 2.543293838620186\n",
      "Epoch 12, Batch: 2000| Training Loss: 2.5373702046871185\n",
      "Epoch 12, Batch: 3000| Training Loss: 2.5392526483535764\n",
      "Epoch 12, Batch: 4000| Training Loss: 2.540057442396879\n",
      "Epoch 12, Batch: 5000| Training Loss: 2.5342420295238495\n",
      "Epoch 12, Batch: 6000| Training Loss: 2.5319489828745523\n",
      "Epoch 12, Batch: 7000| Training Loss: 2.5293134885685786\n",
      "Epoch 12, Batch: 8000| Training Loss: 2.5269579568207265\n",
      "Epoch 12, Batch: 9000| Training Loss: 2.527011247171296\n",
      "Epoch 12, Batch: 10000| Training Loss: 2.525254525077343\n",
      "Epoch 12, Batch: 11000| Training Loss: 2.523629799398509\n",
      "Epoch 12, Batch: 12000| Training Loss: 2.521135803103447\n",
      "Epoch 12, Batch: 13000| Training Loss: 2.5202142969553285\n",
      "Epoch 12, Batch: 14000| Training Loss: 2.519520762673446\n",
      "Epoch 12, Batch: 15000| Training Loss: 2.5180878323396048\n",
      "Epoch 12, Batch: 16000| Training Loss: 2.5159356627017258\n",
      "Epoch 12, Batch: 17000| Training Loss: 2.5143566462993623\n",
      "Epoch 12, Batch: 18000| Training Loss: 2.5132497075862354\n",
      "Epoch 12, Batch: 19000| Training Loss: 2.511050005222622\n",
      "Epoch 12, Batch: 20000| Training Loss: 2.5108310621142387\n",
      "Epoch 12, Batch: 21000| Training Loss: 2.510173068676676\n",
      "Epoch 12, Batch: 22000| Training Loss: 2.5085379406593065\n",
      "Epoch 12, Batch: 23000| Training Loss: 2.5066986654582233\n",
      "Epoch 12, Batch: 24000| Training Loss: 2.5053915408551695\n",
      "Epoch 12, Batch: 25000| Training Loss: 2.50370935195446\n",
      "Epoch 12, Training Loss: 2.502957239267494, Validation Error: 71.90451282945398, Validation Top-3 Accuracy: 49.04541888205269, Training Error: 67.93194790258346\n",
      "Epoch 13, Batch: 1000| Training Loss: 2.5370378701686858\n",
      "Epoch 13, Batch: 2000| Training Loss: 2.5322136712670327\n",
      "Epoch 13, Batch: 3000| Training Loss: 2.533961107691129\n",
      "Epoch 13, Batch: 4000| Training Loss: 2.535274796783924\n",
      "Epoch 13, Batch: 5000| Training Loss: 2.5295150082588194\n",
      "Epoch 13, Batch: 6000| Training Loss: 2.526884123543898\n",
      "Epoch 13, Batch: 7000| Training Loss: 2.524285138266427\n",
      "Epoch 13, Batch: 8000| Training Loss: 2.521792883276939\n",
      "Epoch 13, Batch: 9000| Training Loss: 2.521888610985544\n",
      "Epoch 13, Batch: 10000| Training Loss: 2.5201230486273767\n",
      "Epoch 13, Batch: 11000| Training Loss: 2.5184295614741066\n",
      "Epoch 13, Batch: 12000| Training Loss: 2.5160482522249223\n",
      "Epoch 13, Batch: 13000| Training Loss: 2.5152424144378074\n",
      "Epoch 13, Batch: 14000| Training Loss: 2.514633881568909\n",
      "Epoch 13, Batch: 15000| Training Loss: 2.5131953220685324\n",
      "Epoch 13, Batch: 16000| Training Loss: 2.5110844136923554\n",
      "Epoch 13, Batch: 17000| Training Loss: 2.5095186686656055\n",
      "Epoch 13, Batch: 18000| Training Loss: 2.5085785607496898\n",
      "Epoch 13, Batch: 19000| Training Loss: 2.5064251913773385\n",
      "Epoch 13, Batch: 20000| Training Loss: 2.5063172518253327\n",
      "Epoch 13, Batch: 21000| Training Loss: 2.5056253214166277\n",
      "Epoch 13, Batch: 22000| Training Loss: 2.5040595415938984\n",
      "Epoch 13, Batch: 23000| Training Loss: 2.5022736714404563\n",
      "Epoch 13, Batch: 24000| Training Loss: 2.501023840546608\n",
      "Epoch 13, Batch: 25000| Training Loss: 2.4993077702903745\n",
      "Epoch 13, Training Loss: 2.4985281681129567, Validation Error: 71.93357161537791, Validation Top-3 Accuracy: 49.0396071248679, Training Error: 67.8664896643277\n",
      "Epoch 14, Batch: 1000| Training Loss: 2.534256413698196\n",
      "Epoch 14, Batch: 2000| Training Loss: 2.527533575296402\n",
      "Epoch 14, Batch: 3000| Training Loss: 2.528925926407178\n",
      "Epoch 14, Batch: 4000| Training Loss: 2.5303451940715314\n",
      "Epoch 14, Batch: 5000| Training Loss: 2.524634659767151\n",
      "Epoch 14, Batch: 6000| Training Loss: 2.522538906951745\n",
      "Epoch 14, Batch: 7000| Training Loss: 2.519612705860819\n",
      "Epoch 14, Batch: 8000| Training Loss: 2.517171920314431\n",
      "Epoch 14, Batch: 9000| Training Loss: 2.517205743485027\n",
      "Epoch 14, Batch: 10000| Training Loss: 2.5155436821699144\n",
      "Epoch 14, Batch: 11000| Training Loss: 2.5138857527212664\n",
      "Epoch 14, Batch: 12000| Training Loss: 2.5117356292307376\n",
      "Epoch 14, Batch: 13000| Training Loss: 2.510960995564094\n",
      "Epoch 14, Batch: 14000| Training Loss: 2.5103062401413916\n",
      "Epoch 14, Batch: 15000| Training Loss: 2.5089368913412096\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('validation_error_model_rnn.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4 (attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274809\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=1, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # alpha can be set to a constant, or it can be a tensor of shape (num_classes,)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability 0\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "# Reload the data with particular batch size\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 128\n",
    "d_embed = 64\n",
    "NUM_EPOCHS = 15\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalThree(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=1, reduction='mean')\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.72 # This causes the LR to be 5e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1000| Training Loss: 5.287326567173004\n",
      "Epoch 1, Batch: 2000| Training Loss: 5.047864525914192\n",
      "Epoch 1, Batch: 3000| Training Loss: 4.905219877481461\n",
      "Epoch 1, Batch: 4000| Training Loss: 4.79524082493782\n",
      "Epoch 1, Batch: 5000| Training Loss: 4.70671489186287\n",
      "Epoch 1, Batch: 6000| Training Loss: 4.622613087058068\n",
      "Epoch 1, Batch: 7000| Training Loss: 4.555860832350595\n",
      "Epoch 1, Batch: 8000| Training Loss: 4.496502450019121\n",
      "Epoch 1, Batch: 9000| Training Loss: 4.445127610709932\n",
      "Epoch 1, Batch: 10000| Training Loss: 4.398497691917419\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_error,train_loss_values, val_error, val_loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the training error\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(device, model, train_loader, val_loader, criterion, optimizer, num_epochs, learn_decay)\u001b[0m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 23\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# For logging purposes\u001b[39;00m\n\u001b[1;32m     25\u001b[0m training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/cis400/enpoisson/.venv/lib/python3.9/site-packages/torch/optim/adam.py:432\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    434\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('validation_error_model_rnn.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5 \n",
    "scaling experiment 3 more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887027\n"
     ]
    }
   ],
   "source": [
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.95 * total_size)\n",
    "val_size = int(total_size * 0.04)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257737\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=1, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # alpha can be set to a constant, or it can be a tensor of shape (num_classes,)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability 0\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "# Reload the data with particular batch size\n",
    "torch.multiprocessing.set_start_method('fork', force=True)\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 256\n",
    "d_embed = 64\n",
    "NUM_EPOCHS = 20\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalTwo(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=1, reduction='mean')\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.72 # This causes the LR to be 5e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1000| Training Loss: 4.8901955642700194\n",
      "Epoch 1, Batch: 2000| Training Loss: 4.567499182343483\n",
      "Epoch 1, Batch: 3000| Training Loss: 4.370153081734975\n",
      "Epoch 1, Batch: 4000| Training Loss: 4.225781790912151\n",
      "Epoch 1, Batch: 5000| Training Loss: 4.115331648445129\n",
      "Epoch 1, Batch: 6000| Training Loss: 4.026681294282278\n",
      "Epoch 1, Batch: 7000| Training Loss: 3.9509704538413457\n",
      "Epoch 1, Batch: 8000| Training Loss: 3.886772244900465\n",
      "Epoch 1, Batch: 9000| Training Loss: 3.830372013224496\n",
      "Epoch 1, Batch: 10000| Training Loss: 3.78042985496521\n",
      "Epoch 1, Batch: 11000| Training Loss: 3.73538499064879\n",
      "Epoch 1, Batch: 12000| Training Loss: 3.694986932992935\n",
      "Epoch 1, Batch: 13000| Training Loss: 3.658469080888308\n",
      "Epoch 1, Batch: 14000| Training Loss: 3.6249415147134236\n",
      "Epoch 1, Batch: 15000| Training Loss: 3.593752561632792\n",
      "Epoch 1, Batch: 16000| Training Loss: 3.564824816510081\n",
      "Epoch 1, Batch: 17000| Training Loss: 3.53814223948647\n",
      "Epoch 1, Batch: 18000| Training Loss: 3.513119463377529\n",
      "Epoch 1, Batch: 19000| Training Loss: 3.4891034611024354\n",
      "Epoch 1, Batch: 20000| Training Loss: 3.4668145275712012\n",
      "Epoch 1, Batch: 21000| Training Loss: 3.445526287317276\n",
      "Epoch 1, Batch: 22000| Training Loss: 3.4259103984399277\n",
      "Epoch 1, Training Loss: 3.4156654808215254, Validation Error: 74.25200931235038, Validation Top-3 Accuracy: 46.27218058654262, Training Error: 78.06075246265449\n",
      "Epoch 2, Batch: 1000| Training Loss: 2.893364725828171\n",
      "Epoch 2, Batch: 2000| Training Loss: 2.8836944414377212\n",
      "Epoch 2, Batch: 3000| Training Loss: 2.8836330687999725\n",
      "Epoch 2, Batch: 4000| Training Loss: 2.8776137053370476\n",
      "Epoch 2, Batch: 5000| Training Loss: 2.8716679653167723\n",
      "Epoch 2, Batch: 6000| Training Loss: 2.866698518951734\n",
      "Epoch 2, Batch: 7000| Training Loss: 2.8632999100003924\n",
      "Epoch 2, Batch: 8000| Training Loss: 2.8577439508140086\n",
      "Epoch 2, Batch: 9000| Training Loss: 2.854327395306693\n",
      "Epoch 2, Batch: 10000| Training Loss: 2.851452553606033\n",
      "Epoch 2, Batch: 11000| Training Loss: 2.8469971785328605\n",
      "Epoch 2, Batch: 12000| Training Loss: 2.8438475562731425\n",
      "Epoch 2, Batch: 13000| Training Loss: 2.8401025356146006\n",
      "Epoch 2, Batch: 14000| Training Loss: 2.8377385467631475\n",
      "Epoch 2, Batch: 15000| Training Loss: 2.8345427823066713\n",
      "Epoch 2, Batch: 16000| Training Loss: 2.83125857283175\n",
      "Epoch 2, Batch: 17000| Training Loss: 2.8281631110696233\n",
      "Epoch 2, Batch: 18000| Training Loss: 2.8254549468358356\n",
      "Epoch 2, Batch: 19000| Training Loss: 2.82206088339655\n",
      "Epoch 2, Batch: 20000| Training Loss: 2.8186651324510574\n",
      "Epoch 2, Batch: 21000| Training Loss: 2.8152023790223257\n",
      "Epoch 2, Batch: 22000| Training Loss: 2.8123090622208333\n",
      "Epoch 2, Training Loss: 2.810361592665503, Validation Error: 71.95271431979532, Validation Top-3 Accuracy: 49.44759334906946, Training Error: 72.4512794649998\n",
      "Epoch 3, Batch: 1000| Training Loss: 2.6587062869071962\n",
      "Epoch 3, Batch: 2000| Training Loss: 2.660412595868111\n",
      "Epoch 3, Batch: 3000| Training Loss: 2.6565345111687977\n",
      "Epoch 3, Batch: 4000| Training Loss: 2.655539228796959\n",
      "Epoch 3, Batch: 5000| Training Loss: 2.65376002368927\n",
      "Epoch 3, Batch: 6000| Training Loss: 2.6534651137987773\n",
      "Epoch 3, Batch: 7000| Training Loss: 2.6520943156651087\n",
      "Epoch 3, Batch: 8000| Training Loss: 2.649502309203148\n",
      "Epoch 3, Batch: 9000| Training Loss: 2.6475289831956226\n",
      "Epoch 3, Batch: 10000| Training Loss: 2.6460900339841844\n",
      "Epoch 3, Batch: 11000| Training Loss: 2.6461275978521868\n",
      "Epoch 3, Batch: 12000| Training Loss: 2.6452931722005206\n",
      "Epoch 3, Batch: 13000| Training Loss: 2.644634838947883\n",
      "Epoch 3, Batch: 14000| Training Loss: 2.6435824951103757\n",
      "Epoch 3, Batch: 15000| Training Loss: 2.6427984112262726\n",
      "Epoch 3, Batch: 16000| Training Loss: 2.642073568686843\n",
      "Epoch 3, Batch: 17000| Training Loss: 2.6414503986695235\n",
      "Epoch 3, Batch: 18000| Training Loss: 2.640105093333456\n",
      "Epoch 3, Batch: 19000| Training Loss: 2.639359418241601\n",
      "Epoch 3, Batch: 20000| Training Loss: 2.63791067994833\n",
      "Epoch 3, Batch: 21000| Training Loss: 2.636920425619398\n",
      "Epoch 3, Batch: 22000| Training Loss: 2.635801821871237\n",
      "Epoch 3, Training Loss: 2.635335211710506, Validation Error: 70.41683462351615, Validation Top-3 Accuracy: 51.563438330750365, Training Error: 70.57346536766022\n",
      "Epoch 4, Batch: 1000| Training Loss: 2.5373446280956267\n",
      "Epoch 4, Batch: 2000| Training Loss: 2.5378602505922316\n",
      "Epoch 4, Batch: 3000| Training Loss: 2.5392682309150696\n",
      "Epoch 4, Batch: 4000| Training Loss: 2.5401832346618174\n",
      "Epoch 4, Batch: 5000| Training Loss: 2.5402788125276565\n",
      "Epoch 4, Batch: 6000| Training Loss: 2.539152854581674\n",
      "Epoch 4, Batch: 7000| Training Loss: 2.5397133933646336\n",
      "Epoch 4, Batch: 8000| Training Loss: 2.538323600783944\n",
      "Epoch 4, Batch: 9000| Training Loss: 2.538986832923359\n",
      "Epoch 4, Batch: 10000| Training Loss: 2.5394639040112494\n",
      "Epoch 4, Batch: 11000| Training Loss: 2.539126297235489\n",
      "Epoch 4, Batch: 12000| Training Loss: 2.5385362767577173\n",
      "Epoch 4, Batch: 13000| Training Loss: 2.5386976237480456\n",
      "Epoch 4, Batch: 14000| Training Loss: 2.5386198419502803\n",
      "Epoch 4, Batch: 15000| Training Loss: 2.5382642931461334\n",
      "Epoch 4, Batch: 16000| Training Loss: 2.53728503421694\n",
      "Epoch 4, Batch: 17000| Training Loss: 2.5373583403545266\n",
      "Epoch 4, Batch: 18000| Training Loss: 2.536750103639232\n",
      "Epoch 4, Batch: 19000| Training Loss: 2.536310265986543\n",
      "Epoch 4, Batch: 20000| Training Loss: 2.5361923887073994\n",
      "Epoch 4, Batch: 21000| Training Loss: 2.535852656074933\n",
      "Epoch 4, Batch: 22000| Training Loss: 2.5350949660648\n",
      "Epoch 4, Training Loss: 2.534877386718916, Validation Error: 69.84345050551585, Validation Top-3 Accuracy: 52.3819708951841, Training Error: 69.4496449115301\n",
      "Epoch 5, Batch: 1000| Training Loss: 2.455795768737793\n",
      "Epoch 5, Batch: 2000| Training Loss: 2.460999011874199\n",
      "Epoch 5, Batch: 3000| Training Loss: 2.4619812879165015\n",
      "Epoch 5, Batch: 4000| Training Loss: 2.462228125602007\n",
      "Epoch 5, Batch: 5000| Training Loss: 2.4624160793542864\n",
      "Epoch 5, Batch: 6000| Training Loss: 2.4629662223855653\n",
      "Epoch 5, Batch: 7000| Training Loss: 2.4638458723340717\n",
      "Epoch 5, Batch: 8000| Training Loss: 2.464811232045293\n",
      "Epoch 5, Batch: 9000| Training Loss: 2.4651653567552567\n",
      "Epoch 5, Batch: 10000| Training Loss: 2.465524309003353\n",
      "Epoch 5, Batch: 11000| Training Loss: 2.4646290250799874\n",
      "Epoch 5, Batch: 12000| Training Loss: 2.4653761232495306\n",
      "Epoch 5, Batch: 13000| Training Loss: 2.465448584373181\n",
      "Epoch 5, Batch: 14000| Training Loss: 2.46615939615454\n",
      "Epoch 5, Batch: 15000| Training Loss: 2.4670228997151056\n",
      "Epoch 5, Batch: 16000| Training Loss: 2.4669904708266257\n",
      "Epoch 5, Batch: 17000| Training Loss: 2.4669475665232716\n",
      "Epoch 5, Batch: 18000| Training Loss: 2.467372151719199\n",
      "Epoch 5, Batch: 19000| Training Loss: 2.46657068677325\n",
      "Epoch 5, Batch: 20000| Training Loss: 2.4669268784105776\n",
      "Epoch 5, Batch: 21000| Training Loss: 2.4671169070346015\n",
      "Epoch 5, Batch: 22000| Training Loss: 2.4668977806188845\n",
      "Epoch 5, Training Loss: 2.4670340014095977, Validation Error: 69.42883702564187, Validation Top-3 Accuracy: 52.92327182591788, Training Error: 68.63125976999869\n",
      "Epoch 6, Batch: 1000| Training Loss: 2.419654834270477\n",
      "Epoch 6, Batch: 2000| Training Loss: 2.4167861628532408\n",
      "Epoch 6, Batch: 3000| Training Loss: 2.4191631760199863\n",
      "Epoch 6, Batch: 4000| Training Loss: 2.4213009018599987\n",
      "Epoch 6, Batch: 5000| Training Loss: 2.4174878660202026\n",
      "Epoch 6, Batch: 6000| Training Loss: 2.4182306553721427\n",
      "Epoch 6, Batch: 7000| Training Loss: 2.4169263096877507\n",
      "Epoch 6, Batch: 8000| Training Loss: 2.4180281056463717\n",
      "Epoch 6, Batch: 9000| Training Loss: 2.417644326686859\n",
      "Epoch 6, Batch: 10000| Training Loss: 2.417822077333927\n",
      "Epoch 6, Batch: 11000| Training Loss: 2.4185188487334686\n",
      "Epoch 6, Batch: 12000| Training Loss: 2.419176219075918\n",
      "Epoch 6, Batch: 13000| Training Loss: 2.4193954980831878\n",
      "Epoch 6, Batch: 14000| Training Loss: 2.4198527453371454\n",
      "Epoch 6, Batch: 15000| Training Loss: 2.4196537686824797\n",
      "Epoch 6, Batch: 16000| Training Loss: 2.4191935260593893\n",
      "Epoch 6, Batch: 17000| Training Loss: 2.4192302016791176\n",
      "Epoch 6, Batch: 18000| Training Loss: 2.4193683308826555\n",
      "Epoch 6, Batch: 19000| Training Loss: 2.419960308507869\n",
      "Epoch 6, Batch: 20000| Training Loss: 2.4199153790593146\n",
      "Epoch 6, Batch: 21000| Training Loss: 2.4198145930256163\n",
      "Epoch 6, Batch: 22000| Training Loss: 2.4201598398414523\n",
      "Epoch 6, Training Loss: 2.420205845058004, Validation Error: 69.117054269943, Validation Top-3 Accuracy: 53.33706266132235, Training Error: 68.06115772384533\n",
      "Epoch 7, Batch: 1000| Training Loss: 2.3790047734975817\n",
      "Epoch 7, Batch: 2000| Training Loss: 2.3771031531095503\n",
      "Epoch 7, Batch: 3000| Training Loss: 2.379221451997757\n",
      "Epoch 7, Batch: 4000| Training Loss: 2.3799567646086217\n",
      "Epoch 7, Batch: 5000| Training Loss: 2.3809941782474517\n",
      "Epoch 7, Batch: 6000| Training Loss: 2.380127229332924\n",
      "Epoch 7, Batch: 7000| Training Loss: 2.381038961700031\n",
      "Epoch 7, Batch: 8000| Training Loss: 2.3811717367321252\n",
      "Epoch 7, Batch: 9000| Training Loss: 2.3818032717704773\n",
      "Epoch 7, Batch: 10000| Training Loss: 2.381688229179382\n",
      "Epoch 7, Batch: 11000| Training Loss: 2.3818280137018726\n",
      "Epoch 7, Batch: 12000| Training Loss: 2.381949381887913\n",
      "Epoch 7, Batch: 13000| Training Loss: 2.3825775895393813\n",
      "Epoch 7, Batch: 14000| Training Loss: 2.383774033810411\n",
      "Epoch 7, Batch: 15000| Training Loss: 2.383695242301623\n",
      "Epoch 7, Batch: 16000| Training Loss: 2.38421569942683\n",
      "Epoch 7, Batch: 17000| Training Loss: 2.384711362544228\n",
      "Epoch 7, Batch: 18000| Training Loss: 2.385281611310111\n",
      "Epoch 7, Batch: 19000| Training Loss: 2.3856527621432355\n",
      "Epoch 7, Batch: 20000| Training Loss: 2.3859968790113926\n",
      "Epoch 7, Batch: 21000| Training Loss: 2.386258827175413\n",
      "Epoch 7, Batch: 22000| Training Loss: 2.3860613055771047\n",
      "Epoch 7, Training Loss: 2.386333574019364, Validation Error: 68.8990531346918, Validation Top-3 Accuracy: 53.70972120333024, Training Error: 67.6129804120294\n",
      "Epoch 8, Batch: 1000| Training Loss: 2.355353504896164\n",
      "Epoch 8, Batch: 2000| Training Loss: 2.3527956774234773\n",
      "Epoch 8, Batch: 3000| Training Loss: 2.352193969766299\n",
      "Epoch 8, Batch: 4000| Training Loss: 2.3528059957027434\n",
      "Epoch 8, Batch: 5000| Training Loss: 2.3531359355926513\n",
      "Epoch 8, Batch: 6000| Training Loss: 2.354752776801586\n",
      "Epoch 8, Batch: 7000| Training Loss: 2.355709219438689\n",
      "Epoch 8, Batch: 8000| Training Loss: 2.356635967865586\n",
      "Epoch 8, Batch: 9000| Training Loss: 2.3584397954013614\n",
      "Epoch 8, Batch: 10000| Training Loss: 2.358787253332138\n",
      "Epoch 8, Batch: 11000| Training Loss: 2.3592840192426334\n",
      "Epoch 8, Batch: 12000| Training Loss: 2.3601197704772154\n",
      "Epoch 8, Batch: 13000| Training Loss: 2.360092986932168\n",
      "Epoch 8, Batch: 14000| Training Loss: 2.3605041221550533\n",
      "Epoch 8, Batch: 15000| Training Loss: 2.360752533133825\n",
      "Epoch 8, Batch: 16000| Training Loss: 2.3606591424643995\n",
      "Epoch 8, Batch: 17000| Training Loss: 2.3609376969197218\n",
      "Epoch 8, Batch: 18000| Training Loss: 2.361379274215963\n",
      "Epoch 8, Batch: 19000| Training Loss: 2.3609146015204883\n",
      "Epoch 8, Batch: 20000| Training Loss: 2.361237249964476\n",
      "Epoch 8, Batch: 21000| Training Loss: 2.361383011721429\n",
      "Epoch 8, Batch: 22000| Training Loss: 2.361390817430886\n",
      "Epoch 8, Training Loss: 2.361541902419073, Validation Error: 68.82583765907913, Validation Top-3 Accuracy: 53.85286157246071, Training Error: 67.27484710049472\n",
      "Epoch 9, Batch: 1000| Training Loss: 2.343248121857643\n",
      "Epoch 9, Batch: 2000| Training Loss: 2.33840684479475\n",
      "Epoch 9, Batch: 3000| Training Loss: 2.3345756745735806\n",
      "Epoch 9, Batch: 4000| Training Loss: 2.334844011515379\n",
      "Epoch 9, Batch: 5000| Training Loss: 2.337282319545746\n",
      "Epoch 9, Batch: 6000| Training Loss: 2.3364753420948983\n",
      "Epoch 9, Batch: 7000| Training Loss: 2.336550540242876\n",
      "Epoch 9, Batch: 8000| Training Loss: 2.3379760411828756\n",
      "Epoch 9, Batch: 9000| Training Loss: 2.3389275206062528\n",
      "Epoch 9, Batch: 10000| Training Loss: 2.338641825568676\n",
      "Epoch 9, Batch: 11000| Training Loss: 2.3393597597425635\n",
      "Epoch 9, Batch: 12000| Training Loss: 2.339337812036276\n",
      "Epoch 9, Batch: 13000| Training Loss: 2.340003566952852\n",
      "Epoch 9, Batch: 14000| Training Loss: 2.3401936278939246\n",
      "Epoch 9, Batch: 15000| Training Loss: 2.3406496274550754\n",
      "Epoch 9, Batch: 16000| Training Loss: 2.3404493429884314\n",
      "Epoch 9, Batch: 17000| Training Loss: 2.3412417228292015\n",
      "Epoch 9, Batch: 18000| Training Loss: 2.3416730526884395\n",
      "Epoch 9, Batch: 19000| Training Loss: 2.34225922783425\n",
      "Epoch 9, Batch: 20000| Training Loss: 2.3430071886956694\n",
      "Epoch 9, Batch: 21000| Training Loss: 2.3433439427557445\n",
      "Epoch 9, Batch: 22000| Training Loss: 2.343580468486656\n",
      "Epoch 9, Training Loss: 2.3434209874029883, Validation Error: 68.70161814427561, Validation Top-3 Accuracy: 53.995179294988716, Training Error: 67.00747862766784\n",
      "Epoch 10, Batch: 1000| Training Loss: 2.326173402428627\n",
      "Epoch 10, Batch: 2000| Training Loss: 2.323601600944996\n",
      "Epoch 10, Batch: 3000| Training Loss: 2.322156659245491\n",
      "Epoch 10, Batch: 4000| Training Loss: 2.3246209776103495\n",
      "Epoch 10, Batch: 5000| Training Loss: 2.3266056490659714\n",
      "Epoch 10, Batch: 6000| Training Loss: 2.3252954720258714\n",
      "Epoch 10, Batch: 7000| Training Loss: 2.32556051504612\n",
      "Epoch 10, Batch: 8000| Training Loss: 2.326784903869033\n",
      "Epoch 10, Batch: 9000| Training Loss: 2.327316428250737\n",
      "Epoch 10, Batch: 10000| Training Loss: 2.3284989197015764\n",
      "Epoch 10, Batch: 11000| Training Loss: 2.328769271785563\n",
      "Epoch 10, Batch: 12000| Training Loss: 2.329203953852256\n",
      "Epoch 10, Batch: 13000| Training Loss: 2.3281029187440874\n",
      "Epoch 10, Batch: 14000| Training Loss: 2.3284268620950836\n",
      "Epoch 10, Batch: 15000| Training Loss: 2.3288593555847803\n",
      "Epoch 10, Batch: 16000| Training Loss: 2.3291616204455496\n",
      "Epoch 10, Batch: 17000| Training Loss: 2.329139161032789\n",
      "Epoch 10, Batch: 18000| Training Loss: 2.329000196059545\n",
      "Epoch 10, Batch: 19000| Training Loss: 2.3291733644196864\n",
      "Epoch 10, Batch: 20000| Training Loss: 2.3294779668807983\n",
      "Epoch 10, Batch: 21000| Training Loss: 2.3301093139024007\n",
      "Epoch 10, Batch: 22000| Training Loss: 2.3301223629658874\n",
      "Epoch 10, Training Loss: 2.330081803918651, Validation Error: 68.61524033596854, Validation Top-3 Accuracy: 54.12351203848955, Training Error: 66.83806559481431\n",
      "Epoch 11, Batch: 1000| Training Loss: 2.320248378276825\n",
      "Epoch 11, Batch: 2000| Training Loss: 2.3232146115899086\n",
      "Epoch 11, Batch: 3000| Training Loss: 2.3211148833433786\n",
      "Epoch 11, Batch: 4000| Training Loss: 2.3167290226519106\n",
      "Epoch 11, Batch: 5000| Training Loss: 2.3150871884822846\n",
      "Epoch 11, Batch: 6000| Training Loss: 2.315989162524541\n",
      "Epoch 11, Batch: 7000| Training Loss: 2.3172398632764817\n",
      "Epoch 11, Batch: 8000| Training Loss: 2.317234185859561\n",
      "Epoch 11, Batch: 9000| Training Loss: 2.3177481820980708\n",
      "Epoch 11, Batch: 10000| Training Loss: 2.317300459611416\n",
      "Epoch 11, Batch: 11000| Training Loss: 2.3181303909150035\n",
      "Epoch 11, Batch: 12000| Training Loss: 2.3183858663737773\n",
      "Epoch 11, Batch: 13000| Training Loss: 2.318166563804333\n",
      "Epoch 11, Batch: 14000| Training Loss: 2.3186034975647924\n",
      "Epoch 11, Batch: 15000| Training Loss: 2.318682140350342\n",
      "Epoch 11, Batch: 16000| Training Loss: 2.3187896403968336\n",
      "Epoch 11, Batch: 17000| Training Loss: 2.3189003146395963\n",
      "Epoch 11, Batch: 18000| Training Loss: 2.3192332382202148\n",
      "Epoch 11, Batch: 19000| Training Loss: 2.3192299381933714\n",
      "Epoch 11, Batch: 20000| Training Loss: 2.3197124170958996\n",
      "Epoch 11, Batch: 21000| Training Loss: 2.3200572933412733\n",
      "Epoch 11, Batch: 22000| Training Loss: 2.32039762404832\n",
      "Epoch 11, Training Loss: 2.3203892753753714, Validation Error: 68.60865916962133, Validation Top-3 Accuracy: 54.16299903573922, Training Error: 66.69258721861624\n",
      "Epoch 12, Batch: 1000| Training Loss: 2.3022127519845963\n",
      "Epoch 12, Batch: 2000| Training Loss: 2.301250276327133\n",
      "Epoch 12, Batch: 3000| Training Loss: 2.304004633029302\n",
      "Epoch 12, Batch: 4000| Training Loss: 2.306507342517376\n",
      "Epoch 12, Batch: 5000| Training Loss: 2.3085814579248427\n",
      "Epoch 12, Batch: 6000| Training Loss: 2.308705147703489\n",
      "Epoch 12, Batch: 7000| Training Loss: 2.3081579592568535\n",
      "Epoch 12, Batch: 8000| Training Loss: 2.3081481655836105\n",
      "Epoch 12, Batch: 9000| Training Loss: 2.3088017545408674\n",
      "Epoch 12, Batch: 10000| Training Loss: 2.3090193758130075\n",
      "Epoch 12, Batch: 11000| Training Loss: 2.310092220956629\n",
      "Epoch 12, Batch: 12000| Training Loss: 2.3097516772945723\n",
      "Epoch 12, Batch: 13000| Training Loss: 2.3101705967921475\n",
      "Epoch 12, Batch: 14000| Training Loss: 2.3107054893374444\n",
      "Epoch 12, Batch: 15000| Training Loss: 2.3104774075031282\n",
      "Epoch 12, Batch: 16000| Training Loss: 2.310750900611281\n",
      "Epoch 12, Batch: 17000| Training Loss: 2.3110339033463423\n",
      "Epoch 12, Batch: 18000| Training Loss: 2.3111163588232464\n",
      "Epoch 12, Batch: 19000| Training Loss: 2.311869910917784\n",
      "Epoch 12, Batch: 20000| Training Loss: 2.3125333769619463\n",
      "Epoch 12, Batch: 21000| Training Loss: 2.3127127315430416\n",
      "Epoch 12, Batch: 22000| Training Loss: 2.313155340005051\n",
      "Epoch 12, Training Loss: 2.3132959932002968, Validation Error: 68.54367015194268, Validation Top-3 Accuracy: 54.22387482793225, Training Error: 66.5995503332667\n",
      "Epoch 13, Batch: 1000| Training Loss: 2.3010719527006147\n",
      "Epoch 13, Batch: 2000| Training Loss: 2.3035984916090966\n",
      "Epoch 13, Batch: 3000| Training Loss: 2.303844014406204\n",
      "Epoch 13, Batch: 4000| Training Loss: 2.3073221991658213\n",
      "Epoch 13, Batch: 5000| Training Loss: 2.3069070588111877\n",
      "Epoch 13, Batch: 6000| Training Loss: 2.307462014754613\n",
      "Epoch 13, Batch: 7000| Training Loss: 2.308490666644914\n",
      "Epoch 13, Batch: 8000| Training Loss: 2.3079448377788068\n",
      "Epoch 13, Batch: 9000| Training Loss: 2.3075583691332073\n",
      "Epoch 13, Batch: 10000| Training Loss: 2.3068897755265234\n",
      "Epoch 13, Batch: 11000| Training Loss: 2.3072378239198166\n",
      "Epoch 13, Batch: 12000| Training Loss: 2.3077778705656526\n",
      "Epoch 13, Batch: 13000| Training Loss: 2.3080335990740704\n",
      "Epoch 13, Batch: 14000| Training Loss: 2.3082812606181418\n",
      "Epoch 13, Batch: 15000| Training Loss: 2.308842882593473\n",
      "Epoch 13, Batch: 16000| Training Loss: 2.3089996145293115\n",
      "Epoch 13, Batch: 17000| Training Loss: 2.3089514522692736\n",
      "Epoch 13, Batch: 18000| Training Loss: 2.3093723546001645\n",
      "Epoch 13, Batch: 19000| Training Loss: 2.3099595532731008\n",
      "Epoch 13, Batch: 20000| Training Loss: 2.3099264594256876\n",
      "Epoch 13, Batch: 21000| Training Loss: 2.3096473640941437\n",
      "Epoch 13, Batch: 22000| Training Loss: 2.310232784861868\n",
      "Epoch 13, Training Loss: 2.310483067042546, Validation Error: 68.52063606972746, Validation Top-3 Accuracy: 54.23127863634631, Training Error: 66.57159770241151\n",
      "Epoch 14, Batch: 1000| Training Loss: 2.3010495876073835\n",
      "Epoch 14, Batch: 2000| Training Loss: 2.301469700753689\n",
      "Epoch 14, Batch: 3000| Training Loss: 2.3048837994337084\n",
      "Epoch 14, Batch: 4000| Training Loss: 2.305605790555477\n",
      "Epoch 14, Batch: 5000| Training Loss: 2.308219081401825\n",
      "Epoch 14, Batch: 6000| Training Loss: 2.3075732073187827\n",
      "Epoch 14, Batch: 7000| Training Loss: 2.3061534626654216\n",
      "Epoch 14, Batch: 8000| Training Loss: 2.306733114108443\n",
      "Epoch 14, Batch: 9000| Training Loss: 2.3063136680523555\n",
      "Epoch 14, Batch: 10000| Training Loss: 2.3061675995111464\n",
      "Epoch 14, Batch: 11000| Training Loss: 2.3059415422786365\n",
      "Epoch 14, Batch: 12000| Training Loss: 2.3059968898892405\n",
      "Epoch 14, Batch: 13000| Training Loss: 2.306686399615728\n",
      "Epoch 14, Batch: 14000| Training Loss: 2.30653858087744\n",
      "Epoch 14, Batch: 15000| Training Loss: 2.307063001783689\n",
      "Epoch 14, Batch: 16000| Training Loss: 2.306903749376535\n",
      "Epoch 14, Batch: 17000| Training Loss: 2.3070921545449425\n",
      "Epoch 14, Batch: 18000| Training Loss: 2.3069576768080395\n",
      "Epoch 14, Batch: 19000| Training Loss: 2.3070518764006462\n",
      "Epoch 14, Batch: 20000| Training Loss: 2.3074179855525494\n",
      "Epoch 14, Batch: 21000| Training Loss: 2.3073053093978335\n",
      "Epoch 14, Batch: 22000| Training Loss: 2.307515310861848\n",
      "Epoch 14, Training Loss: 2.3076449775452677, Validation Error: 68.59549683692693, Validation Top-3 Accuracy: 54.259248595185205, Training Error: 66.51486113569426\n",
      "Epoch 15, Batch: 1000| Training Loss: 2.3078811037540437\n",
      "Epoch 15, Batch: 2000| Training Loss: 2.299698107719421\n",
      "Epoch 15, Batch: 3000| Training Loss: 2.298606783191363\n",
      "Epoch 15, Batch: 4000| Training Loss: 2.3011032277941705\n",
      "Epoch 15, Batch: 5000| Training Loss: 2.3006027051210403\n",
      "Epoch 15, Batch: 6000| Training Loss: 2.301179884592692\n",
      "Epoch 15, Batch: 7000| Training Loss: 2.3015765556778227\n",
      "Epoch 15, Batch: 8000| Training Loss: 2.3030748458206656\n",
      "Epoch 15, Batch: 9000| Training Loss: 2.303076927635405\n",
      "Epoch 15, Batch: 10000| Training Loss: 2.3033722440242768\n",
      "Epoch 15, Batch: 11000| Training Loss: 2.3039932858618823\n",
      "Epoch 15, Batch: 12000| Training Loss: 2.3037954234381517\n",
      "Epoch 15, Batch: 13000| Training Loss: 2.3039932477565914\n",
      "Epoch 15, Batch: 14000| Training Loss: 2.303896097958088\n",
      "Epoch 15, Batch: 15000| Training Loss: 2.3034922714392345\n",
      "Epoch 15, Batch: 16000| Training Loss: 2.303508066408336\n",
      "Epoch 15, Batch: 17000| Training Loss: 2.303993227979716\n",
      "Epoch 15, Batch: 18000| Training Loss: 2.3041342914104463\n",
      "Epoch 15, Batch: 19000| Training Loss: 2.3040478919869973\n",
      "Epoch 15, Batch: 20000| Training Loss: 2.3044624711930752\n",
      "Epoch 15, Batch: 21000| Training Loss: 2.304961301122393\n",
      "Epoch 15, Batch: 22000| Training Loss: 2.304952363594012\n",
      "Epoch 15, Training Loss: 2.3049334641333776, Validation Error: 68.58397979581932, Validation Top-3 Accuracy: 54.24855420041037, Training Error: 66.49317793009902\n",
      "Epoch 16, Batch: 1000| Training Loss: 2.297743152856827\n",
      "Epoch 16, Batch: 2000| Training Loss: 2.3004733124375343\n",
      "Epoch 16, Batch: 3000| Training Loss: 2.2990239609479906\n",
      "Epoch 16, Batch: 4000| Training Loss: 2.3000739731788635\n",
      "Epoch 16, Batch: 5000| Training Loss: 2.301789028716087\n",
      "Epoch 16, Batch: 6000| Training Loss: 2.3009674543738363\n",
      "Epoch 16, Batch: 7000| Training Loss: 2.3013962082351958\n",
      "Epoch 16, Batch: 8000| Training Loss: 2.301256467819214\n",
      "Epoch 16, Batch: 9000| Training Loss: 2.2999593781497745\n",
      "Epoch 16, Batch: 10000| Training Loss: 2.299816385424137\n",
      "Epoch 16, Batch: 11000| Training Loss: 2.299805174480785\n",
      "Epoch 16, Batch: 12000| Training Loss: 2.3003068935771784\n",
      "Epoch 16, Batch: 13000| Training Loss: 2.3008146196328676\n",
      "Epoch 16, Batch: 14000| Training Loss: 2.3011389693192075\n",
      "Epoch 16, Batch: 15000| Training Loss: 2.301292397292455\n",
      "Epoch 16, Batch: 16000| Training Loss: 2.3016817440614106\n",
      "Epoch 16, Batch: 17000| Training Loss: 2.3021704106821734\n",
      "Epoch 16, Batch: 18000| Training Loss: 2.301999675399727\n",
      "Epoch 16, Batch: 19000| Training Loss: 2.3022260814528717\n",
      "Epoch 16, Batch: 20000| Training Loss: 2.301977855306864\n",
      "Epoch 16, Batch: 21000| Training Loss: 2.3018498117185775\n",
      "Epoch 16, Batch: 22000| Training Loss: 2.30235909113017\n",
      "Epoch 16, Training Loss: 2.302419554138099, Validation Error: 68.54778338090968, Validation Top-3 Accuracy: 54.306139407272326, Training Error: 66.45989109211656\n",
      "Epoch 17, Batch: 1000| Training Loss: 2.292620951652527\n",
      "Epoch 17, Batch: 2000| Training Loss: 2.2925683624744417\n",
      "Epoch 17, Batch: 3000| Training Loss: 2.293230333487193\n",
      "Epoch 17, Batch: 4000| Training Loss: 2.294407497495413\n",
      "Epoch 17, Batch: 5000| Training Loss: 2.2954000239133836\n",
      "Epoch 17, Batch: 6000| Training Loss: 2.2949829578995704\n",
      "Epoch 17, Batch: 7000| Training Loss: 2.295505288549832\n",
      "Epoch 17, Batch: 8000| Training Loss: 2.2963006715774537\n",
      "Epoch 17, Batch: 9000| Training Loss: 2.296465449240473\n",
      "Epoch 17, Batch: 10000| Training Loss: 2.2971310606002806\n",
      "Epoch 17, Batch: 11000| Training Loss: 2.297201323498379\n",
      "Epoch 17, Batch: 12000| Training Loss: 2.2985875522693\n",
      "Epoch 17, Batch: 13000| Training Loss: 2.298530591304486\n",
      "Epoch 17, Batch: 14000| Training Loss: 2.2996297837410653\n",
      "Epoch 17, Batch: 15000| Training Loss: 2.2995836859544116\n",
      "Epoch 17, Batch: 16000| Training Loss: 2.2999361901283266\n",
      "Epoch 17, Batch: 17000| Training Loss: 2.2995580414533614\n",
      "Epoch 17, Batch: 18000| Training Loss: 2.299834782315625\n",
      "Epoch 17, Batch: 19000| Training Loss: 2.299298668422197\n",
      "Epoch 17, Batch: 20000| Training Loss: 2.2993718210220337\n",
      "Epoch 17, Batch: 21000| Training Loss: 2.299503674319812\n",
      "Epoch 17, Batch: 22000| Training Loss: 2.2996799209984866\n",
      "Epoch 17, Training Loss: 2.2997882910669047, Validation Error: 68.52968517345487, Validation Top-3 Accuracy: 54.30449411490098, Training Error: 66.43273512855959\n",
      "Epoch 18, Batch: 1000| Training Loss: 2.297372604727745\n",
      "Epoch 18, Batch: 2000| Training Loss: 2.29727473706007\n",
      "Epoch 18, Batch: 3000| Training Loss: 2.2950826564232507\n",
      "Epoch 18, Batch: 4000| Training Loss: 2.2961020243763923\n",
      "Epoch 18, Batch: 5000| Training Loss: 2.2959340673208235\n",
      "Epoch 18, Batch: 6000| Training Loss: 2.2958156197667123\n",
      "Epoch 18, Batch: 7000| Training Loss: 2.2954763026407785\n",
      "Epoch 18, Batch: 8000| Training Loss: 2.2959538547694684\n",
      "Epoch 18, Batch: 9000| Training Loss: 2.296077027241389\n",
      "Epoch 18, Batch: 10000| Training Loss: 2.295252552711964\n",
      "Epoch 18, Batch: 11000| Training Loss: 2.2953584934256295\n",
      "Epoch 18, Batch: 12000| Training Loss: 2.2958895609478156\n",
      "Epoch 18, Batch: 13000| Training Loss: 2.2959834609031677\n",
      "Epoch 18, Batch: 14000| Training Loss: 2.2953767122796602\n",
      "Epoch 18, Batch: 15000| Training Loss: 2.29537058912913\n",
      "Epoch 18, Batch: 16000| Training Loss: 2.2951122795194387\n",
      "Epoch 18, Batch: 17000| Training Loss: 2.295674377995379\n",
      "Epoch 18, Batch: 18000| Training Loss: 2.2958808432221414\n",
      "Epoch 18, Batch: 19000| Training Loss: 2.296333921125061\n",
      "Epoch 18, Batch: 20000| Training Loss: 2.296505644142628\n",
      "Epoch 18, Batch: 21000| Training Loss: 2.296758212271191\n",
      "Epoch 18, Batch: 22000| Training Loss: 2.2969429059028625\n",
      "Epoch 18, Training Loss: 2.2971387339177403, Validation Error: 68.52063606972746, Validation Top-3 Accuracy: 54.38182281972582, Training Error: 66.38535074316935\n",
      "Epoch 19, Batch: 1000| Training Loss: 2.3052006620168686\n",
      "Epoch 19, Batch: 2000| Training Loss: 2.294101974129677\n",
      "Epoch 19, Batch: 3000| Training Loss: 2.2936440488497416\n",
      "Epoch 19, Batch: 4000| Training Loss: 2.290945890724659\n",
      "Epoch 19, Batch: 5000| Training Loss: 2.2932613394498826\n",
      "Epoch 19, Batch: 6000| Training Loss: 2.2924413745800654\n",
      "Epoch 19, Batch: 7000| Training Loss: 2.29156042437894\n",
      "Epoch 19, Batch: 8000| Training Loss: 2.290926064968109\n",
      "Epoch 19, Batch: 9000| Training Loss: 2.291489475223753\n",
      "Epoch 19, Batch: 10000| Training Loss: 2.2920034149050714\n",
      "Epoch 19, Batch: 11000| Training Loss: 2.29232464278828\n",
      "Epoch 19, Batch: 12000| Training Loss: 2.293680051614841\n",
      "Epoch 19, Batch: 13000| Training Loss: 2.293296720321362\n",
      "Epoch 19, Batch: 14000| Training Loss: 2.2938526770387377\n",
      "Epoch 19, Batch: 15000| Training Loss: 2.2942215127944947\n",
      "Epoch 19, Batch: 16000| Training Loss: 2.2947362029477953\n",
      "Epoch 19, Batch: 17000| Training Loss: 2.294211993077222\n",
      "Epoch 19, Batch: 18000| Training Loss: 2.294394560608599\n",
      "Epoch 19, Batch: 19000| Training Loss: 2.294641798872697\n",
      "Epoch 19, Batch: 20000| Training Loss: 2.294542024797201\n",
      "Epoch 19, Batch: 21000| Training Loss: 2.294762278324082\n",
      "Epoch 19, Batch: 22000| Training Loss: 2.295042914623564\n",
      "Epoch 19, Training Loss: 2.2947880704660317, Validation Error: 68.48608494640463, Validation Top-3 Accuracy: 54.34315846611208, Training Error: 66.35580477771771\n",
      "Epoch 20, Batch: 1000| Training Loss: 2.283354738712311\n",
      "Epoch 20, Batch: 2000| Training Loss: 2.285628237247467\n",
      "Epoch 20, Batch: 3000| Training Loss: 2.286309356888135\n",
      "Epoch 20, Batch: 4000| Training Loss: 2.287357018470764\n",
      "Epoch 20, Batch: 5000| Training Loss: 2.288171180701256\n",
      "Epoch 20, Batch: 6000| Training Loss: 2.289258537252744\n",
      "Epoch 20, Batch: 7000| Training Loss: 2.290528487409864\n",
      "Epoch 20, Batch: 8000| Training Loss: 2.2902887794971467\n",
      "Epoch 20, Batch: 9000| Training Loss: 2.2891391021410623\n",
      "Epoch 20, Batch: 10000| Training Loss: 2.288908534002304\n",
      "Epoch 20, Batch: 11000| Training Loss: 2.289685368180275\n",
      "Epoch 20, Batch: 12000| Training Loss: 2.2898968334198\n",
      "Epoch 20, Batch: 13000| Training Loss: 2.2902540549865136\n",
      "Epoch 20, Batch: 14000| Training Loss: 2.2906798217637196\n",
      "Epoch 20, Batch: 15000| Training Loss: 2.29071420378685\n",
      "Epoch 20, Batch: 16000| Training Loss: 2.2911017764657737\n",
      "Epoch 20, Batch: 17000| Training Loss: 2.2912071451369456\n",
      "Epoch 20, Batch: 18000| Training Loss: 2.291278517120414\n",
      "Epoch 20, Batch: 19000| Training Loss: 2.291933691225554\n",
      "Epoch 20, Batch: 20000| Training Loss: 2.291777533119917\n",
      "Epoch 20, Batch: 21000| Training Loss: 2.291695357691674\n",
      "Epoch 20, Batch: 22000| Training Loss: 2.2921809307390992\n",
      "Epoch 20, Training Loss: 2.292385380634366, Validation Error: 68.49184346695843, Validation Top-3 Accuracy: 54.41801923331155, Training Error: 66.33017287333995\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('multi-modal-jan-march-g5-feb-27.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 43.77431906614786%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "if val_loader is not None:\n",
    "    with torch.no_grad():\n",
    "        for boards, sequences, lengths, labels in val_loader:\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking = True), sequences.to(device, non_blocking = True), lengths, labels.to(device, non_blocking = True)\n",
    "            outputs = model(boards, sequences, lengths)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            minus = 0\n",
    "            for idx, (sequence, label) in enumerate(zip(sequences, labels)):\n",
    "                # This tells us we're looking at games that include the opening but has developed more than the first 4 half-moves\n",
    "                if sequence[-1].item() == 0 and sequence[2].item() != 0 and sequence[3].item() != 0 and sequence[4].item() != 0:\n",
    "                    output = probabilities[idx]\n",
    "                    sorted_probs, sorted_indices = torch.sort(output, descending=True)\n",
    "                    predicted_move = sorted_indices[0]\n",
    "                    # print(predicted_move)\n",
    "                    chess_board = load_board_state_from_san(sequence, vocab)\n",
    "                    for move_idx in sorted_indices:\n",
    "                        move = vocab.get_move(move_idx.item()) # Convert index to move (e.g., 'e2e4')\n",
    "                        if is_legal_move(chess_board, move):\n",
    "                            # print(\"we found one\")\n",
    "                            predicted_move = vocab.get_id(move)\n",
    "                            break\n",
    "                    \n",
    "                    # Check if predicted move is correct\n",
    "                    correct_move = label.item() # Convert label to move\n",
    "                    # print(correct_move)\n",
    "                    if predicted_move == correct_move:\n",
    "                        val_correct += 1\n",
    "                else:\n",
    "                    minus += 1\n",
    "            val_total += (labels.size(0) - minus)\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Accuracy: {val_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'multimodalmodel-best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8121])\n",
      "O-O-O\n",
      "O-O-O\n",
      "torch.Size([1, 12, 8, 8, 1])\n",
      "torch.Size([1, 16, 1, 1, 1])\n",
      "torch.Size([1, 1, 1, 1, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 4. Expected size 12 but got size 16 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshow_maps_on_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultimodal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/enpoisson/research/notebooks/utils.py:412\u001b[0m, in \u001b[0;36mshow_maps_on_training_data\u001b[0;34m(vocab, model, train_loader, num_samples, conv2, multimodal)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28mprint\u001b[39m(lengths_expanded\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# Concatenate along a new dimension\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m combined_input \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboards\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequences_expanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths_expanded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Generate the CAM mask\u001b[39;00m\n\u001b[1;32m    415\u001b[0m grayscale_cam \u001b[38;5;241m=\u001b[39m cam(input_tensor\u001b[38;5;241m=\u001b[39mcombined_input, targets\u001b[38;5;241m=\u001b[39mtargets)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 4. Expected size 12 but got size 16 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "# show_maps_on_training_data(vocab, model, train_loader, conv2 = False, multimodal= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6 \n",
    "SENetTwo baby -- hm it's not that promising... let's go back to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887027\n"
     ]
    }
   ],
   "source": [
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.95 * total_size)\n",
    "val_size = int(total_size * 0.04)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2159953\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=1, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # alpha can be set to a constant, or it can be a tensor of shape (num_classes,)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability 0\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "# Reload the data with particular batch size\n",
    "torch.multiprocessing.set_start_method('fork', force=True)\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 192\n",
    "d_embed = 72\n",
    "NUM_EPOCHS = 10\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalFour(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=1, reduction='mean')\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.72 # This causes the LR to be 5e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('multi-modal-jan-march-g5-feb-27.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 7\n",
    "let's scale the RNN baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887027\n"
     ]
    }
   ],
   "source": [
    "# We're scaling the model size so let's bring in more data as well\n",
    "train_size = int(0.95 * total_size)\n",
    "val_size = int(total_size * 0.04)\n",
    "\n",
    "# Create subsets for training and validation\n",
    "train_dataset = Subset(dataset, range(0, train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4381497\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=1, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # alpha can be set to a constant, or it can be a tensor of shape (num_classes,)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability 0\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "# Reload the data with particular batch size\n",
    "torch.multiprocessing.set_start_method('fork', force=True)\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 256\n",
    "d_embed = 64\n",
    "NUM_EPOCHS = 20\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalFive(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=1, reduction='mean')\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.72 # This causes the LR to be 5e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1000| Training Loss: 4.75900833439827\n",
      "Epoch 1, Batch: 2000| Training Loss: 4.388382541537285\n",
      "Epoch 1, Batch: 3000| Training Loss: 4.1606564864317575\n",
      "Epoch 1, Batch: 4000| Training Loss: 4.006464679956436\n",
      "Epoch 1, Batch: 5000| Training Loss: 3.886658103322983\n",
      "Epoch 1, Batch: 6000| Training Loss: 3.7896334119240445\n",
      "Epoch 1, Batch: 7000| Training Loss: 3.709531047446387\n",
      "Epoch 1, Batch: 8000| Training Loss: 3.6415253961980345\n",
      "Epoch 1, Batch: 9000| Training Loss: 3.580289804061254\n",
      "Epoch 1, Batch: 10000| Training Loss: 3.526648753285408\n",
      "Epoch 1, Batch: 11000| Training Loss: 3.478701816623861\n",
      "Epoch 1, Batch: 12000| Training Loss: 3.4365540742476783\n",
      "Epoch 1, Batch: 13000| Training Loss: 3.3983328068256378\n",
      "Epoch 1, Batch: 14000| Training Loss: 3.362579758320536\n",
      "Epoch 1, Batch: 15000| Training Loss: 3.330839539782206\n",
      "Epoch 1, Batch: 16000| Training Loss: 3.3009322288632394\n",
      "Epoch 1, Batch: 17000| Training Loss: 3.2732747440197887\n",
      "Epoch 1, Batch: 18000| Training Loss: 3.2470573121441735\n",
      "Epoch 1, Batch: 19000| Training Loss: 3.222329897830361\n",
      "Epoch 1, Batch: 20000| Training Loss: 3.1991885851979256\n",
      "Epoch 1, Batch: 21000| Training Loss: 3.1777554585933685\n",
      "Epoch 1, Batch: 22000| Training Loss: 3.157049819317731\n",
      "Epoch 1, Training Loss: 3.1459931319263603, Validation Error: 71.62776923140203, Validation Top-3 Accuracy: 50.19949160504678, Training Error: 75.49489492131525\n",
      "Epoch 2, Batch: 1000| Training Loss: 2.5826297461986543\n",
      "Epoch 2, Batch: 2000| Training Loss: 2.5720392942428587\n",
      "Epoch 2, Batch: 3000| Training Loss: 2.571999126513799\n",
      "Epoch 2, Batch: 4000| Training Loss: 2.5677841739952565\n",
      "Epoch 2, Batch: 5000| Training Loss: 2.5630400881290436\n",
      "Epoch 2, Batch: 6000| Training Loss: 2.558756939729055\n",
      "Epoch 2, Batch: 7000| Training Loss: 2.554952021769115\n",
      "Epoch 2, Batch: 8000| Training Loss: 2.55106603641808\n",
      "Epoch 2, Batch: 9000| Training Loss: 2.5470445784860187\n",
      "Epoch 2, Batch: 10000| Training Loss: 2.5438794000267984\n",
      "Epoch 2, Batch: 11000| Training Loss: 2.539988758336414\n",
      "Epoch 2, Batch: 12000| Training Loss: 2.536190140376488\n",
      "Epoch 2, Batch: 13000| Training Loss: 2.532284563743151\n",
      "Epoch 2, Batch: 14000| Training Loss: 2.529374386012554\n",
      "Epoch 2, Batch: 15000| Training Loss: 2.5266578619718554\n",
      "Epoch 2, Batch: 16000| Training Loss: 2.5235928888991475\n",
      "Epoch 2, Batch: 17000| Training Loss: 2.5199248299107833\n",
      "Epoch 2, Batch: 18000| Training Loss: 2.516367725789547\n",
      "Epoch 2, Batch: 19000| Training Loss: 2.5131939395728864\n",
      "Epoch 2, Batch: 20000| Training Loss: 2.5102464813709258\n",
      "Epoch 2, Batch: 21000| Training Loss: 2.5073126879930494\n",
      "Epoch 2, Batch: 22000| Training Loss: 2.504550801136277\n",
      "Epoch 2, Training Loss: 2.502827532665081, Validation Error: 69.48148635641951, Validation Top-3 Accuracy: 53.673524789205146, Training Error: 69.83488550678605\n",
      "Epoch 3, Batch: 1000| Training Loss: 2.326085419178009\n",
      "Epoch 3, Batch: 2000| Training Loss: 2.3225199303627013\n",
      "Epoch 3, Batch: 3000| Training Loss: 2.3215723145008087\n",
      "Epoch 3, Batch: 4000| Training Loss: 2.319658286303282\n",
      "Epoch 3, Batch: 5000| Training Loss: 2.3178503971099853\n",
      "Epoch 3, Batch: 6000| Training Loss: 2.316982016046842\n",
      "Epoch 3, Batch: 7000| Training Loss: 2.3160397162778037\n",
      "Epoch 3, Batch: 8000| Training Loss: 2.3145772943794727\n",
      "Epoch 3, Batch: 9000| Training Loss: 2.3141379363536836\n",
      "Epoch 3, Batch: 10000| Training Loss: 2.3135372390151026\n",
      "Epoch 3, Batch: 11000| Training Loss: 2.3122867254235526\n",
      "Epoch 3, Batch: 12000| Training Loss: 2.3111137374341486\n",
      "Epoch 3, Batch: 13000| Training Loss: 2.3099172185109214\n",
      "Epoch 3, Batch: 14000| Training Loss: 2.3094063325183734\n",
      "Epoch 3, Batch: 15000| Training Loss: 2.3086540171782177\n",
      "Epoch 3, Batch: 16000| Training Loss: 2.307927602224052\n",
      "Epoch 3, Batch: 17000| Training Loss: 2.3063367860387354\n",
      "Epoch 3, Batch: 18000| Training Loss: 2.305156902684106\n",
      "Epoch 3, Batch: 19000| Training Loss: 2.304049464156753\n",
      "Epoch 3, Batch: 20000| Training Loss: 2.302880653399229\n",
      "Epoch 3, Batch: 21000| Training Loss: 2.30196156221912\n",
      "Epoch 3, Batch: 22000| Training Loss: 2.3011010740074243\n",
      "Epoch 3, Training Loss: 2.3005196292869163, Validation Error: 67.95136518069415, Validation Top-3 Accuracy: 55.823098248440004, Training Error: 67.63729608347964\n",
      "Epoch 4, Batch: 1000| Training Loss: 2.1778264788389206\n",
      "Epoch 4, Batch: 2000| Training Loss: 2.173782576918602\n",
      "Epoch 4, Batch: 3000| Training Loss: 2.172971058011055\n",
      "Epoch 4, Batch: 4000| Training Loss: 2.173691421508789\n",
      "Epoch 4, Batch: 5000| Training Loss: 2.1733676206111907\n",
      "Epoch 4, Batch: 6000| Training Loss: 2.1746307747761406\n",
      "Epoch 4, Batch: 7000| Training Loss: 2.1758032539061136\n",
      "Epoch 4, Batch: 8000| Training Loss: 2.1756613008975982\n",
      "Epoch 4, Batch: 9000| Training Loss: 2.175509437614017\n",
      "Epoch 4, Batch: 10000| Training Loss: 2.1744084017038343\n",
      "Epoch 4, Batch: 11000| Training Loss: 2.174327613982287\n",
      "Epoch 4, Batch: 12000| Training Loss: 2.1742457040548326\n",
      "Epoch 4, Batch: 13000| Training Loss: 2.174439227617704\n",
      "Epoch 4, Batch: 14000| Training Loss: 2.174584209833826\n",
      "Epoch 4, Batch: 15000| Training Loss: 2.174781114880244\n",
      "Epoch 4, Batch: 16000| Training Loss: 2.175389982178807\n",
      "Epoch 4, Batch: 17000| Training Loss: 2.1756496526633993\n",
      "Epoch 4, Batch: 18000| Training Loss: 2.1754791209763953\n",
      "Epoch 4, Batch: 19000| Training Loss: 2.1754420254544207\n",
      "Epoch 4, Batch: 20000| Training Loss: 2.174684412735701\n",
      "Epoch 4, Batch: 21000| Training Loss: 2.1746661445640383\n",
      "Epoch 4, Batch: 22000| Training Loss: 2.1749256394613874\n",
      "Epoch 4, Training Loss: 2.1749513831589975, Validation Error: 67.16080257323604, Validation Top-3 Accuracy: 57.21995080641899, Training Error: 66.07641702000015\n",
      "Epoch 5, Batch: 1000| Training Loss: 2.0891829433441163\n",
      "Epoch 5, Batch: 2000| Training Loss: 2.086656774818897\n",
      "Epoch 5, Batch: 3000| Training Loss: 2.08644992407163\n",
      "Epoch 5, Batch: 4000| Training Loss: 2.085378588736057\n",
      "Epoch 5, Batch: 5000| Training Loss: 2.0857428451299667\n",
      "Epoch 5, Batch: 6000| Training Loss: 2.0855690320332845\n",
      "Epoch 5, Batch: 7000| Training Loss: 2.084701429077557\n",
      "Epoch 5, Batch: 8000| Training Loss: 2.0855372597426176\n",
      "Epoch 5, Batch: 9000| Training Loss: 2.0860135297907725\n",
      "Epoch 5, Batch: 10000| Training Loss: 2.086079165184498\n",
      "Epoch 5, Batch: 11000| Training Loss: 2.085845483194698\n",
      "Epoch 5, Batch: 12000| Training Loss: 2.086074550439914\n",
      "Epoch 5, Batch: 13000| Training Loss: 2.0863155415516634\n",
      "Epoch 5, Batch: 14000| Training Loss: 2.0862915130938804\n",
      "Epoch 5, Batch: 15000| Training Loss: 2.086729500794411\n",
      "Epoch 5, Batch: 16000| Training Loss: 2.0868396090194583\n",
      "Epoch 5, Batch: 17000| Training Loss: 2.086841877397369\n",
      "Epoch 5, Batch: 18000| Training Loss: 2.0872595640950733\n",
      "Epoch 5, Batch: 19000| Training Loss: 2.087163865170981\n",
      "Epoch 5, Batch: 20000| Training Loss: 2.087327702111006\n",
      "Epoch 5, Batch: 21000| Training Loss: 2.0873977963016146\n",
      "Epoch 5, Batch: 22000| Training Loss: 2.0875959180539305\n",
      "Epoch 5, Training Loss: 2.0874175998435742, Validation Error: 66.59317697578953, Validation Top-3 Accuracy: 58.0927779926778, Training Error: 64.90050145010767\n",
      "Epoch 6, Batch: 1000| Training Loss: 2.0182772567272185\n",
      "Epoch 6, Batch: 2000| Training Loss: 2.0162404752373697\n",
      "Epoch 6, Batch: 3000| Training Loss: 2.0166362666289013\n",
      "Epoch 6, Batch: 4000| Training Loss: 2.0141587008535864\n",
      "Epoch 6, Batch: 5000| Training Loss: 2.0151508724689484\n",
      "Epoch 6, Batch: 6000| Training Loss: 2.015815553128719\n",
      "Epoch 6, Batch: 7000| Training Loss: 2.0173303314277105\n",
      "Epoch 6, Batch: 8000| Training Loss: 2.018069332823157\n",
      "Epoch 6, Batch: 9000| Training Loss: 2.018886682934231\n",
      "Epoch 6, Batch: 10000| Training Loss: 2.0199833356261254\n",
      "Epoch 6, Batch: 11000| Training Loss: 2.0206205089417373\n",
      "Epoch 6, Batch: 12000| Training Loss: 2.0215135779778164\n",
      "Epoch 6, Batch: 13000| Training Loss: 2.022062383541694\n",
      "Epoch 6, Batch: 14000| Training Loss: 2.0219675738300595\n",
      "Epoch 6, Batch: 15000| Training Loss: 2.0225135505835214\n",
      "Epoch 6, Batch: 16000| Training Loss: 2.022564988002181\n",
      "Epoch 6, Batch: 17000| Training Loss: 2.0231237633438672\n",
      "Epoch 6, Batch: 18000| Training Loss: 2.023536727103922\n",
      "Epoch 6, Batch: 19000| Training Loss: 2.0241375774898027\n",
      "Epoch 6, Batch: 20000| Training Loss: 2.024643572717905\n",
      "Epoch 6, Batch: 21000| Training Loss: 2.024670563805671\n",
      "Epoch 6, Batch: 22000| Training Loss: 2.024920786185698\n",
      "Epoch 6, Training Loss: 2.0248609447606096, Validation Error: 66.23614870145362, Validation Top-3 Accuracy: 58.40209281261458, Training Error: 63.98544246382178\n",
      "Epoch 7, Batch: 1000| Training Loss: 1.966678544640541\n",
      "Epoch 7, Batch: 2000| Training Loss: 1.9710181882977487\n",
      "Epoch 7, Batch: 3000| Training Loss: 1.969425391515096\n",
      "Epoch 7, Batch: 4000| Training Loss: 1.9696549314856528\n",
      "Epoch 7, Batch: 5000| Training Loss: 1.9722385914564133\n",
      "Epoch 7, Batch: 6000| Training Loss: 1.9725069631139438\n",
      "Epoch 7, Batch: 7000| Training Loss: 1.97167008629867\n",
      "Epoch 7, Batch: 8000| Training Loss: 1.9726924123615026\n",
      "Epoch 7, Batch: 9000| Training Loss: 1.9725964783430099\n",
      "Epoch 7, Batch: 10000| Training Loss: 1.97329715975523\n",
      "Epoch 7, Batch: 11000| Training Loss: 1.9730944432995536\n",
      "Epoch 7, Batch: 12000| Training Loss: 1.973171790887912\n",
      "Epoch 7, Batch: 13000| Training Loss: 1.9739177438662603\n",
      "Epoch 7, Batch: 14000| Training Loss: 1.9747521607620375\n",
      "Epoch 7, Batch: 15000| Training Loss: 1.9757661357005438\n",
      "Epoch 7, Batch: 16000| Training Loss: 1.9763912795260548\n",
      "Epoch 7, Batch: 17000| Training Loss: 1.9767888845135184\n",
      "Epoch 7, Batch: 18000| Training Loss: 1.9770869415866004\n",
      "Epoch 7, Batch: 19000| Training Loss: 1.977750526955253\n",
      "Epoch 7, Batch: 20000| Training Loss: 1.9777517967402936\n",
      "Epoch 7, Batch: 21000| Training Loss: 1.978099957891873\n",
      "Epoch 7, Batch: 22000| Training Loss: 1.9788356588374485\n",
      "Epoch 7, Training Loss: 1.9792973614510663, Validation Error: 65.79932378515782, Validation Top-3 Accuracy: 58.846321538108974, Training Error: 63.300966703809834\n",
      "Epoch 8, Batch: 1000| Training Loss: 1.9198599692583085\n",
      "Epoch 8, Batch: 2000| Training Loss: 1.9255484592318535\n",
      "Epoch 8, Batch: 3000| Training Loss: 1.9326706914107006\n",
      "Epoch 8, Batch: 4000| Training Loss: 1.9341773577332497\n",
      "Epoch 8, Batch: 5000| Training Loss: 1.9358430568933487\n",
      "Epoch 8, Batch: 6000| Training Loss: 1.937320421675841\n",
      "Epoch 8, Batch: 7000| Training Loss: 1.9365051843949728\n",
      "Epoch 8, Batch: 8000| Training Loss: 1.9364895163923501\n",
      "Epoch 8, Batch: 9000| Training Loss: 1.937313412004047\n",
      "Epoch 8, Batch: 10000| Training Loss: 1.937388340294361\n",
      "Epoch 8, Batch: 11000| Training Loss: 1.9386508904695512\n",
      "Epoch 8, Batch: 12000| Training Loss: 1.9398435010910033\n",
      "Epoch 8, Batch: 13000| Training Loss: 1.9407413085882481\n",
      "Epoch 8, Batch: 14000| Training Loss: 1.9414322020156043\n",
      "Epoch 8, Batch: 15000| Training Loss: 1.9423136636177698\n",
      "Epoch 8, Batch: 16000| Training Loss: 1.9427516726702452\n",
      "Epoch 8, Batch: 17000| Training Loss: 1.943096442397903\n",
      "Epoch 8, Batch: 18000| Training Loss: 1.9429897598491774\n",
      "Epoch 8, Batch: 19000| Training Loss: 1.943552716248914\n",
      "Epoch 8, Batch: 20000| Training Loss: 1.9438882801175117\n",
      "Epoch 8, Batch: 21000| Training Loss: 1.9447281770422344\n",
      "Epoch 8, Batch: 22000| Training Loss: 1.945279302087697\n",
      "Epoch 8, Training Loss: 1.9455300269542315, Validation Error: 65.86102221966289, Validation Top-3 Accuracy: 59.025658323472975, Training Error: 62.74274539171265\n",
      "Epoch 9, Batch: 1000| Training Loss: 1.9070569090843201\n",
      "Epoch 9, Batch: 2000| Training Loss: 1.9102925953269005\n",
      "Epoch 9, Batch: 3000| Training Loss: 1.9144240866899491\n",
      "Epoch 9, Batch: 4000| Training Loss: 1.914156472325325\n",
      "Epoch 9, Batch: 5000| Training Loss: 1.9144189924001693\n",
      "Epoch 9, Batch: 6000| Training Loss: 1.9152890835801761\n",
      "Epoch 9, Batch: 7000| Training Loss: 1.9158439360175814\n",
      "Epoch 9, Batch: 8000| Training Loss: 1.9163122851997614\n",
      "Epoch 9, Batch: 9000| Training Loss: 1.915836809542444\n",
      "Epoch 9, Batch: 10000| Training Loss: 1.9163679788589478\n",
      "Epoch 9, Batch: 11000| Training Loss: 1.915985341147943\n",
      "Epoch 9, Batch: 12000| Training Loss: 1.91606606254975\n",
      "Epoch 9, Batch: 13000| Training Loss: 1.917081840652686\n",
      "Epoch 9, Batch: 14000| Training Loss: 1.9175640992011342\n",
      "Epoch 9, Batch: 15000| Training Loss: 1.9181928601900737\n",
      "Epoch 9, Batch: 16000| Training Loss: 1.9188508914262057\n",
      "Epoch 9, Batch: 17000| Training Loss: 1.9193762029830148\n",
      "Epoch 9, Batch: 18000| Training Loss: 1.919766785899798\n",
      "Epoch 9, Batch: 19000| Training Loss: 1.919984107707676\n",
      "Epoch 9, Batch: 20000| Training Loss: 1.9202274630248546\n",
      "Epoch 9, Batch: 21000| Training Loss: 1.9203486350036802\n",
      "Epoch 9, Batch: 22000| Training Loss: 1.920662232957103\n",
      "Epoch 9, Training Loss: 1.920696301339762, Validation Error: 65.5360771312696, Validation Top-3 Accuracy: 59.225561251269355, Training Error: 62.310917078364696\n",
      "Epoch 10, Batch: 1000| Training Loss: 1.889495659470558\n",
      "Epoch 10, Batch: 2000| Training Loss: 1.8947880764603615\n",
      "Epoch 10, Batch: 3000| Training Loss: 1.8943429495890935\n",
      "Epoch 10, Batch: 4000| Training Loss: 1.8963514326512814\n",
      "Epoch 10, Batch: 5000| Training Loss: 1.8973331757068634\n",
      "Epoch 10, Batch: 6000| Training Loss: 1.8982377320925394\n",
      "Epoch 10, Batch: 7000| Training Loss: 1.8989822397402354\n",
      "Epoch 10, Batch: 8000| Training Loss: 1.8990795060247183\n",
      "Epoch 10, Batch: 9000| Training Loss: 1.9002401400407156\n",
      "Epoch 10, Batch: 10000| Training Loss: 1.9004565430164337\n",
      "Epoch 10, Batch: 11000| Training Loss: 1.8999752675836736\n",
      "Epoch 10, Batch: 12000| Training Loss: 1.9003880626459917\n",
      "Epoch 10, Batch: 13000| Training Loss: 1.9010858293588344\n",
      "Epoch 10, Batch: 14000| Training Loss: 1.9011186616846494\n",
      "Epoch 10, Batch: 15000| Training Loss: 1.9015813361485798\n",
      "Epoch 10, Batch: 16000| Training Loss: 1.9018506285324692\n",
      "Epoch 10, Batch: 17000| Training Loss: 1.9020766074166577\n",
      "Epoch 10, Batch: 18000| Training Loss: 1.9021825697951846\n",
      "Epoch 10, Batch: 19000| Training Loss: 1.902346289208061\n",
      "Epoch 10, Batch: 20000| Training Loss: 1.9024966235518455\n",
      "Epoch 10, Batch: 21000| Training Loss: 1.9022911072515305\n",
      "Epoch 10, Batch: 22000| Training Loss: 1.902147963382981\n",
      "Epoch 10, Training Loss: 1.9024331238232282, Validation Error: 65.46615223883052, Validation Top-3 Accuracy: 59.3292146188352, Training Error: 62.04961020454606\n",
      "Epoch 11, Batch: 1000| Training Loss: 1.8891170797348023\n",
      "Epoch 11, Batch: 2000| Training Loss: 1.8847965632081032\n",
      "Epoch 11, Batch: 3000| Training Loss: 1.8854445338249206\n",
      "Epoch 11, Batch: 4000| Training Loss: 1.88315141543746\n",
      "Epoch 11, Batch: 5000| Training Loss: 1.8831035776376723\n",
      "Epoch 11, Batch: 6000| Training Loss: 1.8837514655788739\n",
      "Epoch 11, Batch: 7000| Training Loss: 1.883012541600636\n",
      "Epoch 11, Batch: 8000| Training Loss: 1.883819748133421\n",
      "Epoch 11, Batch: 9000| Training Loss: 1.8847289061016506\n",
      "Epoch 11, Batch: 10000| Training Loss: 1.8848029160499573\n",
      "Epoch 11, Batch: 11000| Training Loss: 1.8846054571325128\n",
      "Epoch 11, Batch: 12000| Training Loss: 1.8850224294662477\n",
      "Epoch 11, Batch: 13000| Training Loss: 1.8847163375065876\n",
      "Epoch 11, Batch: 14000| Training Loss: 1.884881186221327\n",
      "Epoch 11, Batch: 15000| Training Loss: 1.8846499672651291\n",
      "Epoch 11, Batch: 16000| Training Loss: 1.8855511597841978\n",
      "Epoch 11, Batch: 17000| Training Loss: 1.886349749102312\n",
      "Epoch 11, Batch: 18000| Training Loss: 1.8868164240651661\n",
      "Epoch 11, Batch: 19000| Training Loss: 1.8873664704373008\n",
      "Epoch 11, Batch: 20000| Training Loss: 1.887773084205389\n",
      "Epoch 11, Batch: 21000| Training Loss: 1.887879708460399\n",
      "Epoch 11, Batch: 22000| Training Loss: 1.8885131787386809\n",
      "Epoch 11, Training Loss: 1.888846587849361, Validation Error: 65.38800088845746, Validation Top-3 Accuracy: 59.46083794842713, Training Error: 61.78224173171917\n",
      "Epoch 12, Batch: 1000| Training Loss: 1.8703290816545486\n",
      "Epoch 12, Batch: 2000| Training Loss: 1.8734398653507234\n",
      "Epoch 12, Batch: 3000| Training Loss: 1.8738914675315221\n",
      "Epoch 12, Batch: 4000| Training Loss: 1.8732504833936692\n",
      "Epoch 12, Batch: 5000| Training Loss: 1.873145902323723\n",
      "Epoch 12, Batch: 6000| Training Loss: 1.8724795601963997\n",
      "Epoch 12, Batch: 7000| Training Loss: 1.871897972890309\n",
      "Epoch 12, Batch: 8000| Training Loss: 1.872563755363226\n",
      "Epoch 12, Batch: 9000| Training Loss: 1.8737588131692675\n",
      "Epoch 12, Batch: 10000| Training Loss: 1.8746181493043899\n",
      "Epoch 12, Batch: 11000| Training Loss: 1.8751875452778557\n",
      "Epoch 12, Batch: 12000| Training Loss: 1.8751134584049385\n",
      "Epoch 12, Batch: 13000| Training Loss: 1.8753122146771504\n",
      "Epoch 12, Batch: 14000| Training Loss: 1.8759937450800623\n",
      "Epoch 12, Batch: 15000| Training Loss: 1.8761281230370204\n",
      "Epoch 12, Batch: 16000| Training Loss: 1.876468874797225\n",
      "Epoch 12, Batch: 17000| Training Loss: 1.877583138528992\n",
      "Epoch 12, Batch: 18000| Training Loss: 1.8776638169752227\n",
      "Epoch 12, Batch: 19000| Training Loss: 1.8781019221230557\n",
      "Epoch 12, Batch: 20000| Training Loss: 1.878497903931141\n",
      "Epoch 12, Batch: 21000| Training Loss: 1.879119836018199\n",
      "Epoch 12, Batch: 22000| Training Loss: 1.8788974140557375\n",
      "Epoch 12, Training Loss: 1.8788451413573406, Validation Error: 65.4406502192351, Validation Top-3 Accuracy: 59.43698121963397, Training Error: 61.60711347694358\n",
      "Epoch 13, Batch: 1000| Training Loss: 1.8616511986255646\n",
      "Epoch 13, Batch: 2000| Training Loss: 1.8660312798023224\n",
      "Epoch 13, Batch: 3000| Training Loss: 1.8667774531443915\n",
      "Epoch 13, Batch: 4000| Training Loss: 1.8659614535272122\n",
      "Epoch 13, Batch: 5000| Training Loss: 1.8674024348020553\n",
      "Epoch 13, Batch: 6000| Training Loss: 1.8699277397592862\n",
      "Epoch 13, Batch: 7000| Training Loss: 1.869630013534001\n",
      "Epoch 13, Batch: 8000| Training Loss: 1.8702216483801604\n",
      "Epoch 13, Batch: 9000| Training Loss: 1.869325083229277\n",
      "Epoch 13, Batch: 10000| Training Loss: 1.8702153650522233\n",
      "Epoch 13, Batch: 11000| Training Loss: 1.870926281820644\n",
      "Epoch 13, Batch: 12000| Training Loss: 1.8705938774645328\n",
      "Epoch 13, Batch: 13000| Training Loss: 1.8708767546965526\n",
      "Epoch 13, Batch: 14000| Training Loss: 1.8714495699661118\n",
      "Epoch 13, Batch: 15000| Training Loss: 1.8715637186924616\n",
      "Epoch 13, Batch: 16000| Training Loss: 1.871878359168768\n",
      "Epoch 13, Batch: 17000| Training Loss: 1.872659608812893\n",
      "Epoch 13, Batch: 18000| Training Loss: 1.8731265728142525\n",
      "Epoch 13, Batch: 19000| Training Loss: 1.8736483406204927\n",
      "Epoch 13, Batch: 20000| Training Loss: 1.87403329693079\n",
      "Epoch 13, Batch: 21000| Training Loss: 1.8744949663934254\n",
      "Epoch 13, Batch: 22000| Training Loss: 1.8748237953619524\n",
      "Epoch 13, Training Loss: 1.8747266909627422, Validation Error: 65.36908003520924, Validation Top-3 Accuracy: 59.472354989044405, Training Error: 61.54628966060934\n",
      "Epoch 14, Batch: 1000| Training Loss: 1.8653297919034957\n",
      "Epoch 14, Batch: 2000| Training Loss: 1.8647128530740738\n",
      "Epoch 14, Batch: 3000| Training Loss: 1.865513298312823\n",
      "Epoch 14, Batch: 4000| Training Loss: 1.864311310172081\n",
      "Epoch 14, Batch: 5000| Training Loss: 1.8651705901384354\n",
      "Epoch 14, Batch: 6000| Training Loss: 1.866461752275626\n",
      "Epoch 14, Batch: 7000| Training Loss: 1.8663919965028763\n",
      "Epoch 14, Batch: 8000| Training Loss: 1.8667335484176875\n",
      "Epoch 14, Batch: 9000| Training Loss: 1.8672009289926952\n",
      "Epoch 14, Batch: 10000| Training Loss: 1.8668005983829499\n",
      "Epoch 14, Batch: 11000| Training Loss: 1.8661511800505899\n",
      "Epoch 14, Batch: 12000| Training Loss: 1.8671527353028456\n",
      "Epoch 14, Batch: 13000| Training Loss: 1.8675254192627393\n",
      "Epoch 14, Batch: 14000| Training Loss: 1.8680306481804168\n",
      "Epoch 14, Batch: 15000| Training Loss: 1.8685803274154662\n",
      "Epoch 14, Batch: 16000| Training Loss: 1.8684601876363158\n",
      "Epoch 14, Batch: 17000| Training Loss: 1.8688835038998548\n",
      "Epoch 14, Batch: 18000| Training Loss: 1.8694053043524423\n",
      "Epoch 14, Batch: 19000| Training Loss: 1.8698301146030425\n",
      "Epoch 14, Batch: 20000| Training Loss: 1.8700080790102482\n",
      "Epoch 14, Batch: 21000| Training Loss: 1.87027894225007\n",
      "Epoch 14, Batch: 22000| Training Loss: 1.870384737816724\n",
      "Epoch 14, Training Loss: 1.8706831458930402, Validation Error: 65.27694370634836, Validation Top-3 Accuracy: 59.491275840135145, Training Error: 61.49228947287296\n",
      "Epoch 15, Batch: 1000| Training Loss: 1.8554281026124955\n",
      "Epoch 15, Batch: 2000| Training Loss: 1.8558290800452233\n",
      "Epoch 15, Batch: 3000| Training Loss: 1.85855242617925\n",
      "Epoch 15, Batch: 4000| Training Loss: 1.8587225877940654\n",
      "Epoch 15, Batch: 5000| Training Loss: 1.8612375869750977\n",
      "Epoch 15, Batch: 6000| Training Loss: 1.8611445616285007\n",
      "Epoch 15, Batch: 7000| Training Loss: 1.862041212609836\n",
      "Epoch 15, Batch: 8000| Training Loss: 1.8629673618525266\n",
      "Epoch 15, Batch: 9000| Training Loss: 1.8633748299148347\n",
      "Epoch 15, Batch: 10000| Training Loss: 1.8642362173199654\n",
      "Epoch 15, Batch: 11000| Training Loss: 1.8650298234982925\n",
      "Epoch 15, Batch: 12000| Training Loss: 1.8643476104736327\n",
      "Epoch 15, Batch: 13000| Training Loss: 1.8641736171704073\n",
      "Epoch 15, Batch: 14000| Training Loss: 1.864230799649443\n",
      "Epoch 15, Batch: 15000| Training Loss: 1.864581346154213\n",
      "Epoch 15, Batch: 16000| Training Loss: 1.864893633440137\n",
      "Epoch 15, Batch: 17000| Training Loss: 1.8654560569524765\n",
      "Epoch 15, Batch: 18000| Training Loss: 1.866036189403799\n",
      "Epoch 15, Batch: 19000| Training Loss: 1.8662516816666253\n",
      "Epoch 15, Batch: 20000| Training Loss: 1.8660237733781337\n",
      "Epoch 15, Batch: 21000| Training Loss: 1.866196448184195\n",
      "Epoch 15, Batch: 22000| Training Loss: 1.866538578049703\n",
      "Epoch 15, Training Loss: 1.8668974376100047, Validation Error: 65.317253350225, Validation Top-3 Accuracy: 59.57024983630162, Training Error: 61.40340911255766\n",
      "Epoch 16, Batch: 1000| Training Loss: 1.8602238562107085\n",
      "Epoch 16, Batch: 2000| Training Loss: 1.8567401405572892\n",
      "Epoch 16, Batch: 3000| Training Loss: 1.8579860603809357\n",
      "Epoch 16, Batch: 4000| Training Loss: 1.8575803333818912\n",
      "Epoch 16, Batch: 5000| Training Loss: 1.8599004878997802\n",
      "Epoch 16, Batch: 6000| Training Loss: 1.8591548386613528\n",
      "Epoch 16, Batch: 7000| Training Loss: 1.857751941238131\n",
      "Epoch 16, Batch: 8000| Training Loss: 1.857382930651307\n",
      "Epoch 16, Batch: 9000| Training Loss: 1.8579148432943555\n",
      "Epoch 16, Batch: 10000| Training Loss: 1.857228558933735\n",
      "Epoch 16, Batch: 11000| Training Loss: 1.8573871245600961\n",
      "Epoch 16, Batch: 12000| Training Loss: 1.858098690400521\n",
      "Epoch 16, Batch: 13000| Training Loss: 1.858894968876472\n",
      "Epoch 16, Batch: 14000| Training Loss: 1.8595821880953654\n",
      "Epoch 16, Batch: 15000| Training Loss: 1.8600738574186961\n",
      "Epoch 16, Batch: 16000| Training Loss: 1.8604636013954878\n",
      "Epoch 16, Batch: 17000| Training Loss: 1.8612593589109534\n",
      "Epoch 16, Batch: 18000| Training Loss: 1.8616376225484743\n",
      "Epoch 16, Batch: 19000| Training Loss: 1.8620381500156302\n",
      "Epoch 16, Batch: 20000| Training Loss: 1.862564516478777\n",
      "Epoch 16, Batch: 21000| Training Loss: 1.8624223669540314\n",
      "Epoch 16, Batch: 22000| Training Loss: 1.8629217866008931\n",
      "Epoch 16, Training Loss: 1.8632922892770278, Validation Error: 65.22676231295091, Validation Top-3 Accuracy: 59.49456642492686, Training Error: 61.36558473474616\n",
      "Epoch 17, Batch: 1000| Training Loss: 1.8523975481987\n",
      "Epoch 17, Batch: 2000| Training Loss: 1.8519348014593124\n",
      "Epoch 17, Batch: 3000| Training Loss: 1.8529634892145792\n",
      "Epoch 17, Batch: 4000| Training Loss: 1.8539121897816657\n",
      "Epoch 17, Batch: 5000| Training Loss: 1.8541234800577164\n",
      "Epoch 17, Batch: 6000| Training Loss: 1.8543155270616214\n",
      "Epoch 17, Batch: 7000| Training Loss: 1.8539472725731987\n",
      "Epoch 17, Batch: 8000| Training Loss: 1.8541309087872506\n",
      "Epoch 17, Batch: 9000| Training Loss: 1.854744359056155\n",
      "Epoch 17, Batch: 10000| Training Loss: 1.855306179189682\n",
      "Epoch 17, Batch: 11000| Training Loss: 1.8563816134279425\n",
      "Epoch 17, Batch: 12000| Training Loss: 1.8561870669623215\n",
      "Epoch 17, Batch: 13000| Training Loss: 1.8571230500844809\n",
      "Epoch 17, Batch: 14000| Training Loss: 1.8573695055246353\n",
      "Epoch 17, Batch: 15000| Training Loss: 1.8577089869101842\n",
      "Epoch 17, Batch: 16000| Training Loss: 1.8581235305145383\n",
      "Epoch 17, Batch: 17000| Training Loss: 1.8583761736996034\n",
      "Epoch 17, Batch: 18000| Training Loss: 1.858805027352439\n",
      "Epoch 17, Batch: 19000| Training Loss: 1.8592157740279247\n",
      "Epoch 17, Batch: 20000| Training Loss: 1.8593748833298682\n",
      "Epoch 17, Batch: 21000| Training Loss: 1.8593099532467978\n",
      "Epoch 17, Batch: 22000| Training Loss: 1.8598577512448484\n",
      "Epoch 17, Training Loss: 1.8596912268919998, Validation Error: 65.23416612509152, Validation Top-3 Accuracy: 59.635238855843546, Training Error: 61.31820034935593\n",
      "Epoch 18, Batch: 1000| Training Loss: 1.8530403599739074\n",
      "Epoch 18, Batch: 2000| Training Loss: 1.8556768921017648\n",
      "Epoch 18, Batch: 3000| Training Loss: 1.8540900129874547\n",
      "Epoch 18, Batch: 4000| Training Loss: 1.8541538175344467\n",
      "Epoch 18, Batch: 5000| Training Loss: 1.8534610314369202\n",
      "Epoch 18, Batch: 6000| Training Loss: 1.8529236391385395\n",
      "Epoch 18, Batch: 7000| Training Loss: 1.8534479495286942\n",
      "Epoch 18, Batch: 8000| Training Loss: 1.853081816494465\n",
      "Epoch 18, Batch: 9000| Training Loss: 1.8545361883772744\n",
      "Epoch 18, Batch: 10000| Training Loss: 1.8546646273851395\n",
      "Epoch 18, Batch: 11000| Training Loss: 1.8542236891876567\n",
      "Epoch 18, Batch: 12000| Training Loss: 1.8549842885335286\n",
      "Epoch 18, Batch: 13000| Training Loss: 1.8548854136925477\n",
      "Epoch 18, Batch: 14000| Training Loss: 1.854874413396631\n",
      "Epoch 18, Batch: 15000| Training Loss: 1.8545339776674907\n",
      "Epoch 18, Batch: 16000| Training Loss: 1.8550877732932567\n",
      "Epoch 18, Batch: 17000| Training Loss: 1.8551011433461133\n",
      "Epoch 18, Batch: 18000| Training Loss: 1.8553083582520484\n",
      "Epoch 18, Batch: 19000| Training Loss: 1.8556064333288294\n",
      "Epoch 18, Batch: 20000| Training Loss: 1.8558517901003362\n",
      "Epoch 18, Batch: 21000| Training Loss: 1.8562891943511508\n",
      "Epoch 18, Batch: 22000| Training Loss: 1.8560690406452525\n",
      "Epoch 18, Training Loss: 1.8562039200679818, Validation Error: 65.30820424649758, Validation Top-3 Accuracy: 59.60151037801992, Training Error: 61.258865954492286\n",
      "Epoch 19, Batch: 1000| Training Loss: 1.8496122146844864\n",
      "Epoch 19, Batch: 2000| Training Loss: 1.8460406258702278\n",
      "Epoch 19, Batch: 3000| Training Loss: 1.8468231254816054\n",
      "Epoch 19, Batch: 4000| Training Loss: 1.8450336224734782\n",
      "Epoch 19, Batch: 5000| Training Loss: 1.8452385841846466\n",
      "Epoch 19, Batch: 6000| Training Loss: 1.8446484319965044\n",
      "Epoch 19, Batch: 7000| Training Loss: 1.8457348757301058\n",
      "Epoch 19, Batch: 8000| Training Loss: 1.8461328339129686\n",
      "Epoch 19, Batch: 9000| Training Loss: 1.8464102076292037\n",
      "Epoch 19, Batch: 10000| Training Loss: 1.8462362758994102\n",
      "Epoch 19, Batch: 11000| Training Loss: 1.8467810849384827\n",
      "Epoch 19, Batch: 12000| Training Loss: 1.8473208479682603\n",
      "Epoch 19, Batch: 13000| Training Loss: 1.8481163554650086\n",
      "Epoch 19, Batch: 14000| Training Loss: 1.8492973957232066\n",
      "Epoch 19, Batch: 15000| Training Loss: 1.8492310204108555\n",
      "Epoch 19, Batch: 16000| Training Loss: 1.8499421472772957\n",
      "Epoch 19, Batch: 17000| Training Loss: 1.8506970177257762\n",
      "Epoch 19, Batch: 18000| Training Loss: 1.851222582704491\n",
      "Epoch 19, Batch: 19000| Training Loss: 1.8518403853115282\n",
      "Epoch 19, Batch: 20000| Training Loss: 1.8521429906547069\n",
      "Epoch 19, Batch: 21000| Training Loss: 1.8525230370249066\n",
      "Epoch 19, Batch: 22000| Training Loss: 1.8524981884035197\n",
      "Epoch 19, Training Loss: 1.852513237180268, Validation Error: 65.33535155767981, Validation Top-3 Accuracy: 59.62043123131717, Training Error: 61.202094750066415\n",
      "Epoch 20, Batch: 1000| Training Loss: 1.847180333852768\n",
      "Epoch 20, Batch: 2000| Training Loss: 1.8460336651802063\n",
      "Epoch 20, Batch: 3000| Training Loss: 1.8442524327039718\n",
      "Epoch 20, Batch: 4000| Training Loss: 1.8455000198185443\n",
      "Epoch 20, Batch: 5000| Training Loss: 1.8449612879753112\n",
      "Epoch 20, Batch: 6000| Training Loss: 1.8456201220353445\n",
      "Epoch 20, Batch: 7000| Training Loss: 1.8460828313146318\n",
      "Epoch 20, Batch: 8000| Training Loss: 1.8459896139204501\n",
      "Epoch 20, Batch: 9000| Training Loss: 1.8456035860511992\n",
      "Epoch 20, Batch: 10000| Training Loss: 1.845315320301056\n",
      "Epoch 20, Batch: 11000| Training Loss: 1.8454705939834768\n",
      "Epoch 20, Batch: 12000| Training Loss: 1.845613623738289\n",
      "Epoch 20, Batch: 13000| Training Loss: 1.8466936256151933\n",
      "Epoch 20, Batch: 14000| Training Loss: 1.8466541168689727\n",
      "Epoch 20, Batch: 15000| Training Loss: 1.8467102019309998\n",
      "Epoch 20, Batch: 16000| Training Loss: 1.8474270254150034\n",
      "Epoch 20, Batch: 17000| Training Loss: 1.8475994056533365\n",
      "Epoch 20, Batch: 18000| Training Loss: 1.847705188771089\n",
      "Epoch 20, Batch: 19000| Training Loss: 1.8482408190651944\n",
      "Epoch 20, Batch: 20000| Training Loss: 1.8483739684581757\n",
      "Epoch 20, Batch: 21000| Training Loss: 1.8486994701453618\n",
      "Epoch 20, Batch: 22000| Training Loss: 1.848857099137523\n",
      "Epoch 20, Training Loss: 1.8490294631212996, Validation Error: 65.3271250997458, Validation Top-3 Accuracy: 59.65498235248253, Training Error: 61.1297712144708\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('multi-modal-jan-march-g5-feb-27.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 45.01369073353509%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "if val_loader is not None:\n",
    "    with torch.no_grad():\n",
    "        for boards, sequences, lengths, labels in val_loader:\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking = True), sequences.to(device, non_blocking = True), lengths, labels.to(device, non_blocking = True)\n",
    "            outputs = model(boards, sequences, lengths)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            minus = 0\n",
    "            for idx, (sequence, label) in enumerate(zip(sequences, labels)):\n",
    "                # This tells us we're looking at games that include the opening but has developed more than the first 4 half-moves\n",
    "                if sequence[-1].item() == 0 and sequence[2].item() != 0 and sequence[3].item() != 0 and sequence[4].item() != 0:\n",
    "                    output = probabilities[idx]\n",
    "                    sorted_probs, sorted_indices = torch.sort(output, descending=True)\n",
    "                    predicted_move = sorted_indices[0]\n",
    "                    # print(predicted_move)\n",
    "                    chess_board = load_board_state_from_san(sequence, vocab)\n",
    "                    for move_idx in sorted_indices:\n",
    "                        move = vocab.get_move(move_idx.item()) # Convert index to move (e.g., 'e2e4')\n",
    "                        if is_legal_move(chess_board, move):\n",
    "                            # print(\"we found one\")\n",
    "                            predicted_move = vocab.get_id(move)\n",
    "                            break\n",
    "                    \n",
    "                    # Check if predicted move is correct\n",
    "                    correct_move = label.item() # Convert label to move\n",
    "                    # print(correct_move)\n",
    "                    if predicted_move == correct_move:\n",
    "                        val_correct += 1\n",
    "                else:\n",
    "                    minus += 1\n",
    "            val_total += (labels.size(0) - minus)\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Accuracy: {val_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 8\n",
    "let's scale all the way -- one more conv, dropout, and 256 from 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7159417\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=1, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # alpha can be set to a constant, or it can be a tensor of shape (num_classes,)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability 0\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "# Reload the data with particular batch size\n",
    "torch.multiprocessing.set_start_method('fork', force=True)\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "d_hidden = 256\n",
    "d_embed = 64\n",
    "NUM_EPOCHS = 13\n",
    "d_out = len(vocab.id_to_move.keys())\n",
    "model = MultiModalSeven(vocab,d_embed,d_hidden,d_out) \n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=1, reduction='mean')\n",
    "lr = 2e-3\n",
    "weight_decay=1e-7\n",
    "learn_decay = 0.72 # This causes the LR to be 5e-5 by epoch 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1000| Training Loss: 4.882390671253204\n",
      "Epoch 1, Batch: 2000| Training Loss: 4.525710904359817\n",
      "Epoch 1, Batch: 3000| Training Loss: 4.320944158951441\n",
      "Epoch 1, Batch: 4000| Training Loss: 4.184255250036716\n",
      "Epoch 1, Batch: 5000| Training Loss: 4.076336099815369\n",
      "Epoch 1, Batch: 6000| Training Loss: 3.9911560486157733\n",
      "Epoch 1, Batch: 7000| Training Loss: 3.9208499415261406\n",
      "Epoch 1, Batch: 8000| Training Loss: 3.8593906884789466\n",
      "Epoch 1, Batch: 9000| Training Loss: 3.807422089126375\n",
      "Epoch 1, Batch: 10000| Training Loss: 3.760690544271469\n",
      "Epoch 1, Batch: 11000| Training Loss: 3.7182563562826676\n",
      "Epoch 1, Batch: 12000| Training Loss: 3.680358818133672\n",
      "Epoch 1, Batch: 13000| Training Loss: 3.645879002167628\n",
      "Epoch 1, Batch: 14000| Training Loss: 3.6136590048074724\n",
      "Epoch 1, Batch: 15000| Training Loss: 3.584489521741867\n",
      "Epoch 1, Batch: 16000| Training Loss: 3.557563627690077\n",
      "Epoch 1, Batch: 17000| Training Loss: 3.5325243727599873\n",
      "Epoch 1, Batch: 18000| Training Loss: 3.508869124359555\n",
      "Epoch 1, Batch: 19000| Training Loss: 3.486759957401376\n",
      "Epoch 1, Batch: 20000| Training Loss: 3.4664405921339987\n",
      "Epoch 1, Batch: 21000| Training Loss: 3.446777699742998\n",
      "Epoch 1, Batch: 22000| Training Loss: 3.428070947798816\n",
      "Epoch 1, Training Loss: 3.41875673334024, Validation Error: 71.75939255834615, Validation Top-3 Accuracy: 49.33818145906201, Training Error: 77.07371631785917\n",
      "Epoch 2, Batch: 1000| Training Loss: 2.941591284751892\n",
      "Epoch 2, Batch: 2000| Training Loss: 2.9315035072565077\n",
      "Epoch 2, Batch: 3000| Training Loss: 2.9247732161680857\n",
      "Epoch 2, Batch: 4000| Training Loss: 2.918836271226406\n",
      "Epoch 2, Batch: 5000| Training Loss: 2.914639620304108\n",
      "Epoch 2, Batch: 6000| Training Loss: 2.9112655022939045\n",
      "Epoch 2, Batch: 7000| Training Loss: 2.906025267601013\n",
      "Epoch 2, Batch: 8000| Training Loss: 2.900508361786604\n",
      "Epoch 2, Batch: 9000| Training Loss: 2.895788123528163\n",
      "Epoch 2, Batch: 10000| Training Loss: 2.8920177077293396\n",
      "Epoch 2, Batch: 11000| Training Loss: 2.8881722798347473\n",
      "Epoch 2, Batch: 12000| Training Loss: 2.8854605766534807\n",
      "Epoch 2, Batch: 13000| Training Loss: 2.8819784495463736\n",
      "Epoch 2, Batch: 14000| Training Loss: 2.87888704097271\n",
      "Epoch 2, Batch: 15000| Training Loss: 2.8760263954321545\n",
      "Epoch 2, Batch: 16000| Training Loss: 2.8732528499513865\n",
      "Epoch 2, Batch: 17000| Training Loss: 2.8700369643604056\n",
      "Epoch 2, Batch: 18000| Training Loss: 2.8671835772726273\n",
      "Epoch 2, Batch: 19000| Training Loss: 2.8640811138529525\n",
      "Epoch 2, Batch: 20000| Training Loss: 2.8609221106410025\n",
      "Epoch 2, Batch: 21000| Training Loss: 2.8574553608780815\n",
      "Epoch 2, Batch: 22000| Training Loss: 2.854397321766073\n",
      "Epoch 2, Training Loss: 2.8528279473527363, Validation Error: 69.37865563224443, Validation Top-3 Accuracy: 52.89694715945031, Training Error: 72.55474230064354\n",
      "Epoch 3, Batch: 1000| Training Loss: 2.711476807594299\n",
      "Epoch 3, Batch: 2000| Training Loss: 2.6986375420093536\n",
      "Epoch 3, Batch: 3000| Training Loss: 2.6956104973951978\n",
      "Epoch 3, Batch: 4000| Training Loss: 2.6934988180994988\n",
      "Epoch 3, Batch: 5000| Training Loss: 2.6927640809059143\n",
      "Epoch 3, Batch: 6000| Training Loss: 2.6930875275532404\n",
      "Epoch 3, Batch: 7000| Training Loss: 2.690596017428807\n",
      "Epoch 3, Batch: 8000| Training Loss: 2.689850678175688\n",
      "Epoch 3, Batch: 9000| Training Loss: 2.689959467808406\n",
      "Epoch 3, Batch: 10000| Training Loss: 2.6886531410217285\n",
      "Epoch 3, Batch: 11000| Training Loss: 2.687575924678282\n",
      "Epoch 3, Batch: 12000| Training Loss: 2.6862120212515195\n",
      "Epoch 3, Batch: 13000| Training Loss: 2.684805941618406\n",
      "Epoch 3, Batch: 14000| Training Loss: 2.6831857513189314\n",
      "Epoch 3, Batch: 15000| Training Loss: 2.681491815296809\n",
      "Epoch 3, Batch: 16000| Training Loss: 2.680419419378042\n",
      "Epoch 3, Batch: 17000| Training Loss: 2.6787068829957175\n",
      "Epoch 3, Batch: 18000| Training Loss: 2.677503168874317\n",
      "Epoch 3, Batch: 19000| Training Loss: 2.676145882342991\n",
      "Epoch 3, Batch: 20000| Training Loss: 2.6748790309906005\n",
      "Epoch 3, Batch: 21000| Training Loss: 2.6736307463759466\n",
      "Epoch 3, Batch: 22000| Training Loss: 2.672491366039623\n",
      "Epoch 3, Training Loss: 2.671978422660464, Validation Error: 68.04843738431543, Validation Top-3 Accuracy: 54.95602958165626, Training Error: 70.80345975288766\n",
      "Epoch 4, Batch: 1000| Training Loss: 2.573667897939682\n",
      "Epoch 4, Batch: 2000| Training Loss: 2.5727008554935455\n",
      "Epoch 4, Batch: 3000| Training Loss: 2.5717783908049268\n",
      "Epoch 4, Batch: 4000| Training Loss: 2.568775460422039\n",
      "Epoch 4, Batch: 5000| Training Loss: 2.5688624884605407\n",
      "Epoch 4, Batch: 6000| Training Loss: 2.570256034374237\n",
      "Epoch 4, Batch: 7000| Training Loss: 2.569336281299591\n",
      "Epoch 4, Batch: 8000| Training Loss: 2.5696215360164643\n",
      "Epoch 4, Batch: 9000| Training Loss: 2.5681204744974773\n",
      "Epoch 4, Batch: 10000| Training Loss: 2.566972803926468\n",
      "Epoch 4, Batch: 11000| Training Loss: 2.5663227054205806\n",
      "Epoch 4, Batch: 12000| Training Loss: 2.566467034270366\n",
      "Epoch 4, Batch: 13000| Training Loss: 2.565767810188807\n",
      "Epoch 4, Batch: 14000| Training Loss: 2.564708875971181\n",
      "Epoch 4, Batch: 15000| Training Loss: 2.5645529107650122\n",
      "Epoch 4, Batch: 16000| Training Loss: 2.563648518078029\n",
      "Epoch 4, Batch: 17000| Training Loss: 2.563034244025455\n",
      "Epoch 4, Batch: 18000| Training Loss: 2.562288401954704\n",
      "Epoch 4, Batch: 19000| Training Loss: 2.56159344227063\n",
      "Epoch 4, Batch: 20000| Training Loss: 2.5608539379000663\n",
      "Epoch 4, Batch: 21000| Training Loss: 2.5604154872440157\n",
      "Epoch 4, Batch: 22000| Training Loss: 2.559777727116238\n",
      "Epoch 4, Training Loss: 2.5595132613282487, Validation Error: 67.15586669847563, Validation Top-3 Accuracy: 56.111024277993536, Training Error: 69.62602012381595\n",
      "Epoch 5, Batch: 1000| Training Loss: 2.4876708244085313\n",
      "Epoch 5, Batch: 2000| Training Loss: 2.484573240697384\n",
      "Epoch 5, Batch: 3000| Training Loss: 2.4849979756673175\n",
      "Epoch 5, Batch: 4000| Training Loss: 2.483901710301638\n",
      "Epoch 5, Batch: 5000| Training Loss: 2.4827095899105074\n",
      "Epoch 5, Batch: 6000| Training Loss: 2.4846035702625913\n",
      "Epoch 5, Batch: 7000| Training Loss: 2.483066918849945\n",
      "Epoch 5, Batch: 8000| Training Loss: 2.482902629300952\n",
      "Epoch 5, Batch: 9000| Training Loss: 2.4826867778433694\n",
      "Epoch 5, Batch: 10000| Training Loss: 2.482954778337479\n",
      "Epoch 5, Batch: 11000| Training Loss: 2.482731701048938\n",
      "Epoch 5, Batch: 12000| Training Loss: 2.481930013914903\n",
      "Epoch 5, Batch: 13000| Training Loss: 2.4820091540721747\n",
      "Epoch 5, Batch: 14000| Training Loss: 2.482012945447649\n",
      "Epoch 5, Batch: 15000| Training Loss: 2.481644153221448\n",
      "Epoch 5, Batch: 16000| Training Loss: 2.4818708631172774\n",
      "Epoch 5, Batch: 17000| Training Loss: 2.481092033940203\n",
      "Epoch 5, Batch: 18000| Training Loss: 2.480991665363312\n",
      "Epoch 5, Batch: 19000| Training Loss: 2.4805022336056357\n",
      "Epoch 5, Batch: 20000| Training Loss: 2.4805164358019827\n",
      "Epoch 5, Batch: 21000| Training Loss: 2.4805244783106306\n",
      "Epoch 5, Batch: 22000| Training Loss: 2.480667262895541\n",
      "Epoch 5, Training Loss: 2.4803813338359, Validation Error: 66.60387137110374, Validation Top-3 Accuracy: 56.90240953046051, Training Error: 68.78124104831718\n",
      "Epoch 6, Batch: 1000| Training Loss: 2.426870351791382\n",
      "Epoch 6, Batch: 2000| Training Loss: 2.4251732823848724\n",
      "Epoch 6, Batch: 3000| Training Loss: 2.4251962911287945\n",
      "Epoch 6, Batch: 4000| Training Loss: 2.4224344259798527\n",
      "Epoch 6, Batch: 5000| Training Loss: 2.4213844990491866\n",
      "Epoch 6, Batch: 6000| Training Loss: 2.4198214433789254\n",
      "Epoch 6, Batch: 7000| Training Loss: 2.4197707193578992\n",
      "Epoch 6, Batch: 8000| Training Loss: 2.420149554222822\n",
      "Epoch 6, Batch: 9000| Training Loss: 2.421023500839869\n",
      "Epoch 6, Batch: 10000| Training Loss: 2.4211286475896836\n",
      "Epoch 6, Batch: 11000| Training Loss: 2.4215675715208054\n",
      "Epoch 6, Batch: 12000| Training Loss: 2.421999078472455\n",
      "Epoch 6, Batch: 13000| Training Loss: 2.4224377567768096\n",
      "Epoch 6, Batch: 14000| Training Loss: 2.4222684759667943\n",
      "Epoch 6, Batch: 15000| Training Loss: 2.4228512387196224\n",
      "Epoch 6, Batch: 16000| Training Loss: 2.4227498471215365\n",
      "Epoch 6, Batch: 17000| Training Loss: 2.423253537255175\n",
      "Epoch 6, Batch: 18000| Training Loss: 2.4226736563775275\n",
      "Epoch 6, Batch: 19000| Training Loss: 2.4232468116597126\n",
      "Epoch 6, Batch: 20000| Training Loss: 2.4230820542812346\n",
      "Epoch 6, Batch: 21000| Training Loss: 2.422946887657756\n",
      "Epoch 6, Batch: 22000| Training Loss: 2.4227759532440793\n",
      "Epoch 6, Training Loss: 2.4226775275553654, Validation Error: 66.10041214554249, Validation Top-3 Accuracy: 57.6485492642414, Training Error: 68.11100138654747\n",
      "Epoch 7, Batch: 1000| Training Loss: 2.380709932923317\n",
      "Epoch 7, Batch: 2000| Training Loss: 2.3718137303590776\n",
      "Epoch 7, Batch: 3000| Training Loss: 2.3710798757473626\n",
      "Epoch 7, Batch: 4000| Training Loss: 2.3717485907375813\n",
      "Epoch 7, Batch: 5000| Training Loss: 2.374629522252083\n",
      "Epoch 7, Batch: 6000| Training Loss: 2.374962603290876\n",
      "Epoch 7, Batch: 7000| Training Loss: 2.3750980682032448\n",
      "Epoch 7, Batch: 8000| Training Loss: 2.374863917797804\n",
      "Epoch 7, Batch: 9000| Training Loss: 2.376119810382525\n",
      "Epoch 7, Batch: 10000| Training Loss: 2.3770465522885322\n",
      "Epoch 7, Batch: 11000| Training Loss: 2.3782249908013777\n",
      "Epoch 7, Batch: 12000| Training Loss: 2.378036395649115\n",
      "Epoch 7, Batch: 13000| Training Loss: 2.3777456975441713\n",
      "Epoch 7, Batch: 14000| Training Loss: 2.3777559858560564\n",
      "Epoch 7, Batch: 15000| Training Loss: 2.378697829755147\n",
      "Epoch 7, Batch: 16000| Training Loss: 2.3786052384153007\n",
      "Epoch 7, Batch: 17000| Training Loss: 2.379348889996024\n",
      "Epoch 7, Batch: 18000| Training Loss: 2.379707241197427\n",
      "Epoch 7, Batch: 19000| Training Loss: 2.379676738789207\n",
      "Epoch 7, Batch: 20000| Training Loss: 2.379371315139532\n",
      "Epoch 7, Batch: 21000| Training Loss: 2.3796408682323635\n",
      "Epoch 7, Batch: 22000| Training Loss: 2.379964594434608\n",
      "Epoch 7, Training Loss: 2.379990744004094, Validation Error: 65.78287086928981, Validation Top-3 Accuracy: 58.079615658659485, Training Error: 67.57997067571588\n",
      "Epoch 8, Batch: 1000| Training Loss: 2.3453375034332273\n",
      "Epoch 8, Batch: 2000| Training Loss: 2.3444930915236473\n",
      "Epoch 8, Batch: 3000| Training Loss: 2.34744098897775\n",
      "Epoch 8, Batch: 4000| Training Loss: 2.348346684962511\n",
      "Epoch 8, Batch: 5000| Training Loss: 2.3492369186878204\n",
      "Epoch 8, Batch: 6000| Training Loss: 2.347684342503548\n",
      "Epoch 8, Batch: 7000| Training Loss: 2.348094582438469\n",
      "Epoch 8, Batch: 8000| Training Loss: 2.34859713229537\n",
      "Epoch 8, Batch: 9000| Training Loss: 2.349200111442142\n",
      "Epoch 8, Batch: 10000| Training Loss: 2.3487545715808866\n",
      "Epoch 8, Batch: 11000| Training Loss: 2.3483784544901414\n",
      "Epoch 8, Batch: 12000| Training Loss: 2.349092869927486\n",
      "Epoch 8, Batch: 13000| Training Loss: 2.3488673469195\n",
      "Epoch 8, Batch: 14000| Training Loss: 2.34837219526938\n",
      "Epoch 8, Batch: 15000| Training Loss: 2.3479636785904567\n",
      "Epoch 8, Batch: 16000| Training Loss: 2.3484567326381804\n",
      "Epoch 8, Batch: 17000| Training Loss: 2.3489306917471042\n",
      "Epoch 8, Batch: 18000| Training Loss: 2.348811751378907\n",
      "Epoch 8, Batch: 19000| Training Loss: 2.3492922964221554\n",
      "Epoch 8, Batch: 20000| Training Loss: 2.3499031863987447\n",
      "Epoch 8, Batch: 21000| Training Loss: 2.349571650385857\n",
      "Epoch 8, Batch: 22000| Training Loss: 2.350089599723166\n",
      "Epoch 8, Training Loss: 2.3500137001097636, Validation Error: 65.63232668909748, Validation Top-3 Accuracy: 58.23262777623202, Training Error: 67.21727922877064\n",
      "Epoch 9, Batch: 1000| Training Loss: 2.3164296123981476\n",
      "Epoch 9, Batch: 2000| Training Loss: 2.3244239725470544\n",
      "Epoch 9, Batch: 3000| Training Loss: 2.3264724646011987\n",
      "Epoch 9, Batch: 4000| Training Loss: 2.3248914309740067\n",
      "Epoch 9, Batch: 5000| Training Loss: 2.3255209552049636\n",
      "Epoch 9, Batch: 6000| Training Loss: 2.3242496726711592\n",
      "Epoch 9, Batch: 7000| Training Loss: 2.324537232501166\n",
      "Epoch 9, Batch: 8000| Training Loss: 2.3238577519059183\n",
      "Epoch 9, Batch: 9000| Training Loss: 2.324179584622383\n",
      "Epoch 9, Batch: 10000| Training Loss: 2.3241438903570177\n",
      "Epoch 9, Batch: 11000| Training Loss: 2.3249222456325183\n",
      "Epoch 9, Batch: 12000| Training Loss: 2.325141662289699\n",
      "Epoch 9, Batch: 13000| Training Loss: 2.325888098496657\n",
      "Epoch 9, Batch: 14000| Training Loss: 2.325938641514097\n",
      "Epoch 9, Batch: 15000| Training Loss: 2.3257954658349353\n",
      "Epoch 9, Batch: 16000| Training Loss: 2.325896268688142\n",
      "Epoch 9, Batch: 17000| Training Loss: 2.3257376770061606\n",
      "Epoch 9, Batch: 18000| Training Loss: 2.3263202075627114\n",
      "Epoch 9, Batch: 19000| Training Loss: 2.3263040491028835\n",
      "Epoch 9, Batch: 20000| Training Loss: 2.3263068618535994\n",
      "Epoch 9, Batch: 21000| Training Loss: 2.32653407791115\n",
      "Epoch 9, Batch: 22000| Training Loss: 2.3263799435550516\n",
      "Epoch 9, Training Loss: 2.326600234377968, Validation Error: 65.42090672019349, Validation Top-3 Accuracy: 58.45062891442523, Training Error: 66.90966173852894\n",
      "Epoch 10, Batch: 1000| Training Loss: 2.3106270071268082\n",
      "Epoch 10, Batch: 2000| Training Loss: 2.308262016236782\n",
      "Epoch 10, Batch: 3000| Training Loss: 2.3078084379037223\n",
      "Epoch 10, Batch: 4000| Training Loss: 2.3076183718442915\n",
      "Epoch 10, Batch: 5000| Training Loss: 2.3064468202114106\n",
      "Epoch 10, Batch: 6000| Training Loss: 2.309446683883667\n",
      "Epoch 10, Batch: 7000| Training Loss: 2.3093127893550056\n",
      "Epoch 10, Batch: 8000| Training Loss: 2.3085829180330038\n",
      "Epoch 10, Batch: 9000| Training Loss: 2.3087653836674162\n",
      "Epoch 10, Batch: 10000| Training Loss: 2.308296024096012\n",
      "Epoch 10, Batch: 11000| Training Loss: 2.309454042423855\n",
      "Epoch 10, Batch: 12000| Training Loss: 2.309700202782949\n",
      "Epoch 10, Batch: 13000| Training Loss: 2.309743525119928\n",
      "Epoch 10, Batch: 14000| Training Loss: 2.309466533124447\n",
      "Epoch 10, Batch: 15000| Training Loss: 2.309733363032341\n",
      "Epoch 10, Batch: 16000| Training Loss: 2.309489685423672\n",
      "Epoch 10, Batch: 17000| Training Loss: 2.309566037142978\n",
      "Epoch 10, Batch: 18000| Training Loss: 2.309884448349476\n",
      "Epoch 10, Batch: 19000| Training Loss: 2.3098435537815094\n",
      "Epoch 10, Batch: 20000| Training Loss: 2.3100677733659745\n",
      "Epoch 10, Batch: 21000| Training Loss: 2.310322448787235\n",
      "Epoch 10, Batch: 22000| Training Loss: 2.310538001320579\n",
      "Epoch 10, Training Loss: 2.31061198238892, Validation Error: 65.3205439333986, Validation Top-3 Accuracy: 58.620093944629566, Training Error: 66.72279130053165\n",
      "Epoch 11, Batch: 1000| Training Loss: 2.306349489450455\n",
      "Epoch 11, Batch: 2000| Training Loss: 2.3003764147162435\n",
      "Epoch 11, Batch: 3000| Training Loss: 2.301346318602562\n",
      "Epoch 11, Batch: 4000| Training Loss: 2.2999627596735954\n",
      "Epoch 11, Batch: 5000| Training Loss: 2.298186535978317\n",
      "Epoch 11, Batch: 6000| Training Loss: 2.2986140716671946\n",
      "Epoch 11, Batch: 7000| Training Loss: 2.298613945450102\n",
      "Epoch 11, Batch: 8000| Training Loss: 2.2978561834543942\n",
      "Epoch 11, Batch: 9000| Training Loss: 2.29839813847012\n",
      "Epoch 11, Batch: 10000| Training Loss: 2.299184122979641\n",
      "Epoch 11, Batch: 11000| Training Loss: 2.298685863148082\n",
      "Epoch 11, Batch: 12000| Training Loss: 2.298420347362757\n",
      "Epoch 11, Batch: 13000| Training Loss: 2.2987737346245694\n",
      "Epoch 11, Batch: 14000| Training Loss: 2.2988972767676628\n",
      "Epoch 11, Batch: 15000| Training Loss: 2.2992899445374806\n",
      "Epoch 11, Batch: 16000| Training Loss: 2.2991484599635004\n",
      "Epoch 11, Batch: 17000| Training Loss: 2.2987593467095317\n",
      "Epoch 11, Batch: 18000| Training Loss: 2.2986506006519\n",
      "Epoch 11, Batch: 19000| Training Loss: 2.298937938313735\n",
      "Epoch 11, Batch: 20000| Training Loss: 2.2988803580105306\n",
      "Epoch 11, Batch: 21000| Training Loss: 2.298895923767771\n",
      "Epoch 11, Batch: 22000| Training Loss: 2.29917611678622\n",
      "Epoch 11, Training Loss: 2.2991483212098713, Validation Error: 65.28928339324938, Validation Top-3 Accuracy: 58.71387556669536, Training Error: 66.55569899415558\n",
      "Epoch 12, Batch: 1000| Training Loss: 2.2948925909996034\n",
      "Epoch 12, Batch: 2000| Training Loss: 2.2907428787350654\n",
      "Epoch 12, Batch: 3000| Training Loss: 2.2917666377623878\n",
      "Epoch 12, Batch: 4000| Training Loss: 2.293661118328571\n",
      "Epoch 12, Batch: 5000| Training Loss: 2.2918260771512986\n",
      "Epoch 12, Batch: 6000| Training Loss: 2.291473979473114\n",
      "Epoch 12, Batch: 7000| Training Loss: 2.290579402906554\n",
      "Epoch 12, Batch: 8000| Training Loss: 2.29063432957232\n",
      "Epoch 12, Batch: 9000| Training Loss: 2.2906630306773716\n",
      "Epoch 12, Batch: 10000| Training Loss: 2.290411179935932\n",
      "Epoch 12, Batch: 11000| Training Loss: 2.2917225022207606\n",
      "Epoch 12, Batch: 12000| Training Loss: 2.290750288685163\n",
      "Epoch 12, Batch: 13000| Training Loss: 2.2914687844514847\n",
      "Epoch 12, Batch: 14000| Training Loss: 2.29101157867057\n",
      "Epoch 12, Batch: 15000| Training Loss: 2.290529222838084\n",
      "Epoch 12, Batch: 16000| Training Loss: 2.29009989567101\n",
      "Epoch 12, Batch: 17000| Training Loss: 2.290075323203031\n",
      "Epoch 12, Batch: 18000| Training Loss: 2.2901161958376566\n",
      "Epoch 12, Batch: 19000| Training Loss: 2.2899101474661574\n",
      "Epoch 12, Batch: 20000| Training Loss: 2.2898327665030958\n",
      "Epoch 12, Batch: 21000| Training Loss: 2.2896771327257155\n",
      "Epoch 12, Batch: 22000| Training Loss: 2.2900687263662163\n",
      "Epoch 12, Training Loss: 2.290194369874014, Validation Error: 65.25884549889355, Validation Top-3 Accuracy: 58.840563018094535, Training Error: 66.46044529545446\n",
      "Epoch 13, Batch: 1000| Training Loss: 2.276117240548134\n",
      "Epoch 13, Batch: 2000| Training Loss: 2.2806292642354964\n",
      "Epoch 13, Batch: 3000| Training Loss: 2.280812165101369\n",
      "Epoch 13, Batch: 4000| Training Loss: 2.2830326341390608\n",
      "Epoch 13, Batch: 5000| Training Loss: 2.2847879681825636\n",
      "Epoch 13, Batch: 6000| Training Loss: 2.2827763640681904\n",
      "Epoch 13, Batch: 7000| Training Loss: 2.282246209008353\n",
      "Epoch 13, Batch: 8000| Training Loss: 2.2824312883764506\n",
      "Epoch 13, Batch: 9000| Training Loss: 2.2839440090788736\n",
      "Epoch 13, Batch: 10000| Training Loss: 2.283828709554672\n",
      "Epoch 13, Batch: 11000| Training Loss: 2.2840397106950934\n",
      "Epoch 13, Batch: 12000| Training Loss: 2.2841046801507474\n",
      "Epoch 13, Batch: 13000| Training Loss: 2.2847997989104343\n",
      "Epoch 13, Batch: 14000| Training Loss: 2.284665596629892\n",
      "Epoch 13, Batch: 15000| Training Loss: 2.2848034077326456\n",
      "Epoch 13, Batch: 16000| Training Loss: 2.2847809025868773\n",
      "Epoch 13, Batch: 17000| Training Loss: 2.2854068148977618\n",
      "Epoch 13, Batch: 18000| Training Loss: 2.285360443982813\n",
      "Epoch 13, Batch: 19000| Training Loss: 2.2854007227734514\n",
      "Epoch 13, Batch: 20000| Training Loss: 2.2855003897845747\n",
      "Epoch 13, Batch: 21000| Training Loss: 2.285454920570056\n",
      "Epoch 13, Batch: 22000| Training Loss: 2.28542319257151\n",
      "Epoch 13, Training Loss: 2.285471364099312, Validation Error: 65.23498877088491, Validation Top-3 Accuracy: 58.860306516596786, Training Error: 66.38119421813514\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_error,train_loss_values, val_error, val_loss_value = train(device, model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, learn_decay)\n",
    "\n",
    "# Plot the training error\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_error, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Validation Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('multi-modal-big-jan-march-g5-march-1.png')  # This will save the plot as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 45.38838449344286%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "if val_loader is not None:\n",
    "    with torch.no_grad():\n",
    "        for boards, sequences, lengths, labels in val_loader:\n",
    "            boards, sequences, lengths, labels = boards.to(device, non_blocking = True), sequences.to(device, non_blocking = True), lengths, labels.to(device, non_blocking = True)\n",
    "            outputs = model(boards, sequences, lengths)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            minus = 0\n",
    "            for idx, (sequence, label) in enumerate(zip(sequences, labels)):\n",
    "                # This tells us we're looking at games that include the opening but has developed more than the first 4 half-moves\n",
    "                if sequence[-1].item() == 0 and sequence[2].item() != 0 and sequence[3].item() != 0 and sequence[4].item() != 0:\n",
    "                    output = probabilities[idx]\n",
    "                    sorted_probs, sorted_indices = torch.sort(output, descending=True)\n",
    "                    predicted_move = sorted_indices[0]\n",
    "                    # print(predicted_move)\n",
    "                    chess_board = load_board_state_from_san(sequence, vocab)\n",
    "                    for move_idx in sorted_indices:\n",
    "                        move = vocab.get_move(move_idx.item()) # Convert index to move (e.g., 'e2e4')\n",
    "                        if is_legal_move(chess_board, move):\n",
    "                            # print(\"we found one\")\n",
    "                            predicted_move = vocab.get_id(move)\n",
    "                            break\n",
    "                    \n",
    "                    # Check if predicted move is correct\n",
    "                    correct_move = label.item() # Convert label to move\n",
    "                    # print(correct_move)\n",
    "                    if predicted_move == correct_move:\n",
    "                        val_correct += 1\n",
    "                else:\n",
    "                    minus += 1\n",
    "            val_total += (labels.size(0) - minus)\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Accuracy: {val_accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
