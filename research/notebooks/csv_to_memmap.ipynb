{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "import dask.dataframe as dd \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import pickle\n",
    "import utils\n",
    "import models\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         game_id                                              moves  \\\n",
      "0       0Gws7Yna  e2e4 d7d5 e4d5 d8d5 b1c3 d5d8 d2d4 e7e6 g1f3 g...   \n",
      "1       0JraozGk  e2e4 e7e6 g1f3 d7d5 e4d5 e6d5 b1c3 g8f6 h2h3 f...   \n",
      "2       0b0GOLhX  e2e4 e7e5 d2d4 e5d4 d1d4 b8c6 d4e3 g8f6 b1c3 f...   \n",
      "3       0cFU8tom  d2d4 d7d5 c2c4 g8f6 b1c3 d5c4 g1f3 f6d5 d1a4 d...   \n",
      "4       0t0cIxvG  e2e4 g8f6 b1c3 e7e5 g1f3 b8c6 d2d4 f8b4 d4e5 f...   \n",
      "...          ...                                                ...   \n",
      "421830  zDJvok19  b1c3 d7d5 e2e3 e7e5 d2d4 e5e4 f2f3 c8f5 f3e4 d...   \n",
      "421831  zOR2NZIz  e2e4 c7c5 f1c4 e7e6 d2d3 b8c6 c4b5 d8c7 b5c6 c...   \n",
      "421832  zSvzvvNe  e2e4 c7c5 g1f3 e7e6 d2d4 c5d4 f3d4 a7a6 c2c4 g...   \n",
      "421833  zfGfeqAo  e2e4 e7e6 g1f3 f8b4 c2c3 b4e7 d2d4 a7a6 e4e5 d...   \n",
      "421834  zvkftdLZ  d2d4 g8f6 c1f4 g7g6 g1f3 f8g7 e2e3 d7d6 f1d3 e...   \n",
      "\n",
      "        white_elo  black_elo  white_active  \\\n",
      "0            1529       1504          True   \n",
      "1            1519       1506          True   \n",
      "2            1562       1543          True   \n",
      "3            1578       1581          True   \n",
      "4            1509       1575          True   \n",
      "...           ...        ...           ...   \n",
      "421830       1500       1512          True   \n",
      "421831       1537       1580          True   \n",
      "421832       1545       1558          True   \n",
      "421833       1531       1558          True   \n",
      "421834       1575       1577          True   \n",
      "\n",
      "                                                    board  \n",
      "0       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "1       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "2       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "3       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "4       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "...                                                   ...  \n",
      "421830  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "421831  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "421832  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "421833  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "421834  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "\n",
      "[421835 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "grouped_df = pd.read_csv(\"../data/haha-longer-apr-jun.csv\")\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_sequences, fens, trainX, trainY, vocab = df_to_data(grouped_df, fixed_window=True, sampling_rate=0.25)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainX_sequences, fens, trainX_seqlengths, trainY = np.array(trainX), np.array(trainX_sequences), np.array(fens), np.array(trainX_seqlengths), np.array(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last step of saving our data onto our disk so that it's ready to load as we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_memmap(array, filename):\n",
    "    # Determine the dtype and shape of the array to create a compatible memmap\n",
    "    dtype = array.dtype\n",
    "    shape = array.shape\n",
    "    \n",
    "    # Create a memmap file with write mode, which will also allocate the disk space\n",
    "    memmap_array = np.memmap(filename, dtype=dtype, mode='w+', shape=shape)\n",
    "    \n",
    "    # Copy the data into the memmap array\n",
    "    memmap_array[:] = array[:]\n",
    "    \n",
    "    # Flush memory changes to disk to ensure all data is written\n",
    "    memmap_array.flush()\n",
    "\n",
    "    # Return the path for confirmation\n",
    "    return filename\n",
    "\n",
    "# Save each array as a memmap file\n",
    "filenames = [\n",
    "    save_as_memmap(fens, './../data/jan-march/fens.memmap')\n",
    "    save_as_memmap(trainX_sequences, './../data/jan-march/trainX_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/jan-march/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/jan-march/trainY.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/jan-march/trainX_seqlengths.memmap')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../data/jan-march/vocab.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished processing the data, let's now load in the data (assuming we're starting from fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (3038976,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../data/jan-march/vocab.pkl', 'rb') as inp:\n",
    "    vocab = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8121\n",
      "torch.Size([12, 8, 8])\n",
      "[[[0 0 0 0 0 0 0 0]\n",
      "  [1 1 0 0 1 0 1 1]\n",
      "  [0 0 1 0 0 1 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[1 0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [1 1 1 1 0 1 1 1]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 1]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, sequences, boards, lengths, labels):\n",
    "        self.sequences = sequences\n",
    "        self.boards = boards\n",
    "        self.lengths = lengths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.boards[idx], dtype=torch.float32),\n",
    "            torch.from_numpy(self.sequences[idx], dtype=torch.long),\n",
    "            torch.from_numpy(self.lengths[idx], dtype=torch.long),\n",
    "            torch.from_numpy(self.labels[idx], dtype=torch.long),\n",
    "        )\n",
    "print(len(vocab.id_to_move.keys()))\n",
    "print(torch.tensor(trainX[0]).shape)\n",
    "print(trainX[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another form of data (only board states but give all the last 8 board states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainX_sequences, trainX, trainY, vocab = df_to_data_extended(grouped_df, fixed_window=True, fixed_window_size=8,sampling_rate=0.25)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainX_sequences, trainX_seqlengths, trainY = np.array(trainX), np.array(trainX_sequences), np.array(trainX_seqlengths), np.array(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each array as a memmap file\n",
    "filenames = [\n",
    "    save_as_memmap(trainX_sequences, './../data/jan-march/trainX_1_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/jan-march/trainX_1.memmap'),\n",
    "    save_as_memmap(trainY, './../data/jan-march/trainY_1.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/jan-march/trainX_1_seqlengths.memmap')\n",
    "]\n",
    "\n",
    "with open('./../data/jan-march/vocab_1.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For trainX_sequences\n",
    "# dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "# trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# # For trainX\n",
    "# dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "# trainX = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# # For trainY\n",
    "# dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "# shape_trainY = (3038976,)  # replace with the correct shape\n",
    "# trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# # For trainX_seqlengths\n",
    "# dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "# trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
