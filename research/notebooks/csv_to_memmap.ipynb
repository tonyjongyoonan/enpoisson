{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import pickle\n",
    "import utils\n",
    "import models\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         game_id                                              moves  \\\n",
      "0       00VRM44j  e2e4 g8f6 e4e5 f6g8 f1b5 f7f6 e5e6 c7c6 e6d7 c...   \n",
      "1       0MG5pz3L  c2c4 g7g6 e2e4 f8g7 d2d3 d7d6 f1e2 g8f6 g1f3 e...   \n",
      "2       0MV7dmua  e2e4 e7e5 f2f4 e5f4 g1f3 d7d5 e4d5 d8d5 b1c3 d...   \n",
      "3       0UNsyqEb  d2d4 d7d5 c2c4 g8f6 b1c3 c8f5 c1g5 e7e6 e2e3 h...   \n",
      "4       10mypbCS  d2d4 g7g6 c1h6 f8h6 g1f3 g8f6 e2e3 b8c6 f1b5 d...   \n",
      "...          ...                                                ...   \n",
      "164316  yckDW8pr  d2d4 d7d5 c1f4 c8f5 e2e3 e7e6 f1d3 f5g6 g1f3 g...   \n",
      "164317  yjFqLLIM  d2d4 g8f6 c2c4 e7e6 g1f3 d7d5 e2e3 c7c6 b2b3 f...   \n",
      "164318  yzgxpBPa  d2d4 d7d5 c2c4 e7e6 b1c3 g8f6 c1g5 f8b4 d1c2 b...   \n",
      "164319  zHpwiwWK  e2e4 c7c5 g1f3 b8c6 f1b5 d7d6 e1g1 e7e5 c2c3 g...   \n",
      "164320  zI8GQITc  e2e4 e7e5 g1f3 b8c6 f1b5 a7a6 b5a4 b7b5 a4b3 c...   \n",
      "\n",
      "        white_elo  black_elo  white_active  \\\n",
      "0            1523       1500          True   \n",
      "1            1538       1580          True   \n",
      "2            1587       1575          True   \n",
      "3            1507       1545          True   \n",
      "4            1500       1500          True   \n",
      "...           ...        ...           ...   \n",
      "164316       1520       1500          True   \n",
      "164317       1525       1572          True   \n",
      "164318       1532       1509          True   \n",
      "164319       1571       1557          True   \n",
      "164320       1512       1548          True   \n",
      "\n",
      "                                                    board  \n",
      "0       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "1       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "2       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "3       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "4       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "...                                                   ...  \n",
      "164316  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "164317  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "164318  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "164319  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "164320  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "\n",
      "[164321 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "grouped_df = pd.read_csv(\"../data/haha_longer-jan.csv\")\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../data/jan-march/vocab.pkl', 'rb') as inp:\n",
    "    vocab_old = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, seq_lengths, vocab = df_to_data_fen_only_padded(grouped_df, fixed_window=True, sampling_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY, seq_lengths = np.asarray(trainY), np.asarray(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_sequences, fens, trainX, trainY, vocab = df_to_data_black(grouped_df, fixed_window=True, sampling_rate=0.25)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainX_sequences, fens, trainX_seqlengths, trainY = np.asarray(trainX), np.asarray(trainX_sequences), np.asarray(fens), np.asarray(trainX_seqlengths), np.asarray(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last step of saving our data onto our disk so that it's ready to load as we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_memmap(array, filename):\n",
    "    # Determine the dtype and shape of the array to create a compatible memmap\n",
    "    dtype = array.dtype\n",
    "    shape = array.shape\n",
    "    \n",
    "    # Create a memmap file with write mode, which will also allocate the disk space\n",
    "    memmap_array = np.memmap(filename, dtype=dtype, mode='w+', shape=shape)\n",
    "    \n",
    "    # Copy the data into the memmap array\n",
    "    memmap_array[:] = array[:]\n",
    "    \n",
    "    # Flush memory changes to disk to ensure all data is written\n",
    "    memmap_array.flush()\n",
    "\n",
    "    # Return the path for confirmation\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for black multi-modal\n",
    "filenames = [\n",
    "    save_as_memmap(trainX_sequences, './../data/black-data/jan/trainX_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/black-data/jan/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/black-data/jan/trainY.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/black-data/jan/trainX_seqlengths.memmap')\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(fens, columns=['fens'])\n",
    "csv_filename = './../data/black-data/jan/fens.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "with open('./../data/black-data/jan/vocab.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for transformer data\n",
    "filenames = [\n",
    "    # save_as_memmap(trainX, './../data/transformer/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/transformer/trainY.memmap'),\n",
    "    save_as_memmap(trainY, './../data/transformer/seq_lengths.memmap')\n",
    "]\n",
    "with open('./../data/transformer/vocab.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for lengths so we can load in files correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1977299, 12, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1977299,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished processing the data, let's now load in the data (assuming we're starting from fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you forget the shape\n",
    "def find_working_shape(filename, dtype, max_first_dim, other_dims):\n",
    "\n",
    "    # Try decreasing sizes from the max_first_dim until we find a working shape\n",
    "    for first_dim in range(max_first_dim, 0, -1):\n",
    "        shape_to_try = (first_dim,) + other_dims\n",
    "        \n",
    "        try:\n",
    "            # Attempt to load the memmap with the current shape\n",
    "            memmap_array = np.memmap(filename, dtype=dtype, mode='r', shape=shape_to_try)\n",
    "            # If successful, return the array\n",
    "            print(f\"Successful shape: {shape_to_try}\")\n",
    "            return memmap_array\n",
    "        except ValueError as e:\n",
    "            # Catch the ValueError if the shape is not feasible, and try the next size\n",
    "            continue\n",
    "    \n",
    "    raise ValueError(\"Could not find a working shape within the given bounds.\")\n",
    "\n",
    "dtype_trainX = np.int64\n",
    "max_first_dim = 3038976  # This is your starting point, the upper bound of the first dimension\n",
    "other_dims = (12, 8, 8)  # The other dimensions of the shape, assumed to be correct\n",
    "\n",
    "trainX_filename = './../data/apr-jun/trainX.memmap'\n",
    "\n",
    "# Try to find a working memmap shape\n",
    "dummy = find_working_shape(trainX_filename, dtype_trainX, max_first_dim, other_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trainX\n",
    "dtype_trainX = np.int32  # or the correct dtype for your data\n",
    "shape_trainX = (130265, 750)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/transformer/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int32 # or the correct dtype for your data\n",
    "shape_trainY = (130265, 7)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/transformer/trainY.memmap', dtype_trainY, shape_trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for jan (black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "#for jan-march\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (1977299, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/black-data/jan/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (1977299, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/black-data/jan/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (1977299,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/black-data/jan/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (1977299,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/black-data/jan/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for jan-march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "#for jan-march\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (3038976,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for april-june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (2780980, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/apr-jun/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (2780980, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/apr-jun/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (2780980,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/apr-jun/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (2780980,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/apr-jun/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's combine memmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5819956, 16)\n"
     ]
    }
   ],
   "source": [
    "def concatenate_memmaps(file1, shape1, file2, shape2, dtype, result_file):\n",
    "    # Calculate the new shape\n",
    "    new_shape = (shape1[0] + shape2[0],) + shape1[1:]\n",
    "    \n",
    "    # Create a new memmap for the concatenated data\n",
    "    concatenated = np.memmap(result_file, dtype=dtype, mode='w+', shape=new_shape)\n",
    "    \n",
    "    # Load the original memmaps\n",
    "    memmap1 = np.memmap(file1, dtype=dtype, mode='r', shape=shape1)\n",
    "    memmap2 = np.memmap(file2, dtype=dtype, mode='r', shape=shape2)\n",
    "    \n",
    "    # Copy data from the original memmaps to the new memmap\n",
    "    concatenated[:shape1[0]] = memmap1[:]\n",
    "    concatenated[shape1[0]:] = memmap2[:]\n",
    "    \n",
    "    # Flush changes to ensure they're written to disk\n",
    "    concatenated.flush()\n",
    "    \n",
    "    return concatenated\n",
    "\n",
    "# Example usage for trainX_sequences\n",
    "dtype = np.int64\n",
    "shape_jan_mar = (3038976, 16)\n",
    "shape_apr_jun = (2780980, 16)\n",
    "result_file_sequences = './../data/combined/trainX_sequences.memmap'\n",
    "\n",
    "concatenated_sequences = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX_sequences.memmap', shape_jan_mar,\n",
    "    './../data/apr-jun/trainX_sequences.memmap', shape_apr_jun,\n",
    "    dtype, result_file_sequences)\n",
    "\n",
    "# Print the shape of the concatenated memmap to verify\n",
    "print(concatenated_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX concatenation\n",
    "shape_jan_mar_trainX = (3038976, 12, 8, 8)\n",
    "shape_apr_jun_trainX = (2780980, 12, 8, 8)\n",
    "result_file_trainX = './../data/combined/trainX.memmap'\n",
    "\n",
    "concatenated_trainX = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX.memmap', shape_jan_mar_trainX,\n",
    "    './../data/apr-jun/trainX.memmap', shape_apr_jun_trainX,\n",
    "    dtype_trainX, result_file_trainX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainY concatenation\n",
    "shape_jan_mar_trainY = (3038976,)\n",
    "shape_apr_jun_trainY = (2780980,)\n",
    "result_file_trainY = './../data/combined/trainY.memmap'\n",
    "\n",
    "concatenated_trainY = concatenate_memmaps(\n",
    "    './../data/jan-march/trainY.memmap', shape_jan_mar_trainY,\n",
    "    './../data/apr-jun/trainY.memmap', shape_apr_jun_trainY,\n",
    "    dtype_trainY, result_file_trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX_seqlengths concatenation\n",
    "shape_jan_mar_seqlengths = (3038976,)\n",
    "shape_apr_jun_seqlengths = (2780980,)\n",
    "result_file_seqlengths = './../data/combined/trainX_seqlengths.memmap'\n",
    "\n",
    "concatenated_seqlengths = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX_seqlengths.memmap', shape_jan_mar_seqlengths,\n",
    "    './../data/apr-jun/trainX_seqlengths.memmap', shape_apr_jun_seqlengths,\n",
    "    dtype_trainX_seqlengths, result_file_seqlengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (5819956, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/combined/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (5819956, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/combined/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (5819956,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/combined/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (5819956,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/combined/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: Let's make another form of data (only board states but give all the last 8 board states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainX_sequences, trainX, trainY, vocab = df_to_data_extended(grouped_df, fixed_window=True, fixed_window_size=8,sampling_rate=0.25)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainX_sequences, trainX_seqlengths, trainY = np.array(trainX), np.array(trainX_sequences), np.array(trainX_seqlengths), np.array(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each array as a memmap file\n",
    "filenames = [\n",
    "    save_as_memmap(trainX_sequences, './../data/jan-march/trainX_1_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/jan-march/trainX_1.memmap'),\n",
    "    save_as_memmap(trainY, './../data/jan-march/trainY_1.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/jan-march/trainX_1_seqlengths.memmap')\n",
    "]\n",
    "\n",
    "with open('./../data/jan-march/vocab_1.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For trainX_sequences\n",
    "# dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "# trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# # For trainX\n",
    "# dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "# trainX = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# # For trainY\n",
    "# dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "# shape_trainY = (3038976,)  # replace with the correct shape\n",
    "# trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# # For trainX_seqlengths\n",
    "# dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "# trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
