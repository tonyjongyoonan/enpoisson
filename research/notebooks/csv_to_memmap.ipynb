{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import pickle\n",
    "import utils\n",
    "import models\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         game_id                                              moves  \\\n",
      "0       00VRM44j  e2e4 g8f6 e4e5 f6g8 f1b5 f7f6 e5e6 c7c6 e6d7 c...   \n",
      "1       0MG5pz3L  c2c4 g7g6 e2e4 f8g7 d2d3 d7d6 f1e2 g8f6 g1f3 e...   \n",
      "2       0MV7dmua  e2e4 e7e5 f2f4 e5f4 g1f3 d7d5 e4d5 d8d5 b1c3 d...   \n",
      "3       0UNsyqEb  d2d4 d7d5 c2c4 g8f6 b1c3 c8f5 c1g5 e7e6 e2e3 h...   \n",
      "4       10mypbCS  d2d4 g7g6 c1h6 f8h6 g1f3 g8f6 e2e3 b8c6 f1b5 d...   \n",
      "...          ...                                                ...   \n",
      "466483  yT5CKw8c  g1f3 e7e6 b1c3 d7d5 d2d4 g8f6 c1g5 c7c5 e2e3 h...   \n",
      "466484  yxAYsxBu  e2e4 e7e5 d2d4 e5d4 c2c3 d4c3 f1c4 c3b2 c1b2 f...   \n",
      "466485  zLOF4boA  d2d4 c7c5 d4c5 b8c6 a2a3 g7g6 g1f3 f8g7 c2c3 e...   \n",
      "466486  zimmRKoi  e2e4 e7e5 g1f3 d7d6 f1c4 c7c6 h2h3 d8e7 e1g1 c...   \n",
      "466487  zzidHYZH  e2e4 e7e6 d2d4 d7d5 e4e5 c7c5 c2c3 d8b6 g1f3 b...   \n",
      "\n",
      "        white_elo  black_elo  white_active  \\\n",
      "0            1523       1500          True   \n",
      "1            1538       1580          True   \n",
      "2            1587       1575          True   \n",
      "3            1507       1545          True   \n",
      "4            1500       1500          True   \n",
      "...           ...        ...           ...   \n",
      "466483       1537       1598          True   \n",
      "466484       1569       1536          True   \n",
      "466485       1535       1594          True   \n",
      "466486       1587       1536          True   \n",
      "466487       1597       1587          True   \n",
      "\n",
      "                                                    board  \n",
      "0       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "1       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "2       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "3       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "4       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "...                                                   ...  \n",
      "466483  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "466484  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "466485  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "466486  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "466487  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "\n",
      "[466488 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "grouped_df = pd.read_csv(\"../data/haha-longer-mid.csv\")\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../data/jan-march/vocab.pkl', 'rb') as inp:\n",
    "    vocab_old = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, seq_lengths, vocab = df_to_data_fen_only_padded(grouped_df, fixed_window=True, sampling_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY, seq_lengths = np.asarray(trainY), np.asarray(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainX_sequences, fens, trainX, trainY, vocab = df_to_data(grouped_df, fixed_window=True, sampling_rate=0.5)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainX, trainX_sequences, fens, trainX_seqlengths, trainY \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(trainX), np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtrainX_sequences\u001b[49m), np\u001b[38;5;241m.\u001b[39marray(fens), np\u001b[38;5;241m.\u001b[39marray(trainX_seqlengths), np\u001b[38;5;241m.\u001b[39marray(trainY)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "trainX, trainX_sequences, fens, trainX_seqlengths, trainY = np.array(trainX), np.array(trainX_sequences), np.array(fens), np.array(trainX_seqlengths), np.array(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last step of saving our data onto our disk so that it's ready to load as we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_memmap(array, filename):\n",
    "    # Determine the dtype and shape of the array to create a compatible memmap\n",
    "    dtype = array.dtype\n",
    "    shape = array.shape\n",
    "    \n",
    "    # Create a memmap file with write mode, which will also allocate the disk space\n",
    "    memmap_array = np.memmap(filename, dtype=dtype, mode='w+', shape=shape)\n",
    "    \n",
    "    # Copy the data into the memmap array\n",
    "    memmap_array[:] = array[:]\n",
    "    \n",
    "    # Flush memory changes to disk to ensure all data is written\n",
    "    memmap_array.flush()\n",
    "\n",
    "    # Return the path for confirmation\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each array as a memmap file\n",
    "filenames = [\n",
    "    save_as_memmap(trainX_sequences, './../data/jan-march/trainX_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/jan-march/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/jan-march/trainY.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/jan-march/trainX_seqlengths.memmap')\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(fens, columns=['fens'])\n",
    "csv_filename = './../data/jan-march/fens.csv'\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for transformer data\n",
    "filenames = [\n",
    "    # save_as_memmap(trainX, './../data/transformer/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/transformer/trainY.memmap'),\n",
    "    save_as_memmap(trainY, './../data/transformer/seq_lengths.memmap')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../data/transformer/vocab.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for lengths so we can load in files correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6127912, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished processing the data, let's now load in the data (assuming we're starting from fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you forget the shape\n",
    "def find_working_shape(filename, dtype, max_first_dim, other_dims):\n",
    "\n",
    "    # Try decreasing sizes from the max_first_dim until we find a working shape\n",
    "    for first_dim in range(max_first_dim, 0, -1):\n",
    "        shape_to_try = (first_dim,) + other_dims\n",
    "        \n",
    "        try:\n",
    "            # Attempt to load the memmap with the current shape\n",
    "            memmap_array = np.memmap(filename, dtype=dtype, mode='r', shape=shape_to_try)\n",
    "            # If successful, return the array\n",
    "            print(f\"Successful shape: {shape_to_try}\")\n",
    "            return memmap_array\n",
    "        except ValueError as e:\n",
    "            # Catch the ValueError if the shape is not feasible, and try the next size\n",
    "            continue\n",
    "    \n",
    "    raise ValueError(\"Could not find a working shape within the given bounds.\")\n",
    "\n",
    "dtype_trainX = np.int64\n",
    "max_first_dim = 3038976  # This is your starting point, the upper bound of the first dimension\n",
    "other_dims = (12, 8, 8)  # The other dimensions of the shape, assumed to be correct\n",
    "\n",
    "trainX_filename = './../data/apr-jun/trainX.memmap'\n",
    "\n",
    "# Try to find a working memmap shape\n",
    "dummy = find_working_shape(trainX_filename, dtype_trainX, max_first_dim, other_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trainX\n",
    "dtype_trainX = np.int32  # or the correct dtype for your data\n",
    "shape_trainX = (130265, 750)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/transformer/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int32 # or the correct dtype for your data\n",
    "shape_trainY = (130265, 7)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/transformer/trainY.memmap', dtype_trainY, shape_trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for jan-march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "#for jan-march\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (3038976,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for april-june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (2780980, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/apr-jun/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (2780980, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/apr-jun/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (2780980,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/apr-jun/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (2780980,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/apr-jun/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's combine memmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5819956, 16)\n"
     ]
    }
   ],
   "source": [
    "def concatenate_memmaps(file1, shape1, file2, shape2, dtype, result_file):\n",
    "    # Calculate the new shape\n",
    "    new_shape = (shape1[0] + shape2[0],) + shape1[1:]\n",
    "    \n",
    "    # Create a new memmap for the concatenated data\n",
    "    concatenated = np.memmap(result_file, dtype=dtype, mode='w+', shape=new_shape)\n",
    "    \n",
    "    # Load the original memmaps\n",
    "    memmap1 = np.memmap(file1, dtype=dtype, mode='r', shape=shape1)\n",
    "    memmap2 = np.memmap(file2, dtype=dtype, mode='r', shape=shape2)\n",
    "    \n",
    "    # Copy data from the original memmaps to the new memmap\n",
    "    concatenated[:shape1[0]] = memmap1[:]\n",
    "    concatenated[shape1[0]:] = memmap2[:]\n",
    "    \n",
    "    # Flush changes to ensure they're written to disk\n",
    "    concatenated.flush()\n",
    "    \n",
    "    return concatenated\n",
    "\n",
    "# Example usage for trainX_sequences\n",
    "dtype = np.int64\n",
    "shape_jan_mar = (3038976, 16)\n",
    "shape_apr_jun = (2780980, 16)\n",
    "result_file_sequences = './../data/combined/trainX_sequences.memmap'\n",
    "\n",
    "concatenated_sequences = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX_sequences.memmap', shape_jan_mar,\n",
    "    './../data/apr-jun/trainX_sequences.memmap', shape_apr_jun,\n",
    "    dtype, result_file_sequences)\n",
    "\n",
    "# Print the shape of the concatenated memmap to verify\n",
    "print(concatenated_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX concatenation\n",
    "shape_jan_mar_trainX = (3038976, 12, 8, 8)\n",
    "shape_apr_jun_trainX = (2780980, 12, 8, 8)\n",
    "result_file_trainX = './../data/combined/trainX.memmap'\n",
    "\n",
    "concatenated_trainX = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX.memmap', shape_jan_mar_trainX,\n",
    "    './../data/apr-jun/trainX.memmap', shape_apr_jun_trainX,\n",
    "    dtype_trainX, result_file_trainX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainY concatenation\n",
    "shape_jan_mar_trainY = (3038976,)\n",
    "shape_apr_jun_trainY = (2780980,)\n",
    "result_file_trainY = './../data/combined/trainY.memmap'\n",
    "\n",
    "concatenated_trainY = concatenate_memmaps(\n",
    "    './../data/jan-march/trainY.memmap', shape_jan_mar_trainY,\n",
    "    './../data/apr-jun/trainY.memmap', shape_apr_jun_trainY,\n",
    "    dtype_trainY, result_file_trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX_seqlengths concatenation\n",
    "shape_jan_mar_seqlengths = (3038976,)\n",
    "shape_apr_jun_seqlengths = (2780980,)\n",
    "result_file_seqlengths = './../data/combined/trainX_seqlengths.memmap'\n",
    "\n",
    "concatenated_seqlengths = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX_seqlengths.memmap', shape_jan_mar_seqlengths,\n",
    "    './../data/apr-jun/trainX_seqlengths.memmap', shape_apr_jun_seqlengths,\n",
    "    dtype_trainX_seqlengths, result_file_seqlengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (5819956, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/combined/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (5819956, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/combined/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (5819956,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/combined/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (5819956,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/combined/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: Let's make another form of data (only board states but give all the last 8 board states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainX_sequences, trainX, trainY, vocab = df_to_data_extended(grouped_df, fixed_window=True, fixed_window_size=8,sampling_rate=0.25)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainX_sequences, trainX_seqlengths, trainY = np.array(trainX), np.array(trainX_sequences), np.array(trainX_seqlengths), np.array(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each array as a memmap file\n",
    "filenames = [\n",
    "    save_as_memmap(trainX_sequences, './../data/jan-march/trainX_1_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/jan-march/trainX_1.memmap'),\n",
    "    save_as_memmap(trainY, './../data/jan-march/trainY_1.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/jan-march/trainX_1_seqlengths.memmap')\n",
    "]\n",
    "\n",
    "with open('./../data/jan-march/vocab_1.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For trainX_sequences\n",
    "# dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "# trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# # For trainX\n",
    "# dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "# trainX = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# # For trainY\n",
    "# dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "# shape_trainY = (3038976,)  # replace with the correct shape\n",
    "# trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# # For trainX_seqlengths\n",
    "# dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "# shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "# trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
