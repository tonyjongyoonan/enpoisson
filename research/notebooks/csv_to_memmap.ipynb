{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import pickle\n",
    "import utils\n",
    "import models\n",
    "import dask.array as da\n",
    "\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         game_id                                              moves  \\\n",
      "0       1gFKuI4R  g1f3 c7c5 g2g3 g7g6 f1g2 f8g7 e1g1 b8c6 c2c4 d...   \n",
      "1       6Kp4KfSK  d2d4 d7d5 c2c4 d5c4 b1c3 e7e5 e2e3 b8c6 f1c4 g...   \n",
      "2       AJ0ErxUz  d2d4 c7c5 g1f3 c5d4 c1f4 b8c6 c2c3 e7e5 f4e5 d...   \n",
      "3       D1t7sFQ6  d2d4 g8f6 c2c4 e7e6 b1c3 d7d5 g1f3 f8b4 d1b3 b...   \n",
      "4       M77OjMWp  d2d4 g8f6 c2c4 g7g6 b1c3 f8g7 e2e4 d7d6 f2f4 e...   \n",
      "...          ...                                                ...   \n",
      "263267  xpxi2PfS  e2e4 c7c6 d2d4 d7d5 b1c3 d5e4 c3e4 c8f5 e4g3 f...   \n",
      "263268  y38Wy8Io  d2d4 g8f6 g1f3 g7g6 c1g5 f8g7 b1d2 e8g8 e2e4 d...   \n",
      "263269  y4GxfsDR  d2d4 g8f6 g1f3 g7g6 c1f4 f8g7 e2e3 d7d6 h2h3 f...   \n",
      "263270  yANoOutS  c2c4 g8f6 b1c3 e7e6 e2e4 f8b4 e4e5 c7c6 e5f6 b...   \n",
      "263271  ybpO73Eh  e2e4 e7e5 b1c3 b8c6 f1c4 g8f6 d2d3 f8c5 c1g5 h...   \n",
      "\n",
      "        white_elo  black_elo  white_active  \\\n",
      "0            2199       2142          True   \n",
      "1            2104       2177          True   \n",
      "2            2108       2165          True   \n",
      "3            2148       2184          True   \n",
      "4            2131       2139          True   \n",
      "...           ...        ...           ...   \n",
      "263267       2070       2013          True   \n",
      "263268       2030       2044          True   \n",
      "263269       2162       2101          True   \n",
      "263270       2064       2095          True   \n",
      "263271       2084       2100          True   \n",
      "\n",
      "                                                    board  \n",
      "0       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "1       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "2       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "3       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "4       rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "...                                                   ...  \n",
      "263267  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "263268  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "263269  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "263270  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "263271  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...  \n",
      "\n",
      "[263272 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "grouped_df = pd.read_csv(\"../data/2100-jan-jun.csv\")\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this when combining memmaps\n",
    "with open('./../data/black-data/july-sept/vocab.pkl', 'rb') as inp:\n",
    "    vocab_old = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_memmap(array, filename):\n",
    "    # Determine the dtype and shape of the array to create a compatible memmap\n",
    "    dtype = array.dtype\n",
    "    shape = array.shape\n",
    "    \n",
    "    # Create a memmap file with write mode, which will also allocate the disk space\n",
    "    memmap_array = np.memmap(filename, dtype=dtype, mode='w+', shape=shape)\n",
    "    \n",
    "    # Copy the data into the memmap array\n",
    "    memmap_array[:] = array[:]\n",
    "    \n",
    "    # Flush memory changes to disk to ensure all data is written\n",
    "    memmap_array.flush()\n",
    "\n",
    "    # Return the path for confirmation\n",
    "    return filename\n",
    "\n",
    "# If you forget the shape\n",
    "def find_working_shape(filename, dtype, max_first_dim, other_dims):\n",
    "\n",
    "    # Try decreasing sizes from the max_first_dim until we find a working shape\n",
    "    for first_dim in range(max_first_dim, 0, -1):\n",
    "        shape_to_try = (first_dim,) + other_dims\n",
    "        \n",
    "        try:\n",
    "            # Attempt to load the memmap with the current shape\n",
    "            memmap_array = np.memmap(filename, dtype=dtype, mode='r', shape=shape_to_try)\n",
    "            # If successful, return the array\n",
    "            print(f\"Successful shape: {shape_to_try}\")\n",
    "            return memmap_array\n",
    "        except ValueError as e:\n",
    "            # Catch the ValueError if the shape is not feasible, and try the next size\n",
    "            continue\n",
    "    \n",
    "    raise ValueError(\"Could not find a working shape within the given bounds.\")\n",
    "\n",
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, vocab = df_to_data_fen_only_padded(grouped_df, fixed_window=True, sampling_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2524"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 6, 4, 0, 0, 0, 0, 0, 0], [3, 31, 4, 0, 0, 0, 0, 0, 0], [3, 35, 36, 37, 4, 0, 0, 0, 0], [3, 43, 37, 4, 0, 0, 0, 0, 0], [3, 58, 4, 0, 0, 0, 0, 0, 0], [3, 26, 4, 0, 0, 0, 0, 0, 0], [3, 69, 37, 4, 0, 0, 0, 0, 0], [3, 42, 4, 0, 0, 0, 0, 0, 0], [3, 6, 4, 0, 0, 0, 0, 0, 0], [3, 77, 4, 0, 0, 0, 0, 0, 0], [3, 81, 4, 0, 0, 0, 0, 0, 0], [3, 85, 4, 0, 0, 0, 0, 0, 0], [3, 91, 37, 4, 0, 0, 0, 0, 0], [3, 92, 37, 4, 0, 0, 0, 0, 0], [3, 61, 37, 4, 0, 0, 0, 0, 0], [3, 94, 37, 4, 0, 0, 0, 0, 0], [3, 97, 37, 4, 0, 0, 0, 0, 0], [3, 98, 4, 0, 0, 0, 0, 0, 0], [3, 106, 4, 0, 0, 0, 0, 0, 0], [3, 107, 37, 4, 0, 0, 0, 0, 0], [3, 53, 4, 0, 0, 0, 0, 0, 0], [3, 52, 4, 0, 0, 0, 0, 0, 0], [3, 46, 4, 0, 0, 0, 0, 0, 0], [3, 57, 4, 0, 0, 0, 0, 0, 0], [3, 114, 4, 0, 0, 0, 0, 0, 0], [3, 54, 4, 0, 0, 0, 0, 0, 0], [3, 115, 4, 0, 0, 0, 0, 0, 0], [3, 48, 4, 0, 0, 0, 0, 0, 0], [3, 118, 37, 4, 0, 0, 0, 0, 0], [3, 64, 4, 0, 0, 0, 0, 0, 0], [3, 123, 36, 37, 4, 0, 0, 0, 0], [3, 128, 4, 0, 0, 0, 0, 0, 0], [3, 132, 36, 37, 4, 0, 0, 0, 0], [3, 56, 4, 0, 0, 0, 0, 0, 0], [3, 64, 4, 0, 0, 0, 0, 0, 0], [3, 67, 36, 4, 0, 0, 0, 0, 0], [3, 133, 36, 4, 0, 0, 0, 0, 0], [3, 138, 36, 4, 0, 0, 0, 0, 0], [3, 141, 36, 37, 4, 0, 0, 0, 0], [3, 149, 36, 37, 4, 0, 0, 0, 0], [3, 156, 4, 0, 0, 0, 0, 0, 0], [3, 75, 4, 0, 0, 0, 0, 0, 0], [3, 141, 4, 0, 0, 0, 0, 0, 0], [3, 49, 4, 0, 0, 0, 0, 0, 0], [3, 163, 4, 0, 0, 0, 0, 0, 0], [3, 163, 37, 4, 0, 0, 0, 0, 0], [3, 56, 4, 0, 0, 0, 0, 0, 0], [3, 78, 4, 0, 0, 0, 0, 0, 0], [3, 75, 4, 0, 0, 0, 0, 0, 0], [3, 164, 4, 0, 0, 0, 0, 0, 0], [3, 165, 4, 0, 0, 0, 0, 0, 0], [3, 6, 4, 0, 0, 0, 0, 0, 0], [3, 69, 37, 4, 0, 0, 0, 0, 0], [3, 166, 4, 0, 0, 0, 0, 0, 0], [3, 167, 4, 0, 0, 0, 0, 0, 0], [3, 168, 4, 0, 0, 0, 0, 0, 0], [3, 170, 37, 4, 0, 0, 0, 0, 0], [3, 118, 37, 4, 0, 0, 0, 0, 0], [3, 172, 37, 4, 0, 0, 0, 0, 0], [3, 174, 4, 0, 0, 0, 0, 0, 0], [3, 179, 37, 4, 0, 0, 0, 0, 0], [3, 90, 4, 0, 0, 0, 0, 0, 0], [3, 182, 37, 4, 0, 0, 0, 0, 0], [3, 115, 4, 0, 0, 0, 0, 0, 0], [3, 81, 4, 0, 0, 0, 0, 0, 0], [3, 184, 4, 0, 0, 0, 0, 0, 0], [3, 49, 4, 0, 0, 0, 0, 0, 0], [3, 78, 4, 0, 0, 0, 0, 0, 0], [3, 164, 4, 0, 0, 0, 0, 0, 0], [3, 32, 4, 0, 0, 0, 0, 0, 0], [3, 61, 4, 0, 0, 0, 0, 0, 0], [3, 92, 4, 0, 0, 0, 0, 0, 0], [3, 56, 4, 0, 0, 0, 0, 0, 0], [3, 189, 4, 0, 0, 0, 0, 0, 0], [3, 169, 4, 0, 0, 0, 0, 0, 0], [3, 193, 36, 4, 0, 0, 0, 0, 0], [3, 26, 4, 0, 0, 0, 0, 0, 0], [3, 78, 4, 0, 0, 0, 0, 0, 0], [3, 65, 37, 4, 0, 0, 0, 0, 0], [3, 197, 37, 4, 0, 0, 0, 0, 0], [3, 25, 4, 0, 0, 0, 0, 0, 0], [3, 110, 4, 0, 0, 0, 0, 0, 0], [3, 46, 4, 0, 0, 0, 0, 0, 0], [3, 53, 4, 0, 0, 0, 0, 0, 0], [3, 203, 4, 0, 0, 0, 0, 0, 0], [3, 205, 4, 0, 0, 0, 0, 0, 0], [3, 208, 4, 0, 0, 0, 0, 0, 0], [3, 178, 4, 0, 0, 0, 0, 0, 0], [3, 131, 4, 0, 0, 0, 0, 0, 0], [3, 213, 4, 0, 0, 0, 0, 0, 0], [3, 81, 4, 0, 0, 0, 0, 0, 0], [3, 110, 4, 0, 0, 0, 0, 0, 0], [3, 25, 4, 0, 0, 0, 0, 0, 0], [3, 164, 4, 0, 0, 0, 0, 0, 0], [3, 214, 4, 0, 0, 0, 0, 0, 0], [3, 52, 4, 0, 0, 0, 0, 0, 0], [3, 48, 4, 0, 0, 0, 0, 0, 0], [3, 220, 4, 0, 0, 0, 0, 0, 0], [3, 172, 37, 4, 0, 0, 0, 0, 0], [3, 70, 4, 0, 0, 0, 0, 0, 0], [3, 224, 4, 0, 0, 0, 0, 0, 0], [3, 226, 37, 4, 0, 0, 0, 0, 0], [3, 40, 37, 4, 0, 0, 0, 0, 0], [3, 231, 36, 37, 4, 0, 0, 0, 0], [3, 233, 4, 0, 0, 0, 0, 0, 0], [3, 237, 36, 4, 0, 0, 0, 0, 0], [3, 6, 4, 0, 0, 0, 0, 0, 0], [3, 26, 4, 0, 0, 0, 0, 0, 0], [3, 190, 4, 0, 0, 0, 0, 0, 0], [3, 242, 36, 37, 4, 0, 0, 0, 0], [3, 244, 4, 0, 0, 0, 0, 0, 0], [3, 124, 4, 0, 0, 0, 0, 0, 0], [3, 248, 4, 0, 0, 0, 0, 0, 0], [3, 114, 4, 0, 0, 0, 0, 0, 0], [3, 183, 4, 0, 0, 0, 0, 0, 0], [3, 188, 4, 0, 0, 0, 0, 0, 0], [3, 209, 37, 4, 0, 0, 0, 0, 0], [3, 49, 4, 0, 0, 0, 0, 0, 0], [3, 213, 4, 0, 0, 0, 0, 0, 0], [3, 178, 4, 0, 0, 0, 0, 0, 0], [3, 259, 4, 0, 0, 0, 0, 0, 0], [3, 152, 4, 0, 0, 0, 0, 0, 0], [3, 105, 4, 0, 0, 0, 0, 0, 0], [3, 77, 4, 0, 0, 0, 0, 0, 0], [3, 190, 4, 0, 0, 0, 0, 0, 0], [3, 245, 4, 0, 0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = np.asarray(trainX, dtype=np.int32), np.asarray(trainY, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for transformer data\n",
    "filenames = [\n",
    "    save_as_memmap(trainX, './../data/transformer/jan-march/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/transformer/jan-march/trainY.memmap'),\n",
    "]\n",
    "with open('./../data/transformer/jan-march/vocab.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for lengths so we're able to load them back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6130889, 585)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trainX\n",
    "dtype_trainX = np.int32  # or the correct dtype for your data\n",
    "shape_trainX = (2161324, 585)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/transformer/jan/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int32 # or the correct dtype for your data\n",
    "shape_trainY = (2161324, 6)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/transformer/jan/trainY.memmap', dtype_trainY, shape_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  7  8  9 10 11  9  8  7 12 13 13 13 13 13 13 13 13 12 14 14 14 14\n",
      " 14 14 14 14 12 14 14 14 14 14 14 14 14 12 14 14 14 14 14 14 14 14 12 14\n",
      " 14 14 14 14 14 14 14 12 15 15 15 15 15 15 15 15 12 16 17 18 19 20 18 17\n",
      " 16  5 21  5 20 19 11 10  5 22  5 23  5 24  3 72  4  2  7  8  9 10 11  9\n",
      "  8  7 12 13 13 13 13 13 13 13 13 12 14 14 14 14 14 14 14 14 12 14 14 14\n",
      " 14 14 14 14 14 12 14 14 15 14 14 14 14 14 12 14 14 14 14 14 14 14 14 12\n",
      " 15 15 14 15 15 15 15 15 12 16 17 18 19 20 18 17 16  5  9  5 20 19 11 10\n",
      "  5 22  5 23  5 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(trainX[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O-O\n"
     ]
    }
   ],
   "source": [
    "print(vocab.get_word(77))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_sequences, fens, trainX, trainY, vocab = df_to_data_black(grouped_df, fixed_window=True, sampling_rate=0.25)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainX_sequences, fens, trainX_seqlengths, trainY = np.asarray(trainX), np.asarray(trainX_sequences), np.asarray(fens), np.asarray(trainX_seqlengths), np.asarray(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for black multi-modal\n",
    "filenames = [\n",
    "    save_as_memmap(trainX_sequences, './../data/black-2100/trainX_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/black-2100/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/black-2100/trainY.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/black-2100/trainX_seqlengths.memmap')\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(fens, columns=['fens'])\n",
    "csv_filename = './../data/black-2100/fens.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "with open('./../data/black-2100/vocab.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5987"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.move_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1733003, 12, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_sequences, fens, trainX, trainY, vocab = df_to_data(grouped_df, fixed_window=True, sampling_rate=0.25)\n",
    "trainX_sequences, trainX_seqlengths  = pad_sequences(trainX_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainX_sequences, fens, trainX_seqlengths, trainY = np.asarray(trainX), np.asarray(trainX_sequences), np.asarray(fens), np.asarray(trainX_seqlengths), np.asarray(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for black multi-modal\n",
    "filenames = [\n",
    "    save_as_memmap(trainX_sequences, './../data/white-2100/trainX_sequences.memmap'),\n",
    "    save_as_memmap(trainX, './../data/white-2100/trainX.memmap'),\n",
    "    save_as_memmap(trainY, './../data/white-2100/trainY.memmap'),\n",
    "    save_as_memmap(trainX_seqlengths, './../data/white-2100/trainX_seqlengths.memmap')\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(fens, columns=['fens'])\n",
    "csv_filename = './../data/white-2100/fens.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "with open('./../data/white-2100/vocab.pkl', 'wb') as outp:\n",
    "    pickle.dump(vocab, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1766908, 12, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_trainX = np.int64\n",
    "max_first_dim = 3038976  # This is your starting point, the upper bound of the first dimension\n",
    "other_dims = (12, 8, 8)  # The other dimensions of the shape, assumed to be correct\n",
    "\n",
    "trainX_filename = './../data/apr-jun/trainX.memmap'\n",
    "\n",
    "# Try to find a working memmap shape\n",
    "dummy = find_working_shape(trainX_filename, dtype_trainX, max_first_dim, other_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for jan (black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "#for jan-march\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (1977299, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/black-data/jan/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (1977299, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/black-data/jan/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (1977299,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/black-data/jan/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (1977299,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/black-data/jan/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for jan-march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "#for jan-march\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (3038976, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/jan-march/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (3038976, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/jan-march/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (3038976,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/jan-march/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (3038976,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/jan-march/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for april-june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (2780980, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/apr-jun/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (2780980, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/apr-jun/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (2780980,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/apr-jun/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (2780980,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/apr-jun/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's combine memmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_memmaps(file1, shape1, file2, shape2, dtype, result_file):\n",
    "    # Calculate the new shape\n",
    "    new_shape = (shape1[0] + shape2[0],) + shape1[1:]\n",
    "    \n",
    "    # Create a new memmap for the concatenated data\n",
    "    concatenated = np.memmap(result_file, dtype=dtype, mode='w+', shape=new_shape)\n",
    "    \n",
    "    # Load the original memmaps\n",
    "    memmap1 = np.memmap(file1, dtype=dtype, mode='r', shape=shape1)\n",
    "    memmap2 = np.memmap(file2, dtype=dtype, mode='r', shape=shape2)\n",
    "    \n",
    "    # Copy data from the original memmaps to the new memmap\n",
    "    concatenated[:shape1[0]] = memmap1[:]\n",
    "    concatenated[shape1[0]:] = memmap2[:]\n",
    "    \n",
    "    # Flush changes to ensure they're written to disk\n",
    "    concatenated.flush()\n",
    "    \n",
    "    return concatenated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../data/jan-march/trainX_sequences.memmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m shape_apr_jun \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2780980\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      5\u001b[0m result_file_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./../data/combined/trainX_sequences.memmap\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m concatenated_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_memmaps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./../data/jan-march/trainX_sequences.memmap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_jan_mar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./../data/apr-jun/trainX_sequences.memmap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_apr_jun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_file_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# trainX concatenation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m shape_jan_mar_trainX \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3038976\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mconcatenate_memmaps\u001b[0;34m(file1, shape1, file2, shape2, dtype, result_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m concatenated \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmemmap(result_file, dtype\u001b[38;5;241m=\u001b[39mdtype, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39mnew_shape)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the original memmaps\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m memmap1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m memmap2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmemmap(file2, dtype\u001b[38;5;241m=\u001b[39mdtype, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39mshape2)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Copy data from the original memmaps to the new memmap\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/numpy/core/memmap.py:229\u001b[0m, in \u001b[0;36mmemmap.__new__\u001b[0;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[1;32m    227\u001b[0m     f_ctx \u001b[38;5;241m=\u001b[39m nullcontext(filename)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     f_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m f_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    232\u001b[0m     fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../data/jan-march/trainX_sequences.memmap'"
     ]
    }
   ],
   "source": [
    "# Example usage for trainX_sequences\n",
    "dtype = np.int64\n",
    "shape_jan_mar = (3038976, 16)\n",
    "shape_apr_jun = (2780980, 16)\n",
    "result_file_sequences = './../data/combined/trainX_sequences.memmap'\n",
    "\n",
    "concatenated_sequences = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX_sequences.memmap', shape_jan_mar,\n",
    "    './../data/apr-jun/trainX_sequences.memmap', shape_apr_jun,\n",
    "    dtype, result_file_sequences)\n",
    "\n",
    "\n",
    "# trainX concatenation\n",
    "shape_jan_mar_trainX = (3038976, 12, 8, 8)\n",
    "shape_apr_jun_trainX = (2780980, 12, 8, 8)\n",
    "result_file_trainX = './../data/combined/trainX.memmap'\n",
    "\n",
    "concatenated_trainX = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX.memmap', shape_jan_mar_trainX,\n",
    "    './../data/apr-jun/trainX.memmap', shape_apr_jun_trainX,\n",
    "    dtype_trainX, result_file_trainX)\n",
    "\n",
    "# trainY concatenation\n",
    "shape_jan_mar_trainY = (3038976,)\n",
    "shape_apr_jun_trainY = (2780980,)\n",
    "result_file_trainY = './../data/combined/trainY.memmap'\n",
    "\n",
    "concatenated_trainY = concatenate_memmaps(\n",
    "    './../data/jan-march/trainY.memmap', shape_jan_mar_trainY,\n",
    "    './../data/apr-jun/trainY.memmap', shape_apr_jun_trainY,\n",
    "    dtype_trainY, result_file_trainY)\n",
    "\n",
    "# trainX_seqlengths concatenation\n",
    "shape_jan_mar_seqlengths = (3038976,)\n",
    "shape_apr_jun_seqlengths = (2780980,)\n",
    "result_file_seqlengths = './../data/combined/trainX_seqlengths.memmap'\n",
    "\n",
    "concatenated_seqlengths = concatenate_memmaps(\n",
    "    './../data/jan-march/trainX_seqlengths.memmap', shape_jan_mar_seqlengths,\n",
    "    './../data/apr-jun/trainX_seqlengths.memmap', shape_apr_jun_seqlengths,\n",
    "    dtype_trainX_seqlengths, result_file_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's do it for black data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_memmaps(files, shapes, dtype, result_file):\n",
    "    if len(files) != len(shapes):\n",
    "        raise ValueError(\"The number of files must match the number of shapes\")\n",
    "\n",
    "    # Calculate the total number of rows for the new shape\n",
    "    total_rows = sum(shape[0] for shape in shapes)\n",
    "    # Assume all shapes have the same dimensions beyond the first axis\n",
    "    new_shape = (total_rows,) + shapes[0][1:]\n",
    "    \n",
    "    # Create a new memmap for the concatenated data\n",
    "    concatenated = np.memmap(result_file, dtype=dtype, mode='w+', shape=new_shape)\n",
    "    \n",
    "    # Initial index for data insertion in the concatenated memmap\n",
    "    current_index = 0\n",
    "    \n",
    "    # Loop over each file and corresponding shape\n",
    "    for file, shape in zip(files, shapes):\n",
    "        print(file)\n",
    "        # Load the original memmap\n",
    "        memmap = np.memmap(file, dtype=dtype, mode='r', shape=shape)\n",
    "        \n",
    "        # Copy data to the appropriate slice of the concatenated memmap\n",
    "        concatenated[current_index:current_index + shape[0]] = memmap\n",
    "        \n",
    "        # Update the index for the next insertion point\n",
    "        current_index += shape[0]\n",
    "    \n",
    "    # Flush changes to ensure they're written to disk\n",
    "    concatenated.flush()\n",
    "\n",
    "def concatenate_memmaps_list(files, shapes, dtype, result_file):\n",
    "    if len(files) != len(shapes):\n",
    "        raise ValueError(\"The number of files must match the number of shapes\")\n",
    "    # Loop over each file and corresponding shape\n",
    "    memmaps = []\n",
    "    for file, shape in zip(files, shapes):\n",
    "        print(file)\n",
    "        # Load the original memmap\n",
    "        memmap = np.memmap(file, dtype=dtype, mode='r', shape=shape)\n",
    "        memmaps.append(memmap)\n",
    "    \n",
    "    # Flush changes to ensure they're written to disk\n",
    "    # concatenated.flush()\n",
    "    \n",
    "    return da.concatenate(memmaps,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/black-data/jan/trainX.memmap\n",
      "./../data/black-data/feb/trainX.memmap\n",
      "./../data/black-data/march/trainX.memmap\n",
      "./../data/black-data/apr-jun/trainX.memmap\n",
      "./../data/black-data/july-sept/trainX.memmap\n",
      "./../data/black-data/oct-dec/trainX.memmap\n"
     ]
    }
   ],
   "source": [
    "trainX_files = ['./../data/black-data/jan/trainX.memmap',\n",
    "                './../data/black-data/feb/trainX.memmap', \n",
    "                './../data/black-data/march/trainX.memmap',\n",
    "                './../data/black-data/apr-jun/trainX.memmap',\n",
    "                './../data/black-data/july-sept/trainX.memmap',\n",
    "                './../data/black-data/oct-dec/trainX.memmap'\n",
    "                ]\n",
    "\n",
    "trainY_files = ['./../data/black-data/jan/trainY.memmap',\n",
    "                './../data/black-data/feb/trainY.memmap',\n",
    "                './../data/black-data/march/trainY.memmap',\n",
    "                './../data/black-data/apr-jun/trainY.memmap',\n",
    "                './../data/black-data/july-sept/trainY.memmap',\n",
    "                './../data/black-data/oct-dec/trainY.memmap'\n",
    "               ]\n",
    "\n",
    "trainX_sequences_files = ['./../data/black-data/jan/trainX_sequences.memmap',\n",
    "                          './../data/black-data/feb/trainX_sequences.memmap',\n",
    "                          './../data/black-data/march/trainX_sequences.memmap',\n",
    "                          './../data/black-data/apr-jun/trainX_sequences.memmap',\n",
    "                          './../data/black-data/july-sept/trainX_sequences.memmap',\n",
    "                          './../data/black-data/oct-dec/trainX_sequences.memmap'\n",
    "                         ]\n",
    "\n",
    "trainX_seqlengths_files = ['./../data/black-data/jan/trainX_seqlengths.memmap',\n",
    "                           './../data/black-data/feb/trainX_seqlengths.memmap',\n",
    "                           './../data/black-data/march/trainX_seqlengths.memmap',\n",
    "                           './../data/black-data/apr-jun/trainX_seqlengths.memmap',\n",
    "                           './../data/black-data/july-sept/trainX_seqlengths.memmap',\n",
    "                           './../data/black-data/oct-dec/trainX_seqlengths.memmap'\n",
    "                          ]\n",
    "\n",
    "trainX_shapes = [(1071641, 12, 8, 8),\n",
    "                 (922280, 12, 8, 8),\n",
    "                 (1040912, 12, 8, 8),\n",
    "                 (2726090, 12, 8, 8),\n",
    "                 (2654080, 12, 8, 8),\n",
    "                 (2965521, 12, 8, 8)\n",
    "                 ]\n",
    "\n",
    "train_shapes = [(1071641,),\n",
    "                 (922280,),\n",
    "                 (1040912,),\n",
    "                 (2726090,),\n",
    "                 (2654080,),\n",
    "                 (2965521,)\n",
    "                 ]\n",
    "\n",
    "sequence_shapes =[(1071641,16),\n",
    "                 (922280,16),\n",
    "                 (1040912,16),\n",
    "                 (2726090,16),\n",
    "                 (2654080,16),\n",
    "                 (2965521,16)\n",
    "                 ]\n",
    "\n",
    "concatenate_memmaps(trainX_files,trainX_shapes,np.int64, './../data/black-data/combined/trainX.memmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/black-data/jan/trainY.memmap\n",
      "./../data/black-data/feb/trainY.memmap\n",
      "./../data/black-data/march/trainY.memmap\n",
      "./../data/black-data/apr-jun/trainY.memmap\n",
      "./../data/black-data/july-sept/trainY.memmap\n",
      "./../data/black-data/oct-dec/trainY.memmap\n",
      "./../data/black-data/jan/trainX_sequences.memmap\n",
      "./../data/black-data/feb/trainX_sequences.memmap\n",
      "./../data/black-data/march/trainX_sequences.memmap\n",
      "./../data/black-data/apr-jun/trainX_sequences.memmap\n",
      "./../data/black-data/july-sept/trainX_sequences.memmap\n",
      "./../data/black-data/oct-dec/trainX_sequences.memmap\n",
      "./../data/black-data/jan/trainX_seqlengths.memmap\n",
      "./../data/black-data/feb/trainX_seqlengths.memmap\n",
      "./../data/black-data/march/trainX_seqlengths.memmap\n",
      "./../data/black-data/apr-jun/trainX_seqlengths.memmap\n",
      "./../data/black-data/july-sept/trainX_seqlengths.memmap\n",
      "./../data/black-data/oct-dec/trainX_seqlengths.memmap\n"
     ]
    }
   ],
   "source": [
    "concatenate_memmaps(trainY_files,train_shapes,np.int64, './../data/black-data/combined/trainY.memmap')\n",
    "concatenate_memmaps(trainX_sequences_files,sequence_shapes,np.int64, './../data/black-data/combined/trainX_sequences.memmap')\n",
    "concatenate_memmaps(trainX_seqlengths_files,train_shapes,np.int64, './../data/black-data/combined/trainX_seqlengths.memmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a memmap file\n",
    "def load_memmap(filename, dtype, shape):\n",
    "    # Load the memmap file with read-only mode\n",
    "    return np.memmap(filename, dtype=dtype, mode='r', shape=shape)\n",
    "\n",
    "# Assuming you know the dtype and shape, for example:\n",
    "# For trainX_sequences\n",
    "dtype_trainX_sequences = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_sequences = (11380524, 16)  # replace with the correct shape\n",
    "trainX_sequences = load_memmap('./../data/black-data/combined/trainX_sequences.memmap', dtype_trainX_sequences, shape_trainX_sequences)\n",
    "\n",
    "# For trainX\n",
    "dtype_trainX = np.int64  # or the correct dtype for your data\n",
    "shape_trainX = (11380524, 12, 8, 8)  # replace with the correct shape\n",
    "trainX = load_memmap('./../data/black-data/combined/trainX.memmap', dtype_trainX, shape_trainX)\n",
    "\n",
    "# For trainY\n",
    "dtype_trainY = np.int64  # or the correct dtype for your data\n",
    "shape_trainY = (11380524,)  # replace with the correct shape\n",
    "trainY = load_memmap('./../data/black-data/combined/trainY.memmap', dtype_trainY, shape_trainY)\n",
    "\n",
    "# For trainX_seqlengths\n",
    "dtype_trainX_seqlengths = np.int64  # or the correct dtype for your data\n",
    "shape_trainX_seqlengths = (11380524,)  # replace with the correct shape\n",
    "trainX_seqlengths = load_memmap('./../data/black-data/combined/trainX_seqlengths.memmap', dtype_trainX_seqlengths, shape_trainX_seqlengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
